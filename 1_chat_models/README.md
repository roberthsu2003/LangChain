# Chat Models â€” ç¯„ä¾‹èˆ‡èªªæ˜

ä½¿ç”¨ LangChain èˆ‡ä¸åŒå» å•†çš„ chat æ¨¡å‹ï¼ˆOpenAIã€Google Geminiã€Anthropicã€Ollama ç­‰ï¼‰ã€å»ºç«‹å°è©±æ­·å²èˆ‡å°‡è¨Šæ¯å„²å­˜åˆ° Firebase/Firestoreã€‚

## ç›®éŒ„
1. [ä¸»è¦æ¨¡å‹æä¾›å•†çš„é…ç½®](#1_ä¸»è¦æ¨¡å‹æä¾›å•†çš„é…ç½®)
2. [é€£çµå„å®¶æ¨¡å‹åŸºæœ¬ç¯„ä¾‹](#2_é€£çµå„å®¶æ¨¡å‹åŸºæœ¬ç¯„ä¾‹)
3. [å°è©±ç®¡ç†ç¯„ä¾‹](#2å°è©±ç®¡ç†ç¯„ä¾‹)
4. [æ›¿ä»£_æ¯”è¼ƒç¯„ä¾‹](#3æ›¿ä»£_æ¯”è¼ƒç¯„ä¾‹)
5. [èˆ‡ä½¿ç”¨è€…äº’å‹•çš„å°è©±ç¯„ä¾‹ï¼ˆå« chat loopï¼‰](#4èˆ‡ä½¿ç”¨è€…äº’å‹•çš„å°è©±ç¯„ä¾‹)
6. [å„²å­˜è¨Šæ¯æ­·å²åˆ° Firebase/Firestore](#5å„²å­˜è¨Šæ¯æ­·å²åˆ°Firebase_Firestore)
---

## 1_ä¸»è¦æ¨¡å‹æä¾›å•†çš„é…ç½®

**å¥—ä»¶å®‰è£**

```bash
langchain-google-genai
langchain-openai
langchain-anthropic
langchain-ollama
```

> ä¸»è¦æ¨¡å‹å•†ç”³è«‹APIç¶²å€
> 1. è©¦ç”¨-[Google AI Studio](./https://aistudio.google.com/)
> 2. éœ€ä»˜è²»-[OpenAI Platform](https://platform.openai.com/docs/overview)->é»é¸å³ä¸Šè§’è¨­å®šå¾Œ,é¸å–å·¦é‚Šæ¬„ä½APIkey
> 3. éœ€ä»˜è²»-[Anthropic console](https://console.anthropic.com/dashboard)->é»é¸å·¦é‚Šçš„API keys
		
**env**

```bash
GOOGLE_API_KEY=XXXXXXXXX
OPENAI_API_KEY=XXXXXXX
ANTHROPIC_API_KEY=XXXXX
```

---

## 2_é€£çµå„å®¶æ¨¡å‹åŸºæœ¬ç¯„ä¾‹
- [1chat_model_basic.ipynb](./1chat_model_basic.ipynb)

ç”¨é€”ï¼šç¤ºç¯„å¦‚ä½•ä½¿ç”¨å¤šå®¶æä¾›è€…çš„ chat modelï¼ˆOpenAI / Anthropic / Google / ollamaï¼‰ä¾†å‘¼å«ä¸¦å–å¾—å›æ‡‰ã€‚

é‡é»ï¼š
- ä»¥ `langchain_openai.ChatOpenAI`ã€`ChatAnthropic`ã€`ChatGoogleGenerativeAI` ç­‰å»ºç«‹æ¨¡å‹ã€‚
- ç¯„ä¾‹ä½¿ç”¨ `SystemMessage` èˆ‡ `HumanMessage` çš„ messages åˆ—è¡¨ä½œç‚ºè¼¸å…¥ã€‚
- ç¤ºç¯„å–®æ¬¡å‘¼å«èˆ‡åœ¨ messages ä¸­åŒ…å«å…ˆå‰ AI å›æ‡‰å†çºŒå•çš„æƒ…å¢ƒã€‚

ä¾è³´ï¼š`python-dotenv`ã€`langchain_openai`ã€`langchain_anthropic`ã€`langchain_google_genai`ã€`langchain_core`ã€‚

åŸ·è¡Œè¦é»ï¼šè¼‰å…¥ `.env` å¾Œï¼Œç”¨é©ç•¶çš„ç’°å¢ƒè®Šæ•¸ï¼ˆAPI key / project configï¼‰å‘¼å« `model.invoke(messages)`ã€‚

### google

- [1chat_model_basic.ipynb](./1chat_model_basic.ipynb)

```python
#google
# Chat Model Documents:https://python.langchain.com/docs/integrations/chat/
# Google Chat Model Documents: https://python.langchain.com/docs/integrations/chat/google_generative_ai/

from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI

# Load environment variables from .env
load_dotenv()

# Create a ChatGoogleGenerativeAI model
model = ChatGoogleGenerativeAI(model="gemini-2.5-flash")

# Invoke the model with a message
result = model.invoke("81é™¤ä»¥9çš„ç­”æ¡ˆæ˜¯?")
print("æ‰€æœ‰ç­”æ¡ˆ")
print(result)
print("å›ç­”å…§å®¹æ˜¯")
print(result.content)
```

### openAI

- [1chat_model_basic.ipynb](./1chat_model_basic.ipynb)

```python
#openapi
# Chat Model Documents:https://python.langchain.com/docs/integrations/chat/
# Google Chat Model Documents:https://python.langchain.com/docs/integrations/chat/openai/ 

from dotenv import load_dotenv
from langchain_openai import ChatOpenAI

# Load environment variables from .env
load_dotenv()

# Create a ChatOpenAI model
model = ChatOpenAI(model="gpt-5-mini")

# Invoke the model with a message
result = model.invoke("81é™¤ä»¥9çš„ç­”æ¡ˆæ˜¯?")
print("æ‰€æœ‰ç­”æ¡ˆ")
print(result)
print("å›ç­”å…§å®¹æ˜¯")
print(result.content)
```

### anthropic api

- [1chat_model_basic.ipynb](./1chat_model_basic.ipynb)

```python
#anthropic api
# Chat Model Documents:https://python.langchain.com/docs/integrations/chat/
# Google Chat Model Documents:https://python.langchain.com/docs/integrations/chat/anthropic/ 

from dotenv import load_dotenv
from langchain_anthropic import ChatAnthropic

# Load environment variables from .env
load_dotenv()

# Create a ChatAnthropic model
model = ChatAnthropic(model="claude-3-5-sonnet-latest")


# Invoke the model with a message
result = model.invoke("81é™¤ä»¥9çš„ç­”æ¡ˆæ˜¯?")
print("æ‰€æœ‰ç­”æ¡ˆ")
print(result)
print("å›ç­”å…§å®¹æ˜¯")
print(result.content)
```

### ollama

- [1chat_model_basic.ipynb](./1chat_model_basic.ipynb)

```python
#ollama api
# Chat Model Documents:https://python.langchain.com/docs/integrations/chat/
# Google Chat Model Documents:https://python.langchain.com/docs/integrations/chat/ollama/


from langchain_ollama import ChatOllama


# Create a ChatOllama model
# é€éç¶²å€çš„æ–¹å¼é€£çµollama (æŒ‡å®š base_url æŒ‡å‘ Ollama server)
# é è¨­ Ollama server åœ¨æœ¬æ©Ÿçš„ 11434 åŸ ï¼Œè‹¥åœ¨å…¶ä»–ä¸»æ©Ÿæˆ–åŸ è«‹æ”¹æˆç›¸å°æ‡‰çš„ç¶²å€

model = ChatOllama(model="llama3.2:latest", base_url="http://host.docker.internal:11434")


# Invoke the model with a message
result = model.invoke("81é™¤ä»¥9çš„ç­”æ¡ˆæ˜¯?")
print("æ‰€æœ‰ç­”æ¡ˆ")
print(result)
print("å›ç­”å…§å®¹æ˜¯")
print(result.content)
```

### ollomaæ•´åˆgradio

- [1ollama_gradio.py](./1ollama_gradio.py)

```python
from langchain_ollama import ChatOllama
import gradio as gr
from dotenv import load_dotenv
import os

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸ï¼ˆå¯ç”¨ OLLAMA_URL / OLLAMA_MODEL è¦†è“‹é è¨­ï¼‰
load_dotenv()
OLLAMA_URL = os.getenv("OLLAMA_URL", "http://host.docker.internal:11434")
MODEL_NAME = os.getenv("OLLAMA_MODEL", "llama3.2:latest")

# ä½¿ç”¨æœ€åŸå§‹çš„å‘¼å«æ–¹å¼ï¼šç›´æ¥ä»¥å­—ä¸² prompt é€åˆ° Ollama
model = ChatOllama(model=MODEL_NAME, base_url=OLLAMA_URL)


def answer(prompt: str) -> str:
    """æœ€ç°¡å–®çš„ wrapperï¼šæŠŠ prompt å‚³çµ¦ model.invokeï¼Œå›å‚³æ–‡å­—å›æ‡‰ã€‚"""
    if not prompt:
        return ""
    res = model.invoke(prompt)
    return res.content if hasattr(res, "content") else str(res)


# æœ€å°çš„ Gradio ä»‹é¢ï¼šä¸€å€‹è¼¸å…¥æ¡† + ä¸€å€‹æ–‡å­—è¼¸å‡º
iface = gr.Interface(
    fn=answer,
    inputs=gr.Textbox(lines=3, placeholder="åœ¨æ­¤è¼¸å…¥å•é¡Œï¼ŒæŒ‰é€å‡º..."),
    outputs="text",
    title="Ollama ç°¡æ˜“ Gradio ç¯„ä¾‹",
    description="ç¤ºç¯„å¦‚ä½•æŠŠåŸå…ˆçš„ Ollama å‘¼å«æ•´åˆåˆ° Gradioã€‚å¯ç”¨ OLLAMA_URL/OLLAMA_MODEL ç’°å¢ƒè®Šæ•¸è¦†è“‹é è¨­ã€‚",
)

if __name__ == "__main__":
    iface.launch(server_name="0.0.0.0", server_port=7860)
```

![](./images/pic1.png)
---

## 2å°è©±ç®¡ç†ç¯„ä¾‹

LangChain èˆ‡ LLMæ¨¡å‹çš„èŠå¤©æ¨¡å‹é€²è¡Œå°è©±,å±•ç¤ºå¦‚ä½•å»ºç«‹åŒ…å«ç³»çµ±è¨Šæ¯ã€äººé¡è¨Šæ¯å’Œ AI è¨Šæ¯çš„å°è©±

### å°è©±ç®¡ç†çš„å¥½è™•ï¼š

1. ğŸ§  ä¸Šä¸‹æ–‡ç†è§£ï¼šAI èƒ½å¤ ç†è§£å°è©±çš„ä¸Šä¸‹æ–‡
2. ğŸ”„ é€£çºŒæ€§ï¼šå°è©±ä¿æŒé€£è²«ï¼Œä¸æœƒæ–·å±¤
3. ğŸ¯ æº–ç¢ºæ€§ï¼šAI çš„å›ç­”æ›´æº–ç¢ºï¼Œå› ç‚ºæœ‰å®Œæ•´èƒŒæ™¯
4. ğŸ’¡ å€‹æ€§åŒ–ï¼šå¯ä»¥è¨˜ä½ç”¨æˆ¶çš„åå¥½å’Œä¹‹å‰çš„äº’å‹•
5. ğŸš€ æ•ˆç‡ï¼šç”¨æˆ¶ä¸éœ€è¦é‡è¤‡è§£é‡‹ç›¸åŒçš„æ¦‚å¿µ

### æŠ€è¡“å¯¦ç¾:

- ä½¿ç”¨ messages åˆ—è¡¨ä¿å­˜å°è©±æ­·å²
- æ¯æ¬¡å°è©±éƒ½å°‡æ–°çš„è¨Šæ¯åŠ å…¥åˆ—è¡¨
- AI æ¨¡å‹èƒ½å¤ çœ‹åˆ°å®Œæ•´çš„å°è©±è„ˆçµ¡

### å¯¦éš›æ‡‰ç”¨å ´æ™¯

- å®¢æœèŠå¤©æ©Ÿå™¨äºº
- æ•™è‚²è¼”åŠ©ç³»çµ±
- å€‹äººåŠ©ç†æ‡‰ç”¨
- ä»»ä½•éœ€è¦é€£çºŒå°è©±çš„ AI ç³»çµ±

---

### ç°¡å–®çš„å°è©±ç®¡ç†

ç¯„ä¾‹æª”:[ç°¡å–®çš„å°è©±ç®¡ç†_gpt-4o](./2.ç°¡å–®çš„å°è©±ç®¡ç†_gpt-4o.ipynb)

ç¯„ä¾‹æª”:[ç°¡å–®çš„å°è©±ç®¡ç†_gemini](./2.ç°¡å–®çš„å°è©±ç®¡ç†_gemini.ipynb)

ç¯„ä¾‹æª”:[ç°¡å–®çš„å°è©±ç®¡ç†_ollama](./2.ç°¡å–®çš„å°è©±ç®¡ç†_ollama.ipynb)

---

### äº†è§£å°è©±ç®¡ç†çš„å¯¦ç”¨æ€§

ç¯„ä¾‹æª”:[å°è©±ç®¡ç†çš„å¯¦ç”¨æ€§_gpt-4o](./2.å°è©±ç®¡ç†çš„å¯¦ç”¨æ€§_gpt-4o.py)

ç¯„ä¾‹æª”[å°è©±ç®¡ç†çš„å¯¦ç”¨æ€§_gemini](./2.å°è©±ç®¡ç†çš„å¯¦ç”¨æ€§_gemini.py)

ç¯„ä¾‹æª”[å°è©±ç®¡ç†çš„å¯¦ç”¨æ€§_ollama](./2.å°è©±ç®¡ç†çš„å¯¦ç”¨æ€§_ollama.py)

[**å°è©±ç®¡ç†çš„å¯¦ç”¨æ€§_è¼¸å‡ºçµæœ**](./å°è©±ç®¡ç†çš„å¯¦ç”¨æ€§_è¼¸å‡ºçµæœ.md)

---


## 3æ›¿ä»£_æ¯”è¼ƒç¯„ä¾‹

### 3_chat_model_alternatives.py
ç”¨é€”ï¼šæ¯”è¼ƒä¸åŒæä¾›è€…çš„çµæœæˆ–ç¤ºç¯„å¦‚ä½•åœ¨ç¨‹å¼ä¸­æ›¿æ›æ¨¡å‹ï¼ˆOpenAIã€Googleã€Ollama ç­‰ï¼‰ã€‚

é‡é»ï¼š
- åŒä¸€å¥— messages æˆ– prompt åŒæ™‚å‘¼å«å¤šå€‹ modelï¼Œä¸¦å°å‡ºå„è‡ªå›æ‡‰ä»¥ä¾¿æ¯”è¼ƒã€‚

ä¾è³´ï¼šè¦–ä½¿ç”¨çš„ provider è€Œå®šï¼ˆåœ¨æª”æ¡ˆä¸­å¯çœ‹åˆ° `ChatGoogleGenerativeAI`ã€`OllamaLLM` ç­‰ï¼‰ã€‚

---

### 3_chat_model_alternatives1.py
ç”¨é€”ï¼šé€²ä¸€æ­¥çš„æ›¿ä»£/æ¯”è¼ƒç¯„ä¾‹ï¼Œç¯„ä¾‹ä¸­å‘¼å« Google èˆ‡ Ollamaï¼Œä¸¦ç¤ºç¯„æŠŠç›¸åŒ messages é€çµ¦ä¸åŒæ¨¡å‹ã€‚

é‡é»ï¼šç”¨æ–¼æ•™å­¸æ¯”è¼ƒå„æ¨¡å‹åœ¨ç›¸åŒ prompt ä¸‹çš„å·®ç•°ã€‚

---

## 4èˆ‡ä½¿ç”¨è€…äº’å‹•çš„å°è©±ç¯„ä¾‹

### 4_chat_model_conversation_with_user.py
ç”¨é€”ï¼šç¤ºç¯„ä¸€å€‹ç°¡å–®çš„ chat loopï¼ˆäº’å‹•å¼ï¼‰ï¼ŒæŒçºŒä¿å­˜ `chat_history`ï¼ˆlistï¼‰ï¼Œä¸¦å°‡å…¶ä½œç‚ºä¸Šä¸‹æ–‡å‚³çµ¦æ¨¡å‹å–å¾—å›è¦†ã€‚

é‡é»ï¼š
- ä½¿ç”¨ `SystemMessage` ä½œç‚ºåˆå§‹æç¤ºï¼ˆä¾‹å¦‚ï¼šYou are a helpful AI assistant.ï¼‰ã€‚
- ä»¥ while è¿´åœˆè®€å–ä½¿ç”¨è€…è¼¸å…¥ï¼Œé€å‡º `chat_history` å‘¼å« `model.invoke(chat_history)`ï¼Œå†æŠŠå›è¦†åŠ å…¥ historyã€‚
- ç¯„ä¾‹åŒ…å«åœæ­¢æ¢ä»¶ï¼ˆè¼¸å…¥ `exit` çµæŸï¼‰ã€‚

ä¾è³´ï¼š`python-dotenv`ã€ç›¸æ‡‰ provider çš„ LangChain wrapperï¼ˆOpenAI / Google / Ollamaï¼‰ã€‚

åŸ·è¡Œè¦é»ï¼šé©åˆåšæœ¬åœ°äº’å‹•æ¸¬è©¦æˆ–æ•™å­¸ç¤ºç¯„ã€‚

---

### 4_chat_model_conversation_with_user_google.py
ç”¨é€”ï¼šåŒ `4_chat_model_conversation_with_user.py`ï¼Œä½†ç¤ºç¯„ä½¿ç”¨ `ChatGoogleGenerativeAI` ä½œç‚ºå¾Œç«¯ã€‚

é‡é»èˆ‡åŸ·è¡Œï¼šç¢ºä¿ Google æˆæ¬Šèˆ‡ model åç¨±æ­£ç¢ºã€‚

---

### 4_chat_model_conversation_with_user_ollama.py
ç”¨é€”ï¼šåŒä¸Šï¼Œä½†ä½¿ç”¨ Ollama LLM ä½œç‚ºäº’å‹•å¼å°è©±å¾Œç«¯ã€‚

é‡é»ï¼šOllama å›å‚³æ ¼å¼å¯èƒ½èˆ‡å…¶ä»– provider ä¸åŒï¼Œç¯„ä¾‹å±•ç¤ºå¦‚ä½•æŠŠå›æ‡‰åŠ å…¥ `chat_history`ã€‚

---

## 5å„²å­˜è¨Šæ¯æ­·å²åˆ°Firebase_Firestore

### 5_chat_model_save_message_history_firebase.py
ç”¨é€”ï¼šç¤ºç¯„å¦‚ä½•æŠŠå°è©±æ­·å²å„²å­˜åˆ° Google Firestoreï¼ˆFirebaseï¼‰ï¼Œä½¿ç”¨ `langchain_google_firestore.FirestoreChatMessageHistory`ã€‚

é‡é»ï¼š
- ç¯„ä¾‹å±•ç¤º Firestore client åˆå§‹åŒ–ã€å»ºç«‹ `FirestoreChatMessageHistory(session_id, collection, client)`ï¼Œä¸¦ç¤ºç¯„å¦‚ä½• `add_user_message` / `add_ai_message`ã€‚
- ç¯„ä¾‹ä¸­åŒ…å«æ­¥é©Ÿèªªæ˜ï¼ˆå»ºç«‹ Firebase å°ˆæ¡ˆã€å•Ÿç”¨ Firestoreã€è¨­å®š Google Cloud CLI èˆ‡èªè­‰ç­‰ï¼‰ã€‚

ä¾è³´ï¼š`python-dotenv`ã€`google-cloud-firestore`ã€`langchain_google_firestore`ã€`langchain_openai`ï¼ˆæˆ–å…¶ä»– chat providerï¼‰ã€‚

åŸ·è¡Œè¦é»ï¼šè«‹å…ˆåœ¨ Google Cloud Console è¨­å®šå¥½å°ˆæ¡ˆèˆ‡èªè­‰ï¼Œä¸¦åœ¨æœ¬æ©Ÿè¨­å®š ADC æˆ– service accountï¼Œå¦å‰‡ç„¡æ³•åˆå§‹åŒ– `firestore.Client`ã€‚

---


