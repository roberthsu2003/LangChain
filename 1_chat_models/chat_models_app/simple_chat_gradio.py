"""
ç°¡åŒ–ç‰ˆ LangChain Chat Models Gradio æ‡‰ç”¨ç¨‹å¼
é©åˆåˆå­¸è€…ä½¿ç”¨çš„ç°¡æ½”ç‰ˆæœ¬
"""

import gradio as gr
import os
from dotenv import load_dotenv
from langchain_core.messages import AIMessage, HumanMessage, SystemMessage
from langchain_ollama import ChatOllama

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

class SimpleChatManager:
    """ç°¡åŒ–çš„èŠå¤©ç®¡ç†å™¨"""
    
    def __init__(self):
        self.model = ChatOllama(model="llama3.2:latest", base_url="http://localhost:11434")
        self.conversation_history = []
        self.system_message = "ä½ æ˜¯ä¸€å€‹å‹å–„ä¸”æ¨‚æ–¼åŠ©äººçš„ AI åŠ©æ‰‹ï¼Œè«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”å•é¡Œã€‚"
    
    def chat(self, user_input: str) -> str:
        """é€²è¡Œå°è©±"""
        if not user_input.strip():
            return "è«‹è¼¸å…¥æ‚¨çš„å•é¡Œ..."
        
        try:
            # å»ºç«‹è¨Šæ¯åˆ—è¡¨
            messages = [SystemMessage(content=self.system_message)]
            
            # æ·»åŠ å°è©±æ­·å²
            for msg in self.conversation_history:
                if msg["role"] == "user":
                    messages.append(HumanMessage(content=msg["content"]))
                elif msg["role"] == "assistant":
                    messages.append(AIMessage(content=msg["content"]))
            
            # æ·»åŠ ç•¶å‰ç”¨æˆ¶è¼¸å…¥
            messages.append(HumanMessage(content=user_input))
            
            # å‘¼å«æ¨¡å‹
            response = self.model.invoke(messages)
            
            # å–å¾—å›æ‡‰å…§å®¹
            if hasattr(response, 'content'):
                ai_response = response.content
            else:
                ai_response = str(response)
            
            # ä¿å­˜å°è©±
            self.conversation_history.append({"role": "user", "content": user_input})
            self.conversation_history.append({"role": "assistant", "content": ai_response})
            
            return ai_response
            
        except Exception as e:
            return f"âŒ ç™¼ç”ŸéŒ¯èª¤: {str(e)}"
    
    def clear_conversation(self):
        """æ¸…é™¤å°è©±æ­·å²"""
        self.conversation_history = []
        return "âœ… å°è©±æ­·å²å·²æ¸…é™¤"

# å»ºç«‹å…¨åŸŸçš„ SimpleChatManager å¯¦ä¾‹
chat_manager = SimpleChatManager()

def chat_function(message: str, history: list) -> tuple:
    """Gradio èŠå¤©å‡½æ•¸"""
    if not message.strip():
        return history, ""
    
    # é€²è¡Œå°è©±
    response = chat_manager.chat(message)
    
    # æ›´æ–° Gradio æ­·å²
    history.append([message, response])
    
    return history, ""

def clear_chat():
    """æ¸…é™¤èŠå¤©"""
    chat_manager.clear_conversation()
    return [], ""

def create_simple_interface():
    """å»ºç«‹ç°¡åŒ–çš„ Gradio ä»‹é¢"""
    
    with gr.Blocks(
        title="ç°¡åŒ–ç‰ˆ LangChain Chat æ‡‰ç”¨ç¨‹å¼",
        theme=gr.themes.Soft()
    ) as interface:
        
        gr.Markdown("""
        # ğŸ¤– ç°¡åŒ–ç‰ˆ LangChain Chat æ‡‰ç”¨ç¨‹å¼
        
        é€™æ˜¯ä¸€å€‹ç°¡æ½”çš„ AI å°è©±ä»‹é¢ï¼Œä½¿ç”¨ Ollama æ¨¡å‹ã€‚
        """)
        
        # èŠå¤©ä»‹é¢
        chatbot = gr.Chatbot(
            label="ğŸ’¬ å°è©±ä»‹é¢",
            height=400,
            show_label=True
        )
        
        with gr.Row():
            msg_input = gr.Textbox(
                placeholder="è«‹è¼¸å…¥æ‚¨çš„å•é¡Œ...",
                label="è¼¸å…¥è¨Šæ¯",
                lines=2,
                scale=4
            )
            send_btn = gr.Button("ğŸ“¤ ç™¼é€", variant="primary", scale=1)
        
        with gr.Row():
            clear_btn = gr.Button("ğŸ—‘ï¸ æ¸…é™¤å°è©±", variant="secondary")
        
        # äº‹ä»¶è™•ç†
        send_btn.click(
            chat_function,
            inputs=[msg_input, chatbot],
            outputs=[chatbot, msg_input]
        )
        
        msg_input.submit(
            chat_function,
            inputs=[msg_input, chatbot],
            outputs=[chatbot, msg_input]
        )
        
        clear_btn.click(
            clear_chat,
            outputs=[chatbot, msg_input]
        )
    
    return interface

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸš€ å•Ÿå‹•ç°¡åŒ–ç‰ˆ LangChain Chat Gradio æ‡‰ç”¨ç¨‹å¼...")
    
    try:
        # æ¸¬è©¦æ¨¡å‹é€£ç·š
        test_response = chat_manager.model.invoke("Hello")
        print("âœ… Ollama æ¨¡å‹é€£ç·šæˆåŠŸ")
    except Exception as e:
        print(f"âŒ Ollama æ¨¡å‹é€£ç·šå¤±æ•—: {e}")
        print("è«‹ç¢ºä¿ Ollama æ­£åœ¨é‹è¡Œæ–¼ http://localhost:11434")
        return
    
    # å»ºç«‹ä¸¦å•Ÿå‹•ä»‹é¢
    interface = create_simple_interface()
    
    print("ğŸŒ å•Ÿå‹• Web ä»‹é¢...")
    interface.launch(
        server_name="0.0.0.0",
        server_port=7861,
        share=False,
        show_error=True
    )

if __name__ == "__main__":
    main()
