"""
æ¸¬è©¦ Gradio æ‡‰ç”¨ç¨‹å¼çš„åŠŸèƒ½
"""

import os
import sys
from dotenv import load_dotenv

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

def test_imports():
    """æ¸¬è©¦æ‰€æœ‰å¿…è¦çš„å¥—ä»¶æ˜¯å¦å¯ä»¥æ­£å¸¸åŒ¯å…¥"""
    print("ğŸ” æ¸¬è©¦å¥—ä»¶åŒ¯å…¥...")
    
    try:
        import gradio as gr
        print("âœ… Gradio åŒ¯å…¥æˆåŠŸ")
    except ImportError as e:
        print(f"âŒ Gradio åŒ¯å…¥å¤±æ•—: {e}")
        return False
    
    try:
        from langchain_core.messages import AIMessage, HumanMessage, SystemMessage
        print("âœ… LangChain Core åŒ¯å…¥æˆåŠŸ")
    except ImportError as e:
        print(f"âŒ LangChain Core åŒ¯å…¥å¤±æ•—: {e}")
        return False
    
    try:
        from langchain_ollama import ChatOllama
        print("âœ… LangChain Ollama åŒ¯å…¥æˆåŠŸ")
    except ImportError as e:
        print(f"âŒ LangChain Ollama åŒ¯å…¥å¤±æ•—: {e}")
        return False
    
    try:
        from langchain_openai import ChatOpenAI
        print("âœ… LangChain OpenAI åŒ¯å…¥æˆåŠŸ")
    except ImportError as e:
        print(f"âŒ LangChain OpenAI åŒ¯å…¥å¤±æ•—: {e}")
        return False
    
    try:
        from langchain_anthropic import ChatAnthropic
        print("âœ… LangChain Anthropic åŒ¯å…¥æˆåŠŸ")
    except ImportError as e:
        print(f"âŒ LangChain Anthropic åŒ¯å…¥å¤±æ•—: {e}")
        return False
    
    try:
        from langchain_google_genai import ChatGoogleGenerativeAI
        print("âœ… LangChain Google GenAI åŒ¯å…¥æˆåŠŸ")
    except ImportError as e:
        print(f"âŒ LangChain Google GenAI åŒ¯å…¥å¤±æ•—: {e}")
        return False
    
    return True

def test_environment_variables():
    """æ¸¬è©¦ç’°å¢ƒè®Šæ•¸è¨­å®š"""
    print("\nğŸ” æ¸¬è©¦ç’°å¢ƒè®Šæ•¸...")
    
    # æª¢æŸ¥ .env æª”æ¡ˆæ˜¯å¦å­˜åœ¨
    env_file = os.path.join(os.path.dirname(__file__), '.env')
    if os.path.exists(env_file):
        print("âœ… .env æª”æ¡ˆå­˜åœ¨")
    else:
        print("âš ï¸ .env æª”æ¡ˆä¸å­˜åœ¨ï¼Œå°‡ä½¿ç”¨ç³»çµ±ç’°å¢ƒè®Šæ•¸")
    
    # æª¢æŸ¥å„å€‹ API é‡‘é‘°
    api_keys = {
        "GOOGLE_API_KEY": os.getenv("GOOGLE_API_KEY"),
        "OPENAI_API_KEY": os.getenv("OPENAI_API_KEY"),
        "ANTHROPIC_API_KEY": os.getenv("ANTHROPIC_API_KEY"),
    }
    
    for key, value in api_keys.items():
        if value:
            print(f"âœ… {key} å·²è¨­å®š")
        else:
            print(f"âš ï¸ {key} æœªè¨­å®š")
    
    # Ollama è¨­å®š
    ollama_url = os.getenv("OLLAMA_URL", "http://localhost:11434")
    ollama_model = os.getenv("OLLAMA_MODEL", "llama3.2:latest")
    print(f"âœ… Ollama URL: {ollama_url}")
    print(f"âœ… Ollama Model: {ollama_model}")
    
    return True

def test_ollama_connection():
    """æ¸¬è©¦ Ollama é€£ç·š"""
    print("\nğŸ” æ¸¬è©¦ Ollama é€£ç·š...")
    
    try:
        from langchain_ollama import ChatOllama
        
        ollama_url = os.getenv("OLLAMA_URL", "http://localhost:11434")
        ollama_model = os.getenv("OLLAMA_MODEL", "llama3.2:latest")
        
        model = ChatOllama(model=ollama_model, base_url=ollama_url)
        
        # æ¸¬è©¦ç°¡å–®çš„å‘¼å«
        response = model.invoke("Hello")
        
        if hasattr(response, 'content'):
            print(f"âœ… Ollama é€£ç·šæˆåŠŸï¼Œå›æ‡‰: {response.content[:50]}...")
        else:
            print(f"âœ… Ollama é€£ç·šæˆåŠŸï¼Œå›æ‡‰: {str(response)[:50]}...")
        
        return True
        
    except Exception as e:
        print(f"âŒ Ollama é€£ç·šå¤±æ•—: {e}")
        print("ğŸ’¡ è«‹ç¢ºä¿ Ollama æ­£åœ¨é‹è¡Œï¼šollama serve")
        return False

def test_chat_manager():
    """æ¸¬è©¦ ChatManager é¡åˆ¥"""
    print("\nğŸ” æ¸¬è©¦ ChatManager é¡åˆ¥...")
    
    try:
        # åŒ¯å…¥ ChatModelsManager
        sys.path.append(os.path.dirname(__file__))
        from chat_models_gradio_app import ChatModelsManager
        
        # å»ºç«‹å¯¦ä¾‹
        chat_manager = ChatModelsManager()
        
        # æ¸¬è©¦å¯ç”¨æ¨¡å‹
        available_models = chat_manager.get_available_models()
        print(f"âœ… æ‰¾åˆ° {len(available_models)} å€‹å¯ç”¨æ¨¡å‹:")
        for model in available_models:
            print(f"   - {model}")
        
        # æ¸¬è©¦å°è©±åŠŸèƒ½
        if available_models:
            response = chat_manager.chat("Hello, how are you?", available_models[0])
            print(f"âœ… å°è©±æ¸¬è©¦æˆåŠŸï¼Œå›æ‡‰: {response[:50]}...")
        
        return True
        
    except Exception as e:
        print(f"âŒ ChatManager æ¸¬è©¦å¤±æ•—: {e}")
        return False

def test_simple_chat_manager():
    """æ¸¬è©¦ SimpleChatManager é¡åˆ¥"""
    print("\nğŸ” æ¸¬è©¦ SimpleChatManager é¡åˆ¥...")
    
    try:
        # åŒ¯å…¥ SimpleChatManager
        sys.path.append(os.path.dirname(__file__))
        from simple_chat_gradio import SimpleChatManager
        
        # å»ºç«‹å¯¦ä¾‹
        chat_manager = SimpleChatManager()
        
        # æ¸¬è©¦å°è©±åŠŸèƒ½
        response = chat_manager.chat("Hello, how are you?")
        print(f"âœ… ç°¡åŒ–ç‰ˆå°è©±æ¸¬è©¦æˆåŠŸï¼Œå›æ‡‰: {response[:50]}...")
        
        return True
        
    except Exception as e:
        print(f"âŒ SimpleChatManager æ¸¬è©¦å¤±æ•—: {e}")
        return False

def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    print("ğŸš€ é–‹å§‹æ¸¬è©¦ LangChain Chat Models Gradio æ‡‰ç”¨ç¨‹å¼")
    print("=" * 60)
    
    tests = [
        ("å¥—ä»¶åŒ¯å…¥", test_imports),
        ("ç’°å¢ƒè®Šæ•¸", test_environment_variables),
        ("Ollama é€£ç·š", test_ollama_connection),
        ("ChatManager", test_chat_manager),
        ("SimpleChatManager", test_simple_chat_manager),
    ]
    
    results = []
    
    for test_name, test_func in tests:
        try:
            result = test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"âŒ {test_name} æ¸¬è©¦ç™¼ç”Ÿç•°å¸¸: {e}")
            results.append((test_name, False))
    
    # é¡¯ç¤ºæ¸¬è©¦çµæœ
    print("\n" + "=" * 60)
    print("ğŸ“Š æ¸¬è©¦çµæœç¸½çµ")
    print("=" * 60)
    
    passed = 0
    total = len(results)
    
    for test_name, result in results:
        status = "âœ… é€šé" if result else "âŒ å¤±æ•—"
        print(f"{test_name}: {status}")
        if result:
            passed += 1
    
    print(f"\nç¸½è¨ˆ: {passed}/{total} æ¸¬è©¦é€šé")
    
    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æ¸¬è©¦éƒ½é€šéäº†ï¼æ‚¨å¯ä»¥åŸ·è¡Œæ‡‰ç”¨ç¨‹å¼äº†ã€‚")
        print("\nåŸ·è¡ŒæŒ‡ä»¤:")
        print("  uv run python chat_models_gradio_app.py  # å®Œæ•´ç‰ˆ")
        print("  uv run python simple_chat_gradio.py      # ç°¡åŒ–ç‰ˆ")
        print("\næˆ–ä½¿ç”¨å‚³çµ±æ–¹å¼:")
        print("  source .venv/bin/activate")
        print("  python chat_models_gradio_app.py")
    else:
        print(f"\nâš ï¸ æœ‰ {total - passed} å€‹æ¸¬è©¦å¤±æ•—ï¼Œè«‹æª¢æŸ¥ç›¸é—œè¨­å®šã€‚")
    
    return passed == total

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
