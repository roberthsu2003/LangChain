{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fc39815",
   "metadata": {},
   "source": [
    "# Prompt Template 完整範例：專業翻譯工具 (配合 Ollama)\n",
    "\n",
    "這個範例將展示如何使用 LangChain 的 Prompt Template 配合 Ollama 模型建立一個專業的翻譯工具，包含：\n",
    "\n",
    "1. **基本 Prompt Template 使用**\n",
    "2. **多變數的複雜模板**\n",
    "3. **與 Ollama Chat Model 整合**\n",
    "4. **實際應用場景**\n",
    "5. **真實的翻譯結果**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4d2279c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Ollama 模型設定完成 ===\n",
      "使用模型: llama3.2:latest\n",
      "模型類型: <class 'langchain_ollama.llms.OllamaLLM'>\n"
     ]
    }
   ],
   "source": [
    "# 1. 設定 Ollama 模型\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# 建立一個 ollama 模型\n",
    "model = OllamaLLM(model=\"llama3.2:latest\")\n",
    "\n",
    "print(\"=== Ollama 模型設定完成 ===\")\n",
    "print(f\"使用模型: llama3.2:latest\")\n",
    "print(f\"模型類型: {type(model)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb70ee41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 基本 Prompt Template 範例 (配合 Ollama) ===\n",
      "輸入的提示詞：\n",
      "\n",
      "你是一位專業的繁體中文翻譯家，具有豐富的語言學背景。\n",
      "請將使用者提供的以下英文句子翻譯成流暢、自然的繁體中文。\n",
      "\n",
      "英文句子：Hello, how are you?\n",
      "繁體中文翻譯：\n",
      "\n",
      "\n",
      "==================================================\n",
      "Ollama 模型回應：\n",
      "问候，你好吗？\n"
     ]
    }
   ],
   "source": [
    "# 2. 基本 Prompt Template 使用 (配合 Ollama)\n",
    "# 建立翻譯模板\n",
    "template_text = \"\"\"\n",
    "你是一位專業的繁體中文翻譯家，具有豐富的語言學背景。\n",
    "請將使用者提供的以下英文句子翻譯成流暢、自然的繁體中文。\n",
    "\n",
    "英文句子：{english_sentence}\n",
    "繁體中文翻譯：\n",
    "\"\"\"\n",
    "\n",
    "# 建立 Prompt Template\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"english_sentence\"],\n",
    "    template=template_text\n",
    ")\n",
    "\n",
    "# 使用模板並透過 Ollama 模型進行翻譯\n",
    "english_text = \"Hello, how are you?\"\n",
    "formatted_prompt = prompt_template.format(english_sentence=english_text)\n",
    "\n",
    "print(\"=== 基本 Prompt Template 範例 (配合 Ollama) ===\")\n",
    "print(\"輸入的提示詞：\")\n",
    "print(formatted_prompt)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Ollama 模型回應：\")\n",
    "\n",
    "# 透過 Ollama 模型進行翻譯\n",
    "try:\n",
    "    response = model.invoke(formatted_prompt)\n",
    "    print(response)\n",
    "except Exception as e:\n",
    "    print(f\"模型調用錯誤: {e}\")\n",
    "    print(\"請確保 Ollama 服務正在運行，並且已安裝 llama3.2:latest 模型\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7cc7f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 多變數複雜模板範例 (配合 Ollama) ===\n",
      "輸入的提示詞：\n",
      "Human: \n",
      "你是一位專業的繁體中文翻譯家，專精於商業領域。\n",
      "請將以下英文文本翻譯成繁體中文，並確保：\n",
      "1. 保持原文的語氣和風格\n",
      "2. 使用專業術語\n",
      "3. 符合繁體中文的語言習慣\n",
      "\n",
      "英文文本：The quarterly revenue increased by 15% compared to last year.\n",
      "繁體中文翻譯：\n",
      "\n",
      "\n",
      "==================================================\n",
      "Ollama 模型回應：\n",
      "我是一位專業的繁體中文翻譯家，專精於商業領域。\n",
      "\n",
      "以下是英文文本的繁體中文翻譯：\n",
      "\n",
      "季度毛利增加了15%，與去年相比。\n"
     ]
    }
   ],
   "source": [
    "# 3. 多變數的複雜模板 (配合 Ollama)\n",
    "# 建立多變數的翻譯模板\n",
    "complex_template = \"\"\"\n",
    "你是一位專業的{target_language}翻譯家，專精於{domain}領域。\n",
    "請將以下{source_language}文本翻譯成{target_language}，並確保：\n",
    "1. 保持原文的語氣和風格\n",
    "2. 使用專業術語\n",
    "3. 符合{target_language}的語言習慣\n",
    "\n",
    "{source_language}文本：{text}\n",
    "{target_language}翻譯：\n",
    "\"\"\"\n",
    "\n",
    "# 建立 ChatPromptTemplate\n",
    "chat_prompt_template = ChatPromptTemplate.from_template(complex_template)\n",
    "\n",
    "# 使用多個變數\n",
    "formatted_prompt = chat_prompt_template.format(\n",
    "    source_language=\"英文\",\n",
    "    target_language=\"繁體中文\", \n",
    "    domain=\"商業\",\n",
    "    text=\"The quarterly revenue increased by 15% compared to last year.\"\n",
    ")\n",
    "\n",
    "print(\"=== 多變數複雜模板範例 (配合 Ollama) ===\")\n",
    "print(\"輸入的提示詞：\")\n",
    "print(formatted_prompt)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Ollama 模型回應：\")\n",
    "\n",
    "# 透過 Ollama 模型進行翻譯\n",
    "try:\n",
    "    response = model.invoke(formatted_prompt)\n",
    "    print(response)\n",
    "except Exception as e:\n",
    "    print(f\"模型調用錯誤: {e}\")\n",
    "    print(\"請確保 Ollama 服務正在運行，並且已安裝 llama3.2:latest 模型\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "beab213e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 結構化模板範例 (配合 Ollama) ===\n",
      "輸入的提示詞：\n",
      "System: 你是一位專業的法律翻譯家，具有10年的翻譯經驗。\n",
      "Human: 請將以下英文文本翻譯成繁體中文：\\n\\nThe defendant is hereby ordered to pay damages in the amount of $50,000.\n",
      "\n",
      "==================================================\n",
      "Ollama 模型回應：\n",
      "請允許我幫您翻譯以下英文文本：\n",
      "\n",
      "原文：The defendant is hereby ordered to pay damages in the amount of $50,000。\n",
      "\n",
      "翻譯後：被告已經由法庭命令，應繳付 damages 50,000 美元。\n"
     ]
    }
   ],
   "source": [
    "# 4. 使用系統與人類訊息的結構化模板 (配合 Ollama)\n",
    "# 方法一：使用 Tuple 格式\n",
    "messages = [\n",
    "    (\"system\", \"你是一位專業的{domain}翻譯家，具有{experience}年的翻譯經驗。\"),\n",
    "    (\"human\", \"請將以下{source_language}文本翻譯成{target_language}：\\\\n\\\\n{text}\"),\n",
    "]\n",
    "\n",
    "structured_template = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "# 使用結構化模板\n",
    "formatted_prompt = structured_template.format(\n",
    "    domain=\"法律\",\n",
    "    experience=\"10\",\n",
    "    source_language=\"英文\",\n",
    "    target_language=\"繁體中文\",\n",
    "    text=\"The defendant is hereby ordered to pay damages in the amount of $50,000.\"\n",
    ")\n",
    "\n",
    "print(\"=== 結構化模板範例 (配合 Ollama) ===\")\n",
    "print(\"輸入的提示詞：\")\n",
    "print(formatted_prompt)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Ollama 模型回應：\")\n",
    "\n",
    "# 透過 Ollama 模型進行翻譯\n",
    "try:\n",
    "    response = model.invoke(formatted_prompt)\n",
    "    print(response)\n",
    "except Exception as e:\n",
    "    print(f\"模型調用錯誤: {e}\")\n",
    "    print(\"請確保 Ollama 服務正在運行，並且已安裝 llama3.2:latest 模型\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0b5d69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 翻譯工具實際應用範例 (配合 Ollama) ===\n",
      "\n",
      "【一般翻譯】\n",
      "原文: Welcome to our company. We are excited to work with you.\n",
      "翻譯結果:\n",
      "歡迎來到我們的公司。 我們很高興與您合作。\n",
      "\n",
      "==================================================\n",
      "\n",
      "【商業翻譯】\n",
      "原文: The contract will be effective from January 1st, 2024, and will expire on December 31st, 2024.\n",
      "翻譯結果:\n",
      "以下是英文商業文本的繁體中文翻譯：\n",
      "\n",
      "根據合同的條款，合同自2024年1月1日起生效，到2024年12月31日止。\n",
      "\n",
      "注意：合同的有效期從2024年1月1日開始，到2024年12月31日止。\n",
      "\n",
      "==================================================\n",
      "\n",
      "【技術翻譯】\n",
      "原文: The API endpoint returns a JSON response with user authentication tokens.\n",
      "翻譯結果:\n",
      "你是一位專業的技術翻譯家，專精於網路開發領域。\n",
      "\n",
      "以下是英文原文的中文翻译：\n",
      "\n",
      "API端點返回一個 JSON 回應，其中包含用戶身份 Tokens。\n",
      "\n",
      "注意：\n",
      "\n",
      "* 我們保證了技術術語的準確性，以使翻譯結果更為可靠。\n",
      "* 我們保持了技術文檔的清晰度，使用簡潔的句子和正確的詞彙來表達主題。\n",
      "* 我們也遵循了技術寫作規範，採用正確的語法、詞選和符號，用以創造清晰和可理解的文檔。\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# 5. 實際應用：建立翻譯工具類別 (配合 Ollama)\n",
    "class TranslationTool:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        # 建立不同領域的翻譯模板\n",
    "        self.templates = {\n",
    "            \"general\": ChatPromptTemplate.from_template(\"\"\"\n",
    "你是一位專業的翻譯家。\n",
    "請將以下{source_language}文本翻譯成{target_language}：\n",
    "\n",
    "{text}\n",
    "\"\"\"),\n",
    "            \n",
    "            \"business\": ChatPromptTemplate.from_template(\"\"\"\n",
    "你是一位專業的商業翻譯家，專精於商業文件和合約翻譯。\n",
    "請將以下{source_language}商業文本翻譯成{target_language}，確保：\n",
    "1. 保持專業術語的準確性\n",
    "2. 符合商業文件的正式語氣\n",
    "3. 保持數字的精確性\n",
    "\n",
    "{text}\n",
    "\"\"\"),\n",
    "            \n",
    "            \"technical\": ChatPromptTemplate.from_template(\"\"\"\n",
    "你是一位專業的技術翻譯家，專精於{domain}領域。\n",
    "請將以下{source_language}技術文本翻譯成{target_language}，確保：\n",
    "1. 技術術語的準確性\n",
    "2. 保持技術文檔的清晰度\n",
    "3. 符合技術寫作規範\n",
    "\n",
    "{text}\n",
    "\"\"\")\n",
    "        }\n",
    "    \n",
    "    def translate(self, text, source_lang=\"英文\", target_lang=\"繁體中文\", \n",
    "                 domain=\"general\", tech_domain=\"軟體開發\"):\n",
    "        \"\"\"執行翻譯\"\"\"\n",
    "        if domain == \"technical\":\n",
    "            template = self.templates[\"technical\"]\n",
    "            prompt = template.format(\n",
    "                source_language=source_lang,\n",
    "                target_language=target_lang,\n",
    "                domain=tech_domain,\n",
    "                text=text\n",
    "            )\n",
    "        else:\n",
    "            template = self.templates[domain]\n",
    "            prompt = template.format(\n",
    "                source_language=source_lang,\n",
    "                target_language=target_lang,\n",
    "                text=text\n",
    "            )\n",
    "        \n",
    "        # 透過 Ollama 模型進行翻譯\n",
    "        try:\n",
    "            response = self.model.invoke(prompt)\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            return f\"翻譯錯誤: {e}\"\n",
    "\n",
    "# 建立翻譯工具實例\n",
    "translator = TranslationTool(model)\n",
    "\n",
    "print(\"=== 翻譯工具實際應用範例 (配合 Ollama) ===\")\n",
    "\n",
    "# 測試不同類型的翻譯\n",
    "test_cases = [\n",
    "    {\n",
    "        \"text\": \"Welcome to our company. We are excited to work with you.\",\n",
    "        \"domain\": \"general\",\n",
    "        \"title\": \"【一般翻譯】\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"The contract will be effective from January 1st, 2024, and will expire on December 31st, 2024.\",\n",
    "        \"domain\": \"business\", \n",
    "        \"title\": \"【商業翻譯】\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"The API endpoint returns a JSON response with user authentication tokens.\",\n",
    "        \"domain\": \"technical\",\n",
    "        \"tech_domain\": \"網路開發\",\n",
    "        \"title\": \"【技術翻譯】\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for case in test_cases:\n",
    "    print(f\"\\n{case['title']}\")\n",
    "    print(\"原文:\", case['text'])\n",
    "    print(\"翻譯結果:\")\n",
    "    \n",
    "    if case['domain'] == \"technical\":\n",
    "        result = translator.translate(\n",
    "            case['text'],\n",
    "            domain=case['domain'],\n",
    "            tech_domain=case['tech_domain']\n",
    "        )\n",
    "    else:\n",
    "        result = translator.translate(\n",
    "            case['text'],\n",
    "            domain=case['domain']\n",
    "        )\n",
    "    \n",
    "    print(result)\n",
    "    print(\"\\n\" + \"=\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30da64a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Few-shot Learning 模板範例 (配合 Ollama) ===\n",
      "輸入的提示詞：\n",
      "System: 你是一位專業的英文到繁體中文翻譯家。請根據以下範例，將使用者的英文句子翻譯成自然流暢的繁體中文。\n",
      "Human: Hello, how are you?\n",
      "AI: 你好，你好嗎？\n",
      "Human: Thank you very much for your help.\n",
      "AI: 非常感謝你的幫助。\n",
      "Human: I would like to order a coffee, please.\n",
      "AI: 我想要點一杯咖啡，麻煩了。\n",
      "Human: 請翻譯：Good morning, have a great day!\n",
      "\n",
      "==================================================\n",
      "Ollama 模型回應：\n",
      "我可以幫你翻譯成繁體中文：\n",
      "\n",
      "人類：早上好，祝你一天都很好！\n",
      "機器人：早上好，你好嗎？\n"
     ]
    }
   ],
   "source": [
    "# 6. 進階範例：Few-shot Learning 模板 (配合 Ollama)\n",
    "from langchain.prompts import FewShotChatMessagePromptTemplate\n",
    "\n",
    "# 定義範例\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"Hello, how are you?\",\n",
    "        \"output\": \"你好，你好嗎？\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Thank you very much for your help.\",\n",
    "        \"output\": \"非常感謝你的幫助。\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"I would like to order a coffee, please.\",\n",
    "        \"output\": \"我想要點一杯咖啡，麻煩了。\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 建立範例模板\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"ai\", \"{output}\")\n",
    "])\n",
    "\n",
    "# 建立 Few-shot 模板\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples\n",
    ")\n",
    "\n",
    "# 建立最終的提示模板\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一位專業的英文到繁體中文翻譯家。請根據以下範例，將使用者的英文句子翻譯成自然流暢的繁體中文。\"),\n",
    "    few_shot_prompt,\n",
    "    (\"human\", \"請翻譯：{input}\")\n",
    "])\n",
    "\n",
    "# 使用 Few-shot 模板\n",
    "input_text = \"Good morning, have a great day!\"\n",
    "formatted_prompt = final_prompt.format(input=input_text)\n",
    "\n",
    "print(\"=== Few-shot Learning 模板範例 (配合 Ollama) ===\")\n",
    "print(\"輸入的提示詞：\")\n",
    "print(formatted_prompt)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Ollama 模型回應：\")\n",
    "\n",
    "# 透過 Ollama 模型進行翻譯\n",
    "try:\n",
    "    response = model.invoke(formatted_prompt)\n",
    "    print(response)\n",
    "except Exception as e:\n",
    "    print(f\"模型調用錯誤: {e}\")\n",
    "    print(\"請確保 Ollama 服務正在運行，並且已安裝 llama3.2:latest 模型\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b053c7a",
   "metadata": {},
   "source": [
    "## 📝 總結\n",
    "\n",
    "這個完整的範例展示了 Prompt Template 配合 Ollama 模型的各種使用方式：\n",
    "\n",
    "### 🎯 **核心概念**\n",
    "- **PromptTemplate**: 基本的文字模板，適合簡單的單變數替換\n",
    "- **ChatPromptTemplate**: 適合與 Chat Model 整合的結構化模板\n",
    "- **FewShotChatMessagePromptTemplate**: 支援範例學習的進階模板\n",
    "- **OllamaLLM**: 本地運行的開源大語言模型\n",
    "\n",
    "### 🔧 **實際應用場景**\n",
    "1. **翻譯工具**: 不同領域的專業翻譯，現在可以獲得真實的翻譯結果\n",
    "2. **內容生成**: 結構化的內容創作\n",
    "3. **問答系統**: 標準化的問題處理\n",
    "4. **客服機器人**: 統一的回應格式\n",
    "\n",
    "### 💡 **最佳實踐**\n",
    "- 使用清晰的變數名稱\n",
    "- 提供具體的指令和上下文\n",
    "- 根據不同場景選擇合適的模板類型\n",
    "- 利用 Few-shot learning 提升模型表現\n",
    "- 加入錯誤處理機制確保程式穩定性\n",
    "\n",
    "### 🚀 **Ollama 整合優勢**\n",
    "- **本地運行**: 資料隱私性高，無需網路連線\n",
    "- **開源模型**: 可自由選擇和調整模型\n",
    "- **成本效益**: 無需付費 API 調用\n",
    "- **即時回應**: 本地處理速度快\n",
    "\n",
    "### ⚠️ **注意事項**\n",
    "- 確保 Ollama 服務正在運行\n",
    "- 已安裝所需的模型 (llama3.2:latest)\n",
    "- 本地硬體資源充足以支援模型運行\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
