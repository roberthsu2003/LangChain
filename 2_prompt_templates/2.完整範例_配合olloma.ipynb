{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fc39815",
   "metadata": {},
   "source": [
    "# Prompt Template å®Œæ•´ç¯„ä¾‹ï¼šå°ˆæ¥­ç¿»è­¯å·¥å…· (é…åˆ Ollama)\n",
    "\n",
    "é€™å€‹ç¯„ä¾‹å°‡å±•ç¤ºå¦‚ä½•ä½¿ç”¨ LangChain çš„ Prompt Template é…åˆ Ollama æ¨¡å‹å»ºç«‹ä¸€å€‹å°ˆæ¥­çš„ç¿»è­¯å·¥å…·ï¼ŒåŒ…å«ï¼š\n",
    "\n",
    "1. **åŸºæœ¬ Prompt Template ä½¿ç”¨**\n",
    "2. **å¤šè®Šæ•¸çš„è¤‡é›œæ¨¡æ¿**\n",
    "3. **èˆ‡ Ollama Chat Model æ•´åˆ**\n",
    "4. **å¯¦éš›æ‡‰ç”¨å ´æ™¯**\n",
    "5. **çœŸå¯¦çš„ç¿»è­¯çµæœ**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4d2279c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Ollama æ¨¡å‹è¨­å®šå®Œæˆ ===\n",
      "ä½¿ç”¨æ¨¡å‹: llama3.2:latest\n",
      "æ¨¡å‹é¡å‹: <class 'langchain_ollama.llms.OllamaLLM'>\n"
     ]
    }
   ],
   "source": [
    "# 1. è¨­å®š Ollama æ¨¡å‹\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# å»ºç«‹ä¸€å€‹ ollama æ¨¡å‹\n",
    "model = OllamaLLM(model=\"llama3.2:latest\")\n",
    "\n",
    "print(\"=== Ollama æ¨¡å‹è¨­å®šå®Œæˆ ===\")\n",
    "print(f\"ä½¿ç”¨æ¨¡å‹: llama3.2:latest\")\n",
    "print(f\"æ¨¡å‹é¡å‹: {type(model)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb70ee41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== åŸºæœ¬ Prompt Template ç¯„ä¾‹ (é…åˆ Ollama) ===\n",
      "è¼¸å…¥çš„æç¤ºè©ï¼š\n",
      "\n",
      "ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„ç¹é«”ä¸­æ–‡ç¿»è­¯å®¶ï¼Œå…·æœ‰è±å¯Œçš„èªè¨€å­¸èƒŒæ™¯ã€‚\n",
      "è«‹å°‡ä½¿ç”¨è€…æä¾›çš„ä»¥ä¸‹è‹±æ–‡å¥å­ç¿»è­¯æˆæµæš¢ã€è‡ªç„¶çš„ç¹é«”ä¸­æ–‡ã€‚\n",
      "\n",
      "è‹±æ–‡å¥å­ï¼šHello, how are you?\n",
      "ç¹é«”ä¸­æ–‡ç¿»è­¯ï¼š\n",
      "\n",
      "\n",
      "==================================================\n",
      "Ollama æ¨¡å‹å›æ‡‰ï¼š\n",
      "é—®å€™ï¼Œä½ å¥½å—ï¼Ÿ\n"
     ]
    }
   ],
   "source": [
    "# 2. åŸºæœ¬ Prompt Template ä½¿ç”¨ (é…åˆ Ollama)\n",
    "# å»ºç«‹ç¿»è­¯æ¨¡æ¿\n",
    "template_text = \"\"\"\n",
    "ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„ç¹é«”ä¸­æ–‡ç¿»è­¯å®¶ï¼Œå…·æœ‰è±å¯Œçš„èªè¨€å­¸èƒŒæ™¯ã€‚\n",
    "è«‹å°‡ä½¿ç”¨è€…æä¾›çš„ä»¥ä¸‹è‹±æ–‡å¥å­ç¿»è­¯æˆæµæš¢ã€è‡ªç„¶çš„ç¹é«”ä¸­æ–‡ã€‚\n",
    "\n",
    "è‹±æ–‡å¥å­ï¼š{english_sentence}\n",
    "ç¹é«”ä¸­æ–‡ç¿»è­¯ï¼š\n",
    "\"\"\"\n",
    "\n",
    "# å»ºç«‹ Prompt Template\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"english_sentence\"],\n",
    "    template=template_text\n",
    ")\n",
    "\n",
    "# ä½¿ç”¨æ¨¡æ¿ä¸¦é€é Ollama æ¨¡å‹é€²è¡Œç¿»è­¯\n",
    "english_text = \"Hello, how are you?\"\n",
    "formatted_prompt = prompt_template.format(english_sentence=english_text)\n",
    "\n",
    "print(\"=== åŸºæœ¬ Prompt Template ç¯„ä¾‹ (é…åˆ Ollama) ===\")\n",
    "print(\"è¼¸å…¥çš„æç¤ºè©ï¼š\")\n",
    "print(formatted_prompt)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Ollama æ¨¡å‹å›æ‡‰ï¼š\")\n",
    "\n",
    "# é€é Ollama æ¨¡å‹é€²è¡Œç¿»è­¯\n",
    "try:\n",
    "    response = model.invoke(formatted_prompt)\n",
    "    print(response)\n",
    "except Exception as e:\n",
    "    print(f\"æ¨¡å‹èª¿ç”¨éŒ¯èª¤: {e}\")\n",
    "    print(\"è«‹ç¢ºä¿ Ollama æœå‹™æ­£åœ¨é‹è¡Œï¼Œä¸¦ä¸”å·²å®‰è£ llama3.2:latest æ¨¡å‹\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7cc7f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== å¤šè®Šæ•¸è¤‡é›œæ¨¡æ¿ç¯„ä¾‹ (é…åˆ Ollama) ===\n",
      "è¼¸å…¥çš„æç¤ºè©ï¼š\n",
      "Human: \n",
      "ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„ç¹é«”ä¸­æ–‡ç¿»è­¯å®¶ï¼Œå°ˆç²¾æ–¼å•†æ¥­é ˜åŸŸã€‚\n",
      "è«‹å°‡ä»¥ä¸‹è‹±æ–‡æ–‡æœ¬ç¿»è­¯æˆç¹é«”ä¸­æ–‡ï¼Œä¸¦ç¢ºä¿ï¼š\n",
      "1. ä¿æŒåŸæ–‡çš„èªæ°£å’Œé¢¨æ ¼\n",
      "2. ä½¿ç”¨å°ˆæ¥­è¡“èª\n",
      "3. ç¬¦åˆç¹é«”ä¸­æ–‡çš„èªè¨€ç¿’æ…£\n",
      "\n",
      "è‹±æ–‡æ–‡æœ¬ï¼šThe quarterly revenue increased by 15% compared to last year.\n",
      "ç¹é«”ä¸­æ–‡ç¿»è­¯ï¼š\n",
      "\n",
      "\n",
      "==================================================\n",
      "Ollama æ¨¡å‹å›æ‡‰ï¼š\n",
      "æˆ‘æ˜¯ä¸€ä½å°ˆæ¥­çš„ç¹é«”ä¸­æ–‡ç¿»è­¯å®¶ï¼Œå°ˆç²¾æ–¼å•†æ¥­é ˜åŸŸã€‚\n",
      "\n",
      "ä»¥ä¸‹æ˜¯è‹±æ–‡æ–‡æœ¬çš„ç¹é«”ä¸­æ–‡ç¿»è­¯ï¼š\n",
      "\n",
      "å­£åº¦æ¯›åˆ©å¢åŠ äº†15%ï¼Œèˆ‡å»å¹´ç›¸æ¯”ã€‚\n"
     ]
    }
   ],
   "source": [
    "# 3. å¤šè®Šæ•¸çš„è¤‡é›œæ¨¡æ¿ (é…åˆ Ollama)\n",
    "# å»ºç«‹å¤šè®Šæ•¸çš„ç¿»è­¯æ¨¡æ¿\n",
    "complex_template = \"\"\"\n",
    "ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„{target_language}ç¿»è­¯å®¶ï¼Œå°ˆç²¾æ–¼{domain}é ˜åŸŸã€‚\n",
    "è«‹å°‡ä»¥ä¸‹{source_language}æ–‡æœ¬ç¿»è­¯æˆ{target_language}ï¼Œä¸¦ç¢ºä¿ï¼š\n",
    "1. ä¿æŒåŸæ–‡çš„èªæ°£å’Œé¢¨æ ¼\n",
    "2. ä½¿ç”¨å°ˆæ¥­è¡“èª\n",
    "3. ç¬¦åˆ{target_language}çš„èªè¨€ç¿’æ…£\n",
    "\n",
    "{source_language}æ–‡æœ¬ï¼š{text}\n",
    "{target_language}ç¿»è­¯ï¼š\n",
    "\"\"\"\n",
    "\n",
    "# å»ºç«‹ ChatPromptTemplate\n",
    "chat_prompt_template = ChatPromptTemplate.from_template(complex_template)\n",
    "\n",
    "# ä½¿ç”¨å¤šå€‹è®Šæ•¸\n",
    "formatted_prompt = chat_prompt_template.format(\n",
    "    source_language=\"è‹±æ–‡\",\n",
    "    target_language=\"ç¹é«”ä¸­æ–‡\", \n",
    "    domain=\"å•†æ¥­\",\n",
    "    text=\"The quarterly revenue increased by 15% compared to last year.\"\n",
    ")\n",
    "\n",
    "print(\"=== å¤šè®Šæ•¸è¤‡é›œæ¨¡æ¿ç¯„ä¾‹ (é…åˆ Ollama) ===\")\n",
    "print(\"è¼¸å…¥çš„æç¤ºè©ï¼š\")\n",
    "print(formatted_prompt)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Ollama æ¨¡å‹å›æ‡‰ï¼š\")\n",
    "\n",
    "# é€é Ollama æ¨¡å‹é€²è¡Œç¿»è­¯\n",
    "try:\n",
    "    response = model.invoke(formatted_prompt)\n",
    "    print(response)\n",
    "except Exception as e:\n",
    "    print(f\"æ¨¡å‹èª¿ç”¨éŒ¯èª¤: {e}\")\n",
    "    print(\"è«‹ç¢ºä¿ Ollama æœå‹™æ­£åœ¨é‹è¡Œï¼Œä¸¦ä¸”å·²å®‰è£ llama3.2:latest æ¨¡å‹\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "beab213e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== çµæ§‹åŒ–æ¨¡æ¿ç¯„ä¾‹ (é…åˆ Ollama) ===\n",
      "è¼¸å…¥çš„æç¤ºè©ï¼š\n",
      "System: ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„æ³•å¾‹ç¿»è­¯å®¶ï¼Œå…·æœ‰10å¹´çš„ç¿»è­¯ç¶“é©—ã€‚\n",
      "Human: è«‹å°‡ä»¥ä¸‹è‹±æ–‡æ–‡æœ¬ç¿»è­¯æˆç¹é«”ä¸­æ–‡ï¼š\\n\\nThe defendant is hereby ordered to pay damages in the amount of $50,000.\n",
      "\n",
      "==================================================\n",
      "Ollama æ¨¡å‹å›æ‡‰ï¼š\n",
      "è«‹å…è¨±æˆ‘å¹«æ‚¨ç¿»è­¯ä»¥ä¸‹è‹±æ–‡æ–‡æœ¬ï¼š\n",
      "\n",
      "åŸæ–‡ï¼šThe defendant is hereby ordered to pay damages in the amount of $50,000ã€‚\n",
      "\n",
      "ç¿»è­¯å¾Œï¼šè¢«å‘Šå·²ç¶“ç”±æ³•åº­å‘½ä»¤ï¼Œæ‡‰ç¹³ä»˜ damages 50,000 ç¾å…ƒã€‚\n"
     ]
    }
   ],
   "source": [
    "# 4. ä½¿ç”¨ç³»çµ±èˆ‡äººé¡è¨Šæ¯çš„çµæ§‹åŒ–æ¨¡æ¿ (é…åˆ Ollama)\n",
    "# æ–¹æ³•ä¸€ï¼šä½¿ç”¨ Tuple æ ¼å¼\n",
    "messages = [\n",
    "    (\"system\", \"ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„{domain}ç¿»è­¯å®¶ï¼Œå…·æœ‰{experience}å¹´çš„ç¿»è­¯ç¶“é©—ã€‚\"),\n",
    "    (\"human\", \"è«‹å°‡ä»¥ä¸‹{source_language}æ–‡æœ¬ç¿»è­¯æˆ{target_language}ï¼š\\\\n\\\\n{text}\"),\n",
    "]\n",
    "\n",
    "structured_template = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "# ä½¿ç”¨çµæ§‹åŒ–æ¨¡æ¿\n",
    "formatted_prompt = structured_template.format(\n",
    "    domain=\"æ³•å¾‹\",\n",
    "    experience=\"10\",\n",
    "    source_language=\"è‹±æ–‡\",\n",
    "    target_language=\"ç¹é«”ä¸­æ–‡\",\n",
    "    text=\"The defendant is hereby ordered to pay damages in the amount of $50,000.\"\n",
    ")\n",
    "\n",
    "print(\"=== çµæ§‹åŒ–æ¨¡æ¿ç¯„ä¾‹ (é…åˆ Ollama) ===\")\n",
    "print(\"è¼¸å…¥çš„æç¤ºè©ï¼š\")\n",
    "print(formatted_prompt)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Ollama æ¨¡å‹å›æ‡‰ï¼š\")\n",
    "\n",
    "# é€é Ollama æ¨¡å‹é€²è¡Œç¿»è­¯\n",
    "try:\n",
    "    response = model.invoke(formatted_prompt)\n",
    "    print(response)\n",
    "except Exception as e:\n",
    "    print(f\"æ¨¡å‹èª¿ç”¨éŒ¯èª¤: {e}\")\n",
    "    print(\"è«‹ç¢ºä¿ Ollama æœå‹™æ­£åœ¨é‹è¡Œï¼Œä¸¦ä¸”å·²å®‰è£ llama3.2:latest æ¨¡å‹\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0b5d69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ç¿»è­¯å·¥å…·å¯¦éš›æ‡‰ç”¨ç¯„ä¾‹ (é…åˆ Ollama) ===\n",
      "\n",
      "ã€ä¸€èˆ¬ç¿»è­¯ã€‘\n",
      "åŸæ–‡: Welcome to our company. We are excited to work with you.\n",
      "ç¿»è­¯çµæœ:\n",
      "æ­¡è¿ä¾†åˆ°æˆ‘å€‘çš„å…¬å¸ã€‚ æˆ‘å€‘å¾ˆé«˜èˆˆèˆ‡æ‚¨åˆä½œã€‚\n",
      "\n",
      "==================================================\n",
      "\n",
      "ã€å•†æ¥­ç¿»è­¯ã€‘\n",
      "åŸæ–‡: The contract will be effective from January 1st, 2024, and will expire on December 31st, 2024.\n",
      "ç¿»è­¯çµæœ:\n",
      "ä»¥ä¸‹æ˜¯è‹±æ–‡å•†æ¥­æ–‡æœ¬çš„ç¹é«”ä¸­æ–‡ç¿»è­¯ï¼š\n",
      "\n",
      "æ ¹æ“šåˆåŒçš„æ¢æ¬¾ï¼ŒåˆåŒè‡ª2024å¹´1æœˆ1æ—¥èµ·ç”Ÿæ•ˆï¼Œåˆ°2024å¹´12æœˆ31æ—¥æ­¢ã€‚\n",
      "\n",
      "æ³¨æ„ï¼šåˆåŒçš„æœ‰æ•ˆæœŸå¾2024å¹´1æœˆ1æ—¥é–‹å§‹ï¼Œåˆ°2024å¹´12æœˆ31æ—¥æ­¢ã€‚\n",
      "\n",
      "==================================================\n",
      "\n",
      "ã€æŠ€è¡“ç¿»è­¯ã€‘\n",
      "åŸæ–‡: The API endpoint returns a JSON response with user authentication tokens.\n",
      "ç¿»è­¯çµæœ:\n",
      "ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„æŠ€è¡“ç¿»è­¯å®¶ï¼Œå°ˆç²¾æ–¼ç¶²è·¯é–‹ç™¼é ˜åŸŸã€‚\n",
      "\n",
      "ä»¥ä¸‹æ˜¯è‹±æ–‡åŸæ–‡çš„ä¸­æ–‡ç¿»è¯‘ï¼š\n",
      "\n",
      "APIç«¯é»è¿”å›ä¸€å€‹ JSON å›æ‡‰ï¼Œå…¶ä¸­åŒ…å«ç”¨æˆ¶èº«ä»½ Tokensã€‚\n",
      "\n",
      "æ³¨æ„ï¼š\n",
      "\n",
      "* æˆ‘å€‘ä¿è­‰äº†æŠ€è¡“è¡“èªçš„æº–ç¢ºæ€§ï¼Œä»¥ä½¿ç¿»è­¯çµæœæ›´ç‚ºå¯é ã€‚\n",
      "* æˆ‘å€‘ä¿æŒäº†æŠ€è¡“æ–‡æª”çš„æ¸…æ™°åº¦ï¼Œä½¿ç”¨ç°¡æ½”çš„å¥å­å’Œæ­£ç¢ºçš„è©å½™ä¾†è¡¨é”ä¸»é¡Œã€‚\n",
      "* æˆ‘å€‘ä¹Ÿéµå¾ªäº†æŠ€è¡“å¯«ä½œè¦ç¯„ï¼Œæ¡ç”¨æ­£ç¢ºçš„èªæ³•ã€è©é¸å’Œç¬¦è™Ÿï¼Œç”¨ä»¥å‰µé€ æ¸…æ™°å’Œå¯ç†è§£çš„æ–‡æª”ã€‚\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# 5. å¯¦éš›æ‡‰ç”¨ï¼šå»ºç«‹ç¿»è­¯å·¥å…·é¡åˆ¥ (é…åˆ Ollama)\n",
    "class TranslationTool:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        # å»ºç«‹ä¸åŒé ˜åŸŸçš„ç¿»è­¯æ¨¡æ¿\n",
    "        self.templates = {\n",
    "            \"general\": ChatPromptTemplate.from_template(\"\"\"\n",
    "ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„ç¿»è­¯å®¶ã€‚\n",
    "è«‹å°‡ä»¥ä¸‹{source_language}æ–‡æœ¬ç¿»è­¯æˆ{target_language}ï¼š\n",
    "\n",
    "{text}\n",
    "\"\"\"),\n",
    "            \n",
    "            \"business\": ChatPromptTemplate.from_template(\"\"\"\n",
    "ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„å•†æ¥­ç¿»è­¯å®¶ï¼Œå°ˆç²¾æ–¼å•†æ¥­æ–‡ä»¶å’Œåˆç´„ç¿»è­¯ã€‚\n",
    "è«‹å°‡ä»¥ä¸‹{source_language}å•†æ¥­æ–‡æœ¬ç¿»è­¯æˆ{target_language}ï¼Œç¢ºä¿ï¼š\n",
    "1. ä¿æŒå°ˆæ¥­è¡“èªçš„æº–ç¢ºæ€§\n",
    "2. ç¬¦åˆå•†æ¥­æ–‡ä»¶çš„æ­£å¼èªæ°£\n",
    "3. ä¿æŒæ•¸å­—çš„ç²¾ç¢ºæ€§\n",
    "\n",
    "{text}\n",
    "\"\"\"),\n",
    "            \n",
    "            \"technical\": ChatPromptTemplate.from_template(\"\"\"\n",
    "ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„æŠ€è¡“ç¿»è­¯å®¶ï¼Œå°ˆç²¾æ–¼{domain}é ˜åŸŸã€‚\n",
    "è«‹å°‡ä»¥ä¸‹{source_language}æŠ€è¡“æ–‡æœ¬ç¿»è­¯æˆ{target_language}ï¼Œç¢ºä¿ï¼š\n",
    "1. æŠ€è¡“è¡“èªçš„æº–ç¢ºæ€§\n",
    "2. ä¿æŒæŠ€è¡“æ–‡æª”çš„æ¸…æ™°åº¦\n",
    "3. ç¬¦åˆæŠ€è¡“å¯«ä½œè¦ç¯„\n",
    "\n",
    "{text}\n",
    "\"\"\")\n",
    "        }\n",
    "    \n",
    "    def translate(self, text, source_lang=\"è‹±æ–‡\", target_lang=\"ç¹é«”ä¸­æ–‡\", \n",
    "                 domain=\"general\", tech_domain=\"è»Ÿé«”é–‹ç™¼\"):\n",
    "        \"\"\"åŸ·è¡Œç¿»è­¯\"\"\"\n",
    "        if domain == \"technical\":\n",
    "            template = self.templates[\"technical\"]\n",
    "            prompt = template.format(\n",
    "                source_language=source_lang,\n",
    "                target_language=target_lang,\n",
    "                domain=tech_domain,\n",
    "                text=text\n",
    "            )\n",
    "        else:\n",
    "            template = self.templates[domain]\n",
    "            prompt = template.format(\n",
    "                source_language=source_lang,\n",
    "                target_language=target_lang,\n",
    "                text=text\n",
    "            )\n",
    "        \n",
    "        # é€é Ollama æ¨¡å‹é€²è¡Œç¿»è­¯\n",
    "        try:\n",
    "            response = self.model.invoke(prompt)\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            return f\"ç¿»è­¯éŒ¯èª¤: {e}\"\n",
    "\n",
    "# å»ºç«‹ç¿»è­¯å·¥å…·å¯¦ä¾‹\n",
    "translator = TranslationTool(model)\n",
    "\n",
    "print(\"=== ç¿»è­¯å·¥å…·å¯¦éš›æ‡‰ç”¨ç¯„ä¾‹ (é…åˆ Ollama) ===\")\n",
    "\n",
    "# æ¸¬è©¦ä¸åŒé¡å‹çš„ç¿»è­¯\n",
    "test_cases = [\n",
    "    {\n",
    "        \"text\": \"Welcome to our company. We are excited to work with you.\",\n",
    "        \"domain\": \"general\",\n",
    "        \"title\": \"ã€ä¸€èˆ¬ç¿»è­¯ã€‘\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"The contract will be effective from January 1st, 2024, and will expire on December 31st, 2024.\",\n",
    "        \"domain\": \"business\", \n",
    "        \"title\": \"ã€å•†æ¥­ç¿»è­¯ã€‘\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"The API endpoint returns a JSON response with user authentication tokens.\",\n",
    "        \"domain\": \"technical\",\n",
    "        \"tech_domain\": \"ç¶²è·¯é–‹ç™¼\",\n",
    "        \"title\": \"ã€æŠ€è¡“ç¿»è­¯ã€‘\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for case in test_cases:\n",
    "    print(f\"\\n{case['title']}\")\n",
    "    print(\"åŸæ–‡:\", case['text'])\n",
    "    print(\"ç¿»è­¯çµæœ:\")\n",
    "    \n",
    "    if case['domain'] == \"technical\":\n",
    "        result = translator.translate(\n",
    "            case['text'],\n",
    "            domain=case['domain'],\n",
    "            tech_domain=case['tech_domain']\n",
    "        )\n",
    "    else:\n",
    "        result = translator.translate(\n",
    "            case['text'],\n",
    "            domain=case['domain']\n",
    "        )\n",
    "    \n",
    "    print(result)\n",
    "    print(\"\\n\" + \"=\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30da64a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Few-shot Learning æ¨¡æ¿ç¯„ä¾‹ (é…åˆ Ollama) ===\n",
      "è¼¸å…¥çš„æç¤ºè©ï¼š\n",
      "System: ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„è‹±æ–‡åˆ°ç¹é«”ä¸­æ–‡ç¿»è­¯å®¶ã€‚è«‹æ ¹æ“šä»¥ä¸‹ç¯„ä¾‹ï¼Œå°‡ä½¿ç”¨è€…çš„è‹±æ–‡å¥å­ç¿»è­¯æˆè‡ªç„¶æµæš¢çš„ç¹é«”ä¸­æ–‡ã€‚\n",
      "Human: Hello, how are you?\n",
      "AI: ä½ å¥½ï¼Œä½ å¥½å—ï¼Ÿ\n",
      "Human: Thank you very much for your help.\n",
      "AI: éå¸¸æ„Ÿè¬ä½ çš„å¹«åŠ©ã€‚\n",
      "Human: I would like to order a coffee, please.\n",
      "AI: æˆ‘æƒ³è¦é»ä¸€æ¯å’–å•¡ï¼Œéº»ç…©äº†ã€‚\n",
      "Human: è«‹ç¿»è­¯ï¼šGood morning, have a great day!\n",
      "\n",
      "==================================================\n",
      "Ollama æ¨¡å‹å›æ‡‰ï¼š\n",
      "æˆ‘å¯ä»¥å¹«ä½ ç¿»è­¯æˆç¹é«”ä¸­æ–‡ï¼š\n",
      "\n",
      "äººé¡ï¼šæ—©ä¸Šå¥½ï¼Œç¥ä½ ä¸€å¤©éƒ½å¾ˆå¥½ï¼\n",
      "æ©Ÿå™¨äººï¼šæ—©ä¸Šå¥½ï¼Œä½ å¥½å—ï¼Ÿ\n"
     ]
    }
   ],
   "source": [
    "# 6. é€²éšç¯„ä¾‹ï¼šFew-shot Learning æ¨¡æ¿ (é…åˆ Ollama)\n",
    "from langchain.prompts import FewShotChatMessagePromptTemplate\n",
    "\n",
    "# å®šç¾©ç¯„ä¾‹\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"Hello, how are you?\",\n",
    "        \"output\": \"ä½ å¥½ï¼Œä½ å¥½å—ï¼Ÿ\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Thank you very much for your help.\",\n",
    "        \"output\": \"éå¸¸æ„Ÿè¬ä½ çš„å¹«åŠ©ã€‚\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"I would like to order a coffee, please.\",\n",
    "        \"output\": \"æˆ‘æƒ³è¦é»ä¸€æ¯å’–å•¡ï¼Œéº»ç…©äº†ã€‚\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# å»ºç«‹ç¯„ä¾‹æ¨¡æ¿\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"ai\", \"{output}\")\n",
    "])\n",
    "\n",
    "# å»ºç«‹ Few-shot æ¨¡æ¿\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples\n",
    ")\n",
    "\n",
    "# å»ºç«‹æœ€çµ‚çš„æç¤ºæ¨¡æ¿\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„è‹±æ–‡åˆ°ç¹é«”ä¸­æ–‡ç¿»è­¯å®¶ã€‚è«‹æ ¹æ“šä»¥ä¸‹ç¯„ä¾‹ï¼Œå°‡ä½¿ç”¨è€…çš„è‹±æ–‡å¥å­ç¿»è­¯æˆè‡ªç„¶æµæš¢çš„ç¹é«”ä¸­æ–‡ã€‚\"),\n",
    "    few_shot_prompt,\n",
    "    (\"human\", \"è«‹ç¿»è­¯ï¼š{input}\")\n",
    "])\n",
    "\n",
    "# ä½¿ç”¨ Few-shot æ¨¡æ¿\n",
    "input_text = \"Good morning, have a great day!\"\n",
    "formatted_prompt = final_prompt.format(input=input_text)\n",
    "\n",
    "print(\"=== Few-shot Learning æ¨¡æ¿ç¯„ä¾‹ (é…åˆ Ollama) ===\")\n",
    "print(\"è¼¸å…¥çš„æç¤ºè©ï¼š\")\n",
    "print(formatted_prompt)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Ollama æ¨¡å‹å›æ‡‰ï¼š\")\n",
    "\n",
    "# é€é Ollama æ¨¡å‹é€²è¡Œç¿»è­¯\n",
    "try:\n",
    "    response = model.invoke(formatted_prompt)\n",
    "    print(response)\n",
    "except Exception as e:\n",
    "    print(f\"æ¨¡å‹èª¿ç”¨éŒ¯èª¤: {e}\")\n",
    "    print(\"è«‹ç¢ºä¿ Ollama æœå‹™æ­£åœ¨é‹è¡Œï¼Œä¸¦ä¸”å·²å®‰è£ llama3.2:latest æ¨¡å‹\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b053c7a",
   "metadata": {},
   "source": [
    "## ğŸ“ ç¸½çµ\n",
    "\n",
    "é€™å€‹å®Œæ•´çš„ç¯„ä¾‹å±•ç¤ºäº† Prompt Template é…åˆ Ollama æ¨¡å‹çš„å„ç¨®ä½¿ç”¨æ–¹å¼ï¼š\n",
    "\n",
    "### ğŸ¯ **æ ¸å¿ƒæ¦‚å¿µ**\n",
    "- **PromptTemplate**: åŸºæœ¬çš„æ–‡å­—æ¨¡æ¿ï¼Œé©åˆç°¡å–®çš„å–®è®Šæ•¸æ›¿æ›\n",
    "- **ChatPromptTemplate**: é©åˆèˆ‡ Chat Model æ•´åˆçš„çµæ§‹åŒ–æ¨¡æ¿\n",
    "- **FewShotChatMessagePromptTemplate**: æ”¯æ´ç¯„ä¾‹å­¸ç¿’çš„é€²éšæ¨¡æ¿\n",
    "- **OllamaLLM**: æœ¬åœ°é‹è¡Œçš„é–‹æºå¤§èªè¨€æ¨¡å‹\n",
    "\n",
    "### ğŸ”§ **å¯¦éš›æ‡‰ç”¨å ´æ™¯**\n",
    "1. **ç¿»è­¯å·¥å…·**: ä¸åŒé ˜åŸŸçš„å°ˆæ¥­ç¿»è­¯ï¼Œç¾åœ¨å¯ä»¥ç²å¾—çœŸå¯¦çš„ç¿»è­¯çµæœ\n",
    "2. **å…§å®¹ç”Ÿæˆ**: çµæ§‹åŒ–çš„å…§å®¹å‰µä½œ\n",
    "3. **å•ç­”ç³»çµ±**: æ¨™æº–åŒ–çš„å•é¡Œè™•ç†\n",
    "4. **å®¢æœæ©Ÿå™¨äºº**: çµ±ä¸€çš„å›æ‡‰æ ¼å¼\n",
    "\n",
    "### ğŸ’¡ **æœ€ä½³å¯¦è¸**\n",
    "- ä½¿ç”¨æ¸…æ™°çš„è®Šæ•¸åç¨±\n",
    "- æä¾›å…·é«”çš„æŒ‡ä»¤å’Œä¸Šä¸‹æ–‡\n",
    "- æ ¹æ“šä¸åŒå ´æ™¯é¸æ“‡åˆé©çš„æ¨¡æ¿é¡å‹\n",
    "- åˆ©ç”¨ Few-shot learning æå‡æ¨¡å‹è¡¨ç¾\n",
    "- åŠ å…¥éŒ¯èª¤è™•ç†æ©Ÿåˆ¶ç¢ºä¿ç¨‹å¼ç©©å®šæ€§\n",
    "\n",
    "### ğŸš€ **Ollama æ•´åˆå„ªå‹¢**\n",
    "- **æœ¬åœ°é‹è¡Œ**: è³‡æ–™éš±ç§æ€§é«˜ï¼Œç„¡éœ€ç¶²è·¯é€£ç·š\n",
    "- **é–‹æºæ¨¡å‹**: å¯è‡ªç”±é¸æ“‡å’Œèª¿æ•´æ¨¡å‹\n",
    "- **æˆæœ¬æ•ˆç›Š**: ç„¡éœ€ä»˜è²» API èª¿ç”¨\n",
    "- **å³æ™‚å›æ‡‰**: æœ¬åœ°è™•ç†é€Ÿåº¦å¿«\n",
    "\n",
    "### âš ï¸ **æ³¨æ„äº‹é …**\n",
    "- ç¢ºä¿ Ollama æœå‹™æ­£åœ¨é‹è¡Œ\n",
    "- å·²å®‰è£æ‰€éœ€çš„æ¨¡å‹ (llama3.2:latest)\n",
    "- æœ¬åœ°ç¡¬é«”è³‡æºå……è¶³ä»¥æ”¯æ´æ¨¡å‹é‹è¡Œ\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
