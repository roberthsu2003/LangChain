{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. åŸºæœ¬éˆ (Chains Basics) - Gemini ç‰ˆæœ¬\n",
    "\n",
    "æœ¬ç¯„ä¾‹å±•ç¤º LangChain çš„åŸºæœ¬éˆæ¦‚å¿µï¼Œå»ºç«‹ä¸€å€‹ç°¡å–®çš„éƒµä»¶å›è¦†ç³»çµ±ã€‚\n",
    "\n",
    "## å­¸ç¿’é‡é»\n",
    "- ç†è§£ LangChain éˆçš„åŸºæœ¬æ¦‚å¿µ\n",
    "- å­¸ç¿’å¦‚ä½•ä½¿ç”¨ LCEL (LangChain Expression Language)\n",
    "- æŒæ¡ Prompt Templateã€LLM å’Œ Output Parser çš„çµ„åˆ\n",
    "- å»ºç«‹ç¬¬ä¸€å€‹å®Œæ•´çš„ AI æ‡‰ç”¨éˆ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å°å…¥å¿…è¦çš„å¥—ä»¶\n",
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# è¼‰å…¥ç’°å¢ƒè®Šæ•¸\n",
    "load_dotenv()\n",
    "\n",
    "# å»ºç«‹ Gemini æ¨¡å‹\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-flash-2.5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šç¾©æç¤ºæ¨¡æ¿ - å»ºç«‹éƒµä»¶å›è¦†ç³»çµ±\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„å®¢æœä»£è¡¨ï¼Œè² è²¬å›è¦†å®¢æˆ¶éƒµä»¶ã€‚è«‹ç”¨å‹å–„ã€å°ˆæ¥­çš„èªèª¿å›è¦†ã€‚\"),\n",
    "        (\"human\", \"è«‹å›è¦†é€™å°å®¢æˆ¶éƒµä»¶ï¼š\\n\\n{email_content}\"),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å»ºç«‹åŸºæœ¬çš„éˆ\n",
    "# ä½¿ç”¨ LCEL (LangChain Expression Language) èªæ³•\n",
    "# éˆçš„æµç¨‹ï¼šPrompt Template â†’ LLM â†’ Output Parser\n",
    "chain = prompt_template | model | StrOutputParser()\n",
    "\n",
    "print(\"åŸºæœ¬éˆå·²å»ºç«‹å®Œæˆï¼\")\n",
    "print(\"éˆçš„çµæ§‹ï¼šPrompt Template â†’ LLM â†’ Output Parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŸ·è¡ŒåŸºæœ¬éˆ - æ¸¬è©¦éƒµä»¶å›è¦†ç³»çµ±\n",
    "customer_email = \"\"\"\n",
    "æ‚¨å¥½ï¼Œ\n",
    "\n",
    "æˆ‘æœ€è¿‘è³¼è²·äº†è²´å…¬å¸çš„ç”¢å“ï¼Œä½†æ˜¯ç™¼ç¾åŒ…è£æœ‰æå£ã€‚\n",
    "è«‹å•å¯ä»¥é€€è²¨æˆ–æ›è²¨å—ï¼Ÿ\n",
    "\n",
    "ç‹å°æ˜\n",
    "\"\"\"\n",
    "\n",
    "result = chain.invoke({\"email_content\": customer_email})\n",
    "\n",
    "# è¼¸å‡ºçµæœ\n",
    "print(\"=\" * 60)\n",
    "print(\"æ™ºèƒ½éƒµä»¶å›è¦†ç³»çµ±è™•ç†çµæœï¼š\")\n",
    "print(\"=\" * 60)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¡ é‡é»èªªæ˜\n",
    "\n",
    "### åŸºæœ¬éˆçš„çµ„æˆ\n",
    "\n",
    "1. **Prompt Template**: å®šç¾©è¼¸å…¥æ ¼å¼å’Œç³»çµ±æç¤º\n",
    "2. **LLM**: å¤§èªè¨€æ¨¡å‹ï¼Œè² è²¬ç”Ÿæˆå›æ‡‰\n",
    "3. **Output Parser**: è§£ææ¨¡å‹è¼¸å‡ºç‚ºæ‰€éœ€æ ¼å¼\n",
    "\n",
    "### LCEL èªæ³•\n",
    "\n",
    "```python\n",
    "# ä½¿ç”¨ç®¡é“ç¬¦è™Ÿ | é€£æ¥å„å€‹çµ„ä»¶\n",
    "chain = prompt_template | model | StrOutputParser()\n",
    "```\n",
    "\n",
    "### éˆçš„åŸ·è¡Œæµç¨‹\n",
    "\n",
    "1. **è¼¸å…¥**: å®¢æˆ¶éƒµä»¶å…§å®¹\n",
    "2. **æ ¼å¼åŒ–**: Prompt Template å°‡è¼¸å…¥æ ¼å¼åŒ–ç‚ºå®Œæ•´çš„æç¤º\n",
    "3. **ç”Ÿæˆ**: LLM æ ¹æ“šæç¤ºç”Ÿæˆå›è¦†\n",
    "4. **è§£æ**: Output Parser å°‡æ¨¡å‹è¼¸å‡ºè§£æç‚ºå­—ä¸²\n",
    "5. **è¼¸å‡º**: æœ€çµ‚çš„éƒµä»¶å›è¦†\n",
    "\n",
    "## ğŸ”§ å¯¦éš›æ‡‰ç”¨å ´æ™¯\n",
    "\n",
    "- **å®¢æœç³»çµ±**: è‡ªå‹•å›è¦†å®¢æˆ¶éƒµä»¶\n",
    "- **å…§å®¹ç”Ÿæˆ**: æ ¹æ“šæ¨¡æ¿ç”Ÿæˆå„ç¨®å…§å®¹\n",
    "- **å•ç­”ç³»çµ±**: å›ç­”ç”¨æˆ¶å•é¡Œ\n",
    "- **ç¿»è­¯æœå‹™**: èªè¨€ç¿»è­¯æ‡‰ç”¨\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. åŸºç¤éˆ (Chains Basics) - Ollama ç‰ˆæœ¬\n",
    "\n",
    "æœ¬ç¯„ä¾‹å±•ç¤ºæœ€åŸºæœ¬çš„ LangChain Expression Language (LCEL) éˆçµ„åˆï¼Œå»ºç«‹ä¸€å€‹ç°¡å–®çš„å•ç­”ç³»çµ±ã€‚\n",
    "\n",
    "## å­¸ç¿’é‡é»\n",
    "- ç†è§£ LCEL çš„ç®¡é“ç¬¦è™Ÿ `|` ç”¨æ³•\n",
    "- å­¸ç¿’åŸºæœ¬çš„éˆçµ„åˆæ–¹å¼\n",
    "- äº†è§£å¦‚ä½•å°‡å¤šå€‹å…ƒä»¶ä¸²è¯èµ·ä¾†\n",
    "- å»ºç«‹å¯¦ç”¨çš„å•ç­”ç³»çµ±\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å°å…¥å¿…è¦çš„å¥—ä»¶\n",
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# è¼‰å…¥ç’°å¢ƒè®Šæ•¸\n",
    "load_dotenv()\n",
    "\n",
    "# å»ºç«‹ Ollama æ¨¡å‹\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-flash-2.5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šç¾©æç¤ºæ¨¡æ¿ - å»ºç«‹ä¸€å€‹å‹å–„çš„å•ç­”åŠ©æ‰‹\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"ä½ æ˜¯ä¸€å€‹å‹å–„ä¸”å°ˆæ¥­çš„åŠ©æ‰‹ï¼Œå°ˆé–€å›ç­”é—œæ–¼ {topic} çš„å•é¡Œã€‚è«‹ç”¨ç°¡å–®æ˜“æ‡‚çš„æ–¹å¼è§£é‡‹ã€‚\"),\n",
    "        (\"human\", \"è«‹å›ç­”é€™å€‹å•é¡Œï¼š{question}\"),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä½¿ç”¨ LangChain Expression Language (LCEL) å»ºç«‹çµ„åˆéˆ\n",
    "# ç®¡é“ç¬¦è™Ÿ | è¡¨ç¤ºï¼šå°‡å·¦é‚Šå…ƒä»¶çš„è¼¸å‡ºå‚³éçµ¦å³é‚Šçš„å…ƒä»¶\n",
    "chain = prompt_template | model | StrOutputParser()\n",
    "\n",
    "print(\"éˆå·²å»ºç«‹å®Œæˆï¼\")\n",
    "print(\"éˆçš„çµæ§‹ï¼šPrompt Template â†’ LLM â†’ Output Parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŸ·è¡Œéˆ - æ¸¬è©¦å•ç­”ç³»çµ±\n",
    "result = chain.invoke({\n",
    "    \"topic\": \"äººå·¥æ™ºæ…§\", \n",
    "    \"question\": \"ä»€éº¼æ˜¯æ©Ÿå™¨å­¸ç¿’ï¼Ÿ\"\n",
    "})\n",
    "\n",
    "# è¼¸å‡ºçµæœ\n",
    "print(\"=\" * 50)\n",
    "print(\"å•ç­”ç³»çµ±å›æ‡‰ï¼š\")\n",
    "print(\"=\" * 50)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¡ é‡é»èªªæ˜\n",
    "\n",
    "1. **LCEL èªæ³•**: `prompt_template | model | StrOutputParser()` ä½¿ç”¨ç®¡é“ç¬¦è™Ÿ `|` ä¾†ä¸²è¯å…ƒä»¶\n",
    "2. **è³‡æ–™æµå‘**: è¼¸å…¥ â†’ Prompt Template â†’ LLM â†’ Output Parser â†’ è¼¸å‡º\n",
    "3. **è‡ªå‹•åŒ–**: ä¸€æ—¦å»ºç«‹éˆï¼Œæ•´å€‹æµç¨‹å°±å¯ä»¥è‡ªå‹•åŸ·è¡Œ\n",
    "4. **æ¨¡çµ„åŒ–**: æ¯å€‹å…ƒä»¶éƒ½å¯ä»¥ç¨ç«‹æ›¿æ›æˆ–ä¿®æ”¹\n",
    "\n",
    "## ğŸ”§ å¯¦éš›æ‡‰ç”¨å ´æ™¯\n",
    "\n",
    "- **å®¢æœç³»çµ±**: å›ç­”å¸¸è¦‹å•é¡Œ\n",
    "- **å­¸ç¿’åŠ©æ‰‹**: è§£é‡‹å­¸ç§‘æ¦‚å¿µ\n",
    "- **æŠ€è¡“æ”¯æ´**: æä¾›è§£æ±ºæ–¹æ¡ˆ\n",
    "- **å…§å®¹ç”Ÿæˆ**: æ ¹æ“šä¸»é¡Œå›ç­”å•é¡Œ\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
