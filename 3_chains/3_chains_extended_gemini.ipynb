{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. æ“´å±•éˆ (Chains Extended) - Gemini ç‰ˆæœ¬\n",
        "\n",
        "æœ¬ç¯„ä¾‹å±•ç¤ºå¦‚ä½•åœ¨éˆä¸­åŠ å…¥è‡ªå®šç¾©è™•ç†æ­¥é©Ÿï¼Œå¦‚å¤§å°å¯«è½‰æ›ã€å­—æ•¸çµ±è¨ˆç­‰ã€‚\n",
        "\n",
        "## å­¸ç¿’é‡é»\n",
        "- ä½¿ç”¨ RunnableLambda æ·»åŠ è‡ªå®šç¾©é‚è¼¯\n",
        "- å­¸ç¿’å¦‚ä½•æ“´å±•åŸºæœ¬çš„éˆåŠŸèƒ½\n",
        "- ç†è§£éˆçš„æ¨¡çµ„åŒ–ç‰¹æ€§\n",
        "- æŒæ¡å¤šæ­¥é©Ÿè™•ç†çš„æŠ€å·§\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å°å…¥å¿…è¦çš„å¥—ä»¶\n",
        "from dotenv import load_dotenv\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "from langchain.schema.runnable import RunnableLambda\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# è¼‰å…¥ç’°å¢ƒè®Šæ•¸\n",
        "load_dotenv()\n",
        "\n",
        "# å»ºç«‹ Gemini æ¨¡å‹\n",
        "model = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å®šç¾©æç¤ºæ¨¡æ¿\n",
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"ä½ æ˜¯ä¸€å€‹å–œåŠ‡æ¼”å“¡ï¼Œå°ˆé–€è¬›é—œæ–¼ {topic} çš„ç¬‘è©±ã€‚\"),\n",
        "        (\"human\", \"è«‹å‘Šè¨´æˆ‘ {joke_count} å€‹ç¬‘è©±ã€‚\"),\n",
        "    ]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å®šç¾©è‡ªå®šç¾©è™•ç†æ­¥é©Ÿ\n",
        "# ä½¿ç”¨ RunnableLambda ä¾†æ·»åŠ è‡ªå®šç¾©é‚è¼¯\n",
        "\n",
        "# æ­¥é©Ÿ 1: å°‡è¼¸å‡ºè½‰æ›ç‚ºå¤§å¯«\n",
        "uppercase_output = RunnableLambda(lambda x: x.upper())\n",
        "\n",
        "# æ­¥é©Ÿ 2: è¨ˆç®—å­—æ•¸ä¸¦æ·»åŠ å­—æ•¸çµ±è¨ˆ\n",
        "count_words = RunnableLambda(lambda x: f\"å­—æ•¸çµ±è¨ˆ: {len(x.split())} å€‹å­—\\n\\n{x}\")\n",
        "\n",
        "print(\"è‡ªå®šç¾©è™•ç†æ­¥é©Ÿå·²å®šç¾©ï¼š\")\n",
        "print(\"1. uppercase_output: å°‡æ–‡å­—è½‰æ›ç‚ºå¤§å¯«\")\n",
        "print(\"2. count_words: è¨ˆç®—å­—æ•¸ä¸¦æ·»åŠ çµ±è¨ˆè³‡è¨Š\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å»ºç«‹æ“´å±•çš„éˆ\n",
        "# éˆçš„æµç¨‹ï¼šPrompt Template â†’ LLM â†’ Output Parser â†’ å¤§å¯«è½‰æ› â†’ å­—æ•¸çµ±è¨ˆ\n",
        "chain = prompt_template | model | StrOutputParser() | uppercase_output | count_words\n",
        "\n",
        "print(\"æ“´å±•éˆå·²å»ºç«‹å®Œæˆï¼\")\n",
        "print(\"éˆçš„çµæ§‹ï¼šPrompt Template â†’ LLM â†’ Output Parser â†’ å¤§å¯«è½‰æ› â†’ å­—æ•¸çµ±è¨ˆ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# åŸ·è¡Œæ“´å±•éˆ\n",
        "result = chain.invoke({\"topic\": \"å¾‹å¸«\", \"joke_count\": 3})\n",
        "\n",
        "# è¼¸å‡ºçµæœ\n",
        "print(\"=\" * 60)\n",
        "print(\"æ“´å±•éˆè™•ç†çµæœï¼š\")\n",
        "print(\"=\" * 60)\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ’¡ é‡é»èªªæ˜\n",
        "\n",
        "### æ“´å±•éˆçš„å„ªå‹¢\n",
        "\n",
        "1. **æ¨¡çµ„åŒ–è¨­è¨ˆ**: æ¯å€‹è™•ç†æ­¥é©Ÿéƒ½æ˜¯ç¨ç«‹çš„ï¼Œå¯ä»¥è¼•é¬†æ·»åŠ ã€ç§»é™¤æˆ–ä¿®æ”¹\n",
        "2. **å¯é‡ç”¨æ€§**: è‡ªå®šç¾©çš„è™•ç†æ­¥é©Ÿå¯ä»¥åœ¨ä¸åŒçš„éˆä¸­é‡è¤‡ä½¿ç”¨\n",
        "3. **éˆæ´»æ€§**: å¯ä»¥æ ¹æ“šéœ€æ±‚çµ„åˆä¸åŒçš„è™•ç†æ­¥é©Ÿ\n",
        "\n",
        "### RunnableLambda çš„ä½¿ç”¨\n",
        "\n",
        "```python\n",
        "# åŸºæœ¬èªæ³•\n",
        "custom_step = RunnableLambda(lambda x: è‡ªå®šç¾©è™•ç†å‡½æ•¸(x))\n",
        "\n",
        "# å¯¦éš›ç¯„ä¾‹\n",
        "uppercase_output = RunnableLambda(lambda x: x.upper())\n",
        "count_words = RunnableLambda(lambda x: f\"å­—æ•¸: {len(x.split())}\\n{x}\")\n",
        "```\n",
        "\n",
        "### éˆçš„çµ„åˆæ–¹å¼\n",
        "\n",
        "```python\n",
        "# ä½¿ç”¨ç®¡é“ç¬¦è™Ÿä¸²è¯å¤šå€‹æ­¥é©Ÿ\n",
        "chain = (\n",
        "    prompt_template \n",
        "    | model \n",
        "    | StrOutputParser() \n",
        "    | uppercase_output \n",
        "    | count_words\n",
        ")\n",
        "```\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
