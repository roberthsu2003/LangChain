{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4. ä¸¦è¡Œéˆ (Chains Parallel) - Gemini ç‰ˆæœ¬\n",
        "\n",
        "æœ¬ç¯„ä¾‹å±•ç¤ºå¦‚ä½•åŒæ™‚åŸ·è¡Œå¤šå€‹åˆ†æ”¯ï¼Œå¦‚ç”¢å“å„ªç¼ºé»åˆ†æï¼Œä½¿ç”¨ RunnableParallel å¯¦ç¾ä¸¦è¡Œè™•ç†ã€‚\n",
        "\n",
        "## å­¸ç¿’é‡é»\n",
        "- ä½¿ç”¨ RunnableParallel å¯¦ç¾ä¸¦è¡Œè™•ç†\n",
        "- å­¸ç¿’å¦‚ä½•åŒæ™‚åŸ·è¡Œå¤šå€‹åˆ†æä»»å‹™\n",
        "- ç†è§£ä¸¦è¡Œè™•ç†çš„å„ªå‹¢\n",
        "- æŒæ¡è¤‡é›œéˆçš„çµ„åˆæŠ€å·§\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å°å…¥å¿…è¦çš„å¥—ä»¶\n",
        "from dotenv import load_dotenv\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "from langchain.schema.runnable import RunnableParallel, RunnableLambda\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# è¼‰å…¥ç’°å¢ƒè®Šæ•¸\n",
        "load_dotenv()\n",
        "\n",
        "# å»ºç«‹ Gemini æ¨¡å‹\n",
        "model = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å®šç¾©ä¸»è¦çš„æç¤ºæ¨¡æ¿ - ç”¢å“ç‰¹å¾µåˆ†æ\n",
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„ç”¢å“è©•è«–å®¶ã€‚\"),\n",
        "        (\"human\", \"è«‹åˆ—å‡ºç”¢å“ {product_name} çš„ä¸»è¦ç‰¹å¾µã€‚\"),\n",
        "    ]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å®šç¾©å„ªé»åˆ†æå‡½æ•¸\n",
        "def analyze_pros(features):\n",
        "    \"\"\"åˆ†æç”¢å“ç‰¹å¾µçš„å„ªé»\"\"\"\n",
        "    pros_template = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\"system\", \"ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„ç”¢å“è©•è«–å®¶ã€‚\"),\n",
        "            (\"human\", \"æ ¹æ“šé€™äº›ç‰¹å¾µï¼š{features}ï¼Œè«‹åˆ—å‡ºé€™äº›ç‰¹å¾µçš„å„ªé»ã€‚\"),\n",
        "        ]\n",
        "    )\n",
        "    return pros_template.format_prompt(features=features)\n",
        "\n",
        "# å®šç¾©ç¼ºé»åˆ†æå‡½æ•¸\n",
        "def analyze_cons(features):\n",
        "    \"\"\"åˆ†æç”¢å“ç‰¹å¾µçš„ç¼ºé»\"\"\"\n",
        "    cons_template = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\"system\", \"ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„ç”¢å“è©•è«–å®¶ã€‚\"),\n",
        "            (\"human\", \"æ ¹æ“šé€™äº›ç‰¹å¾µï¼š{features}ï¼Œè«‹åˆ—å‡ºé€™äº›ç‰¹å¾µçš„ç¼ºé»ã€‚\"),\n",
        "        ]\n",
        "    )\n",
        "    return cons_template.format_prompt(features=features)\n",
        "\n",
        "print(\"åˆ†æå‡½æ•¸å·²å®šç¾©ï¼š\")\n",
        "print(\"1. analyze_pros: åˆ†æç”¢å“å„ªé»\")\n",
        "print(\"2. analyze_cons: åˆ†æç”¢å“ç¼ºé»\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å®šç¾©çµæœåˆä½µå‡½æ•¸\n",
        "def combine_pros_cons(pros, cons):\n",
        "    \"\"\"å°‡å„ªé»å’Œç¼ºé»åˆä½µæˆæœ€çµ‚è©•è«–\"\"\"\n",
        "    return f\"å„ªé»åˆ†æï¼š\\n{pros}\\n\\nç¼ºé»åˆ†æï¼š\\n{cons}\"\n",
        "\n",
        "print(\"çµæœåˆä½µå‡½æ•¸å·²å®šç¾©ï¼šcombine_pros_cons\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ä½¿ç”¨ LCEL ç°¡åŒ–åˆ†æ”¯éˆçš„å»ºç«‹\n",
        "# å„ªé»åˆ†æåˆ†æ”¯\n",
        "pros_branch_chain = (\n",
        "    RunnableLambda(lambda x: analyze_pros(x)) | model | StrOutputParser()\n",
        ")\n",
        "\n",
        "# ç¼ºé»åˆ†æåˆ†æ”¯\n",
        "cons_branch_chain = (\n",
        "    RunnableLambda(lambda x: analyze_cons(x)) | model | StrOutputParser()\n",
        ")\n",
        "\n",
        "print(\"ä¸¦è¡Œåˆ†æ”¯éˆå·²å»ºç«‹ï¼š\")\n",
        "print(\"1. pros_branch_chain: å„ªé»åˆ†æåˆ†æ”¯\")\n",
        "print(\"2. cons_branch_chain: ç¼ºé»åˆ†æåˆ†æ”¯\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å»ºç«‹å®Œæ•´çš„ä¸¦è¡Œè™•ç†éˆ\n",
        "chain = (\n",
        "    prompt_template\n",
        "    | model\n",
        "    | StrOutputParser()\n",
        "    | RunnableParallel(\n",
        "        branches={\n",
        "            \"pros\": pros_branch_chain, \n",
        "            \"cons\": cons_branch_chain\n",
        "        }\n",
        "    )\n",
        "    | RunnableLambda(lambda x: combine_pros_cons(x[\"branches\"][\"pros\"], x[\"branches\"][\"cons\"]))\n",
        ")\n",
        "\n",
        "print(\"ä¸¦è¡Œè™•ç†éˆå·²å»ºç«‹å®Œæˆï¼\")\n",
        "print(\"éˆçš„æµç¨‹ï¼šç”¢å“ç‰¹å¾µ â†’ ä¸¦è¡Œåˆ†æ(å„ªé»+ç¼ºé») â†’ åˆä½µçµæœ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# åŸ·è¡Œä¸¦è¡Œè™•ç†éˆ\n",
        "result = chain.invoke({\"product_name\": \"MacBook Pro\"})\n",
        "\n",
        "# è¼¸å‡ºçµæœ\n",
        "print(\"=\" * 60)\n",
        "print(\"ç”¢å“åˆ†æçµæœï¼š\")\n",
        "print(\"=\" * 60)\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ’¡ é‡é»èªªæ˜\n",
        "\n",
        "### ä¸¦è¡Œè™•ç†çš„å„ªå‹¢\n",
        "\n",
        "1. **æ•ˆç‡æå‡**: åŒæ™‚åŸ·è¡Œå¤šå€‹åˆ†æä»»å‹™ï¼Œç¯€çœæ™‚é–“\n",
        "2. **è³‡æºåˆ©ç”¨**: å……åˆ†åˆ©ç”¨ç³»çµ±è³‡æºï¼Œæé«˜è™•ç†é€Ÿåº¦\n",
        "3. **æ¨¡çµ„åŒ–**: æ¯å€‹åˆ†æ”¯éƒ½æ˜¯ç¨ç«‹çš„ï¼Œæ˜“æ–¼ç¶­è­·å’Œä¿®æ”¹\n",
        "\n",
        "### RunnableParallel çš„ä½¿ç”¨\n",
        "\n",
        "```python\n",
        "# åŸºæœ¬èªæ³•\n",
        "RunnableParallel(\n",
        "    branches={\n",
        "        \"åˆ†æ”¯åç¨±1\": åˆ†æ”¯éˆ1,\n",
        "        \"åˆ†æ”¯åç¨±2\": åˆ†æ”¯éˆ2,\n",
        "        # ... æ›´å¤šåˆ†æ”¯\n",
        "    }\n",
        ")\n",
        "```\n",
        "\n",
        "### ä¸¦è¡Œéˆçš„è³‡æ–™æµ\n",
        "\n",
        "1. **è¼¸å…¥**: ç”¢å“åç¨±\n",
        "2. **ç‰¹å¾µåˆ†æ**: ç”Ÿæˆç”¢å“ç‰¹å¾µåˆ—è¡¨\n",
        "3. **ä¸¦è¡Œè™•ç†**: åŒæ™‚åˆ†æå„ªé»å’Œç¼ºé»\n",
        "4. **çµæœåˆä½µ**: å°‡ä¸¦è¡Œçµæœæ•´åˆæˆæœ€çµ‚å ±å‘Š\n",
        "\n",
        "### å¯¦éš›æ‡‰ç”¨å ´æ™¯\n",
        "\n",
        "- ç”¢å“è©•è«–åˆ†æ\n",
        "- å¤šè§’åº¦æ–‡æœ¬åˆ†æ\n",
        "- ä¸¦è¡Œæ•¸æ“šè™•ç†\n",
        "- å¤šä»»å‹™åŒæ™‚åŸ·è¡Œ\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
