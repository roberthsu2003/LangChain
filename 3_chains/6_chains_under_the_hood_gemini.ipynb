{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 鏈的內部運作 (Chains Under the Hood) - Ollama 版本\n",
    "\n",
    "本範例深入理解 LCEL 鏈的內部實作，展示如何使用 RunnableSequence 手動組合鏈的各個步驟，建立一個文字摘要系統。\n",
    "\n",
    "## 學習重點\n",
    "- 了解鏈的底層運作機制\n",
    "- 學習 RunnableSequence 的使用方法\n",
    "- 理解 RunnableLambda 的作用\n",
    "- 對比手動組合與 LCEL 語法的差異\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RunnableSequence 簡介\n",
    "\n",
    "**RunnableSequence** 是 LangChain 中用來手動組合執行步驟的類別，它讓你可以精確控制鏈的每個環節。\n",
    "\n",
    "### 基本結構\n",
    "\n",
    "```python\n",
    "RunnableSequence(\n",
    "    first=第一個步驟,      # 必須：開始的步驟\n",
    "    middle=[中間步驟],     # 可選：中間的多個步驟（列表）\n",
    "    last=最後一個步驟      # 必須：結束的步驟\n",
    ")\n",
    "```\n",
    "\n",
    "### 核心概念\n",
    "\n",
    "- **順序執行**: 按照 first → middle → last 的順序依次執行\n",
    "- **資料流動**: 上一個步驟的輸出會自動成為下一個步驟的輸入\n",
    "- **完全控制**: 可以在任何位置插入自定義邏輯（如日誌、驗證、轉換等）\n",
    "\n",
    "### 與 LCEL 的關係\n",
    "\n",
    "```python\n",
    "# 這兩種寫法功能相同：\n",
    "chain = prompt | model | parser          # LCEL 語法（簡潔）\n",
    "chain = RunnableSequence(                # 手動組合（精細控制）\n",
    "    first=prompt,\n",
    "    middle=[model],\n",
    "    last=parser\n",
    ")\n",
    "```\n",
    "\n",
    "實際上，當你使用 `|` 運算符時，LangChain 內部就是建立 RunnableSequence！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 導入必要的套件\n",
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnableLambda, RunnableSequence\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# 載入環境變數\n",
    "load_dotenv()\n",
    "\n",
    "# 建立 Ollama 模型\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-flash-2.5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義提示模板 - 建立文字摘要系統\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"你是一個專業的文字摘要助手，擅長將長篇文章濃縮成簡潔的重點摘要。\"),\n",
    "        (\"human\", \"請將以下文章摘要成 {max_length} 字以內的重點：\\n\\n{article}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "各個步驟已定義完成：\n",
      "1. format_prompt: 格式化提示模板\n",
      "2. invoke_model: 呼叫 LLM 模型\n",
      "3. parse_output: 解析模型輸出\n",
      "4. add_debug_log: 添加除錯日誌（展示內部控制的優勢）\n"
     ]
    }
   ],
   "source": [
    "# 手動建立各個可執行步驟 (Runnable)\n",
    "# 這些步驟對應 LCEL 鏈中的各個元件\n",
    "\n",
    "# 步驟 1: 格式化提示\n",
    "# 使用 RunnableLambda 將輸入資料 x 套用到 prompt_template 的 format_prompt 方法\n",
    "# x 必須是一個 dict，包含 prompt_template 所需的參數（例如 article, max_length）\n",
    "# 傳出來的資料類型是 `ChatPromptValue`（來自 langchain.prompts.base）\n",
    "format_prompt = RunnableLambda(lambda x: prompt_template.format_prompt(**x))\n",
    "\n",
    "# 步驟 2: 呼叫模型\n",
    "# 這一行使用 RunnableLambda 將前一步產生的 ChatPromptValue 物件（x）轉換為訊息格式（x.to_messages()），\n",
    "# 並傳遞給 OllamaLLM 的 invoke 方法，取得模型回應。\n",
    "# 注意：OllamaLLM 的 invoke 方法直接返回字串，而非 AIMessage 物件\n",
    "invoke_model = RunnableLambda(lambda x: model.invoke(x.to_messages()))\n",
    "\n",
    "# 步驟 3: 解析輸出\n",
    "# 因為 OllamaLLM 已經返回字串，所以這裡直接返回即可（不需要 .content）\n",
    "parse_output = RunnableLambda(lambda x: x)\n",
    "\n",
    "# 步驟 4: 添加除錯日誌（展示內部運作的價值）\n",
    "def add_debug_log(step_name):\n",
    "    \"\"\"為每個步驟添加除錯日誌，幫助追蹤處理流程\"\"\"\n",
    "    def _log(x):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"[DEBUG] 步驟: {step_name}\")\n",
    "        print(f\"[DEBUG] 輸入類型: {type(x).__name__}\")\n",
    "        if isinstance(x, str):\n",
    "            print(f\"[DEBUG] 內容預覽: {x[:100]}...\" if len(x) > 100 else f\"[DEBUG] 內容: {x}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        return x\n",
    "    return RunnableLambda(_log)\n",
    "\n",
    "print(\"各個步驟已定義完成：\")\n",
    "print(\"1. format_prompt: 格式化提示模板\")\n",
    "print(\"2. invoke_model: 呼叫 LLM 模型\")\n",
    "print(\"3. parse_output: 解析模型輸出\")\n",
    "print(\"4. add_debug_log: 添加除錯日誌（展示內部控制的優勢）\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "手動組合的鏈已建立完成（含除錯功能）！\n",
      "鏈的結構：\n",
      "  開始 → [DEBUG] → format_prompt → [DEBUG] → invoke_model → [DEBUG] → parse_output\n",
      "\n",
      "💡 這展示了手動組合的優勢：可以在任何步驟之間插入自定義邏輯！\n"
     ]
    }
   ],
   "source": [
    "# 使用 RunnableSequence 手動組合鏈，並添加除錯功能\n",
    "# 這相當於 LCEL 的 prompt_template | model | StrOutputParser()\n",
    "# 但我們可以在每個步驟之間插入除錯日誌\n",
    "\n",
    "chain = RunnableSequence(\n",
    "    first=add_debug_log(\"開始處理\"),\n",
    "    middle=[\n",
    "        format_prompt,\n",
    "        add_debug_log(\"格式化完成\"),\n",
    "        invoke_model,\n",
    "        add_debug_log(\"模型調用完成\")\n",
    "    ],\n",
    "    last=parse_output\n",
    ")\n",
    "\n",
    "print(\"手動組合的鏈已建立完成（含除錯功能）！\")\n",
    "print(\"鏈的結構：\")\n",
    "print(\"  開始 → [DEBUG] → format_prompt → [DEBUG] → invoke_model → [DEBUG] → parse_output\")\n",
    "print(\"\\n💡 這展示了手動組合的優勢：可以在任何步驟之間插入自定義邏輯！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "[DEBUG] 步驟: 開始處理\n",
      "[DEBUG] 輸入類型: dict\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "[DEBUG] 步驟: 格式化完成\n",
      "[DEBUG] 輸入類型: ChatPromptValue\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "[DEBUG] 步驟: 模型調用完成\n",
      "[DEBUG] 輸入類型: str\n",
      "[DEBUG] 內容預覽: 人工智慧（AI）是電腦科學的一個分支，旨在創建能夠執行通常需要人類智能的任務。AI技術已經產生重大影響，在醫療、金融、交通和娛樂等領域。機器學習是一種 AI 技術，使用數據來學習而無需明確編程。深度學...\n",
      "============================================================\n",
      "==================================================\n",
      "文章摘要結果：\n",
      "==================================================\n",
      "人工智慧（AI）是電腦科學的一個分支，旨在創建能夠執行通常需要人類智能的任務。AI技術已經產生重大影響，在醫療、金融、交通和娛樂等領域。機器學習是一種 AI 技術，使用數據來學習而無需明確編程。深度學習是該技術的一個分支，使用人工神經網絡模擬人腦的工作方式。\n"
     ]
    }
   ],
   "source": [
    "# 執行手動組合的鏈 - 測試文字摘要系統\n",
    "sample_article = \"\"\"\n",
    "人工智慧（AI）是電腦科學的一個分支，旨在創建能夠執行通常需要人類智能的任務的系統。\n",
    "這些任務包括學習、推理、問題解決、感知和語言理解。AI 技術已經在許多領域產生重大影響，\n",
    "包括醫療保健、金融、交通運輸和娛樂。機器學習是 AI 的一個子領域，它使計算機能夠從數據中學習\n",
    "而無需明確編程。深度學習是機器學習的一個分支，使用人工神經網絡來模擬人腦的工作方式。\n",
    "隨著技術的進步，AI 有望在未來幾年繼續改變我們的生活和工作方式。\n",
    "\"\"\"\n",
    "\n",
    "response = chain.invoke({\n",
    "    \"article\": sample_article,\n",
    "    \"max_length\": 100\n",
    "})\n",
    "\n",
    "# 輸出結果\n",
    "print(\"=\" * 50)\n",
    "print(\"文章摘要結果：\")\n",
    "print(\"=\" * 50)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 理解數據流\n",
    "```\n",
    "chain.invoke({\"article\": \"...\", \"max_length\": 100})\n",
    "    ↓\n",
    "開始處理: dict\n",
    "    ↓\n",
    "format_prompt: dict → ChatPromptValue\n",
    "    ↓\n",
    "格式化完成: ChatPromptValue\n",
    "    ↓\n",
    "invoke_model: ChatPromptValue → str\n",
    "    ↓\n",
    "模型調用完成: str\n",
    "    ↓\n",
    "parse_output: str → str\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💡 重點說明\n",
    "\n",
    "### 手動組合 vs LCEL 語法\n",
    "\n",
    "**手動組合 (RunnableSequence)**:\n",
    "```python\n",
    "chain = RunnableSequence(\n",
    "    first=add_debug_log(\"開始\"),\n",
    "    middle=[format_prompt, add_debug_log(\"格式化\"), invoke_model],\n",
    "    last=parse_output\n",
    ")\n",
    "```\n",
    "\n",
    "**LCEL 語法**:\n",
    "```python\n",
    "chain = prompt_template | model | StrOutputParser()\n",
    "```\n",
    "\n",
    "### 優缺點比較\n",
    "\n",
    "**手動組合的優點**:\n",
    "- ✅ **精細控制**: 可以在任何步驟之間插入自定義邏輯\n",
    "- ✅ **除錯友好**: 容易添加日誌記錄和錯誤處理\n",
    "- ✅ **學習價值**: 清楚看到每個步驟的實作細節\n",
    "- ✅ **效能監控**: 可以追蹤每個步驟的執行時間\n",
    "\n",
    "**LCEL 語法的優點**:\n",
    "- ✅ **程式碼簡潔**: 一行就能完成鏈的定義\n",
    "- ✅ **自動功能**: 自動具備串流、批次處理等功能\n",
    "- ✅ **推薦做法**: LangChain 官方推薦的現代化方法\n",
    "- ✅ **易於維護**: 結構清晰，容易理解\n",
    "\n",
    "### 🎯 實際應用建議\n",
    "\n",
    "**使用手動組合的場景**:\n",
    "1. **開發階段**: 需要詳細的除錯資訊\n",
    "2. **效能優化**: 需要監控每個步驟的執行時間\n",
    "3. **錯誤處理**: 需要對特定步驟進行錯誤捕獲\n",
    "4. **學習理解**: 想要深入理解 LangChain 的內部機制\n",
    "\n",
    "**使用 LCEL 的場景**:\n",
    "1. **生產環境**: 程式碼經過充分測試，不需要詳細除錯\n",
    "2. **快速開發**: 需要快速建立原型\n",
    "3. **簡單流程**: 不需要複雜的中間處理\n",
    "4. **團隊協作**: 程式碼需要清晰易讀\n",
    "\n",
    "## 🔧 實際應用場景\n",
    "\n",
    "- **新聞摘要**: 自動生成新聞重點，並記錄處理時間\n",
    "- **學術論文**: 提取研究重點，追蹤每個處理步驟\n",
    "- **會議記錄**: 整理會議要點，添加品質檢查\n",
    "- **長文閱讀**: 快速了解文章內容，監控處理效能\n",
    "\n",
    "## 📊 除錯輸出範例\n",
    "\n",
    "從上面的執行結果可以看到，我們能夠追蹤：\n",
    "- 每個步驟的輸入資料類型\n",
    "- 處理過程中的資料轉換\n",
    "- 中間結果的預覽\n",
    "\n",
    "這些資訊在開發和除錯時非常有價值！"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}