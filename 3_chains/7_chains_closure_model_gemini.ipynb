{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. é–‰åŒ…æ¨¡å‹éˆ (Closure Model Chains) - Gemini ç‰ˆæœ¬\n",
    "\n",
    "æœ¬ç¯„ä¾‹å±•ç¤ºå¦‚ä½•ä½¿ç”¨ Google Gemini åœ¨ RunnableLambda ä¸­é€šéé–‰åŒ…æ–¹å¼ç›´æ¥èª¿ç”¨æ¨¡å‹ã€‚\n",
    "\n",
    "## ğŸ¯ å­¸ç¿’ç›®æ¨™\n",
    "- ç†è§£é–‰åŒ…åœ¨ LangChain ä¸­çš„æ‡‰ç”¨\n",
    "- æŒæ¡åœ¨è‡ªå®šç¾©å‡½æ•¸ä¸­èª¿ç”¨æ¨¡å‹çš„æŠ€å·§\n",
    "- å­¸ç¿’å®Œå…¨æ§åˆ¶è™•ç†æµç¨‹çš„æ–¹æ³•\n",
    "\n",
    "## ğŸ“ æ ¸å¿ƒæ¦‚å¿µ\n",
    "é–‰åŒ…æ¨¡å‹éˆé€šéåœ¨ RunnableLambda å‡½æ•¸å…§éƒ¨æ•ç²å¤–éƒ¨çš„æ¨¡å‹å¯¦ä¾‹ï¼Œå¯¦ç¾éˆæ´»çš„è‡ªå®šç¾©è™•ç†é‚è¼¯ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableLambda\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "load_dotenv()\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash-latest\")\n",
    "print(\"âœ… Gemini æ¨¡å‹å·²å»ºç«‹\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„å®¢æœä»£è¡¨ã€‚\"),\n",
    "    (\"human\", \"è«‹å›è¦†é€™å°å®¢æˆ¶éƒµä»¶ï¼š\\n\\n{email_content}\")\n",
    "])\n",
    "\n",
    "def format_with_quality_check(reply):\n",
    "    formatted_reply = f\"\"\"\n",
    "è¦ªæ„›çš„å®¢æˆ¶ï¼Œ\n",
    "\n",
    "{reply}\n",
    "\n",
    "æ„Ÿè¬æ‚¨çš„ä¾†ä¿¡ï¼Œå¦‚æœ‰å…¶ä»–å•é¡Œè«‹éš¨æ™‚è¯ç¹«æˆ‘å€‘ã€‚\n",
    "\n",
    "æ­¤è‡´\n",
    "å®¢æœåœ˜éšŠ\n",
    "\"\"\"\n",
    "    \n",
    "    quality_check_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"ä½ æ˜¯éƒµä»¶å“è³ªå¯©æŸ¥å°ˆå®¶ã€‚è«‹è©•ä¼°é€™å°éƒµä»¶ä¸¦çµ¦å‡º1-10åˆ†è©•åˆ†å’Œç°¡çŸ­è©•èªã€‚\"),\n",
    "        (\"human\", \"è©•ä¼°é€™å°éƒµä»¶ï¼š\\n\\n{email}\")\n",
    "    ])\n",
    "    \n",
    "    quality_result = quality_check_prompt.format_prompt(email=formatted_reply)\n",
    "    quality_score = model.invoke(quality_result.to_messages())\n",
    "    \n",
    "    return f\"\"\"\n",
    "{'='*60}\n",
    "ğŸ“§ æ ¼å¼åŒ–çš„éƒµä»¶å›è¦†ï¼š\n",
    "{'='*60}\n",
    "{formatted_reply}\n",
    "\n",
    "{'='*60}\n",
    "ğŸ“Š AI å“è³ªæª¢æŸ¥çµæœï¼š\n",
    "{'='*60}\n",
    "{quality_score.content}\n",
    "\"\"\"\n",
    "\n",
    "closure_chain = prompt_template | model | StrOutputParser() | RunnableLambda(format_with_quality_check)\n",
    "print(\"âœ… é–‰åŒ…æ¨¡å‹éˆå·²å»ºç«‹\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [