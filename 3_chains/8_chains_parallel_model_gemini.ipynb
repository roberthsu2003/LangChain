{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ä¸¦è¡Œæ¨¡å‹éˆ (Parallel Model Chains)\n",
    "\n",
    "æœ¬ç¯„ä¾‹å±•ç¤ºå¦‚ä½•ä½¿ç”¨ RunnableParallel åŒæ™‚èª¿ç”¨å¤šå€‹æ¨¡å‹é€²è¡Œä¸åŒè§’åº¦çš„åˆ†æã€‚\n",
    "\n",
    "## ğŸ¯ å­¸ç¿’ç›®æ¨™\n",
    "- ç†è§£ä¸¦è¡Œè™•ç†çš„æ¦‚å¿µå’Œå„ªå‹¢\n",
    "- æŒæ¡ RunnableParallel çš„ä½¿ç”¨æ–¹æ³•\n",
    "- å­¸ç¿’å¦‚ä½•åˆä½µå¤šå€‹æ¨¡å‹çš„åˆ†æçµæœ\n",
    "\n",
    "## ğŸ“ æ ¸å¿ƒæ¦‚å¿µ\n",
    "ä¸¦è¡Œæ¨¡å‹éˆä½¿ç”¨ RunnableParallel åŒæ™‚åŸ·è¡Œå¤šå€‹æ¨¡å‹èª¿ç”¨ï¼Œæ¯å€‹æ¨¡å‹è² è²¬ä¸åŒçš„åˆ†æä»»å‹™ï¼Œæœ€å¾Œåˆä½µçµæœï¼Œå¤§å¹…æå‡è™•ç†æ•ˆç‡ã€‚\n",
    "\n",
    "## âœ¨ é©ç”¨å ´æ™¯\n",
    "- å¤šè§’åº¦å…§å®¹åˆ†æï¼ˆå“è³ªã€èªæ°£ã€æƒ…æ„Ÿç­‰ï¼‰\n",
    "- éœ€è¦åŒæ™‚ç²å–å¤šç¨®è©•ä¼°çµæœ\n",
    "- æå‡è™•ç†æ•ˆç‡çš„å ´æ™¯\n",
    "- ç¨ç«‹ä»»å‹™çš„ä¸¦è¡Œè™•ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableLambda, RunnableParallel\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "load_dotenv()\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-flash-2.5\")\n",
    "print(\"âœ… æ¨¡å‹å·²å»ºç«‹\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¸»æç¤ºæ¨¡æ¿\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ä½ æ˜¯å°ˆæ¥­çš„å®¢æœä»£è¡¨ã€‚\"),\n",
    "    (\"human\", \"è«‹å›è¦†é€™å°å®¢æˆ¶éƒµä»¶ï¼š\\n\\n{email_content}\")\n",
    "])\n",
    "\n",
    "# æ ¼å¼åŒ–å‡½æ•¸\n",
    "def format_email(reply):\n",
    "    return f\"\"\"\n",
    "è¦ªæ„›çš„å®¢æˆ¶ï¼Œ\n",
    "\n",
    "{reply}\n",
    "\n",
    "æ„Ÿè¬æ‚¨çš„ä¾†ä¿¡ã€‚\n",
    "\n",
    "æ­¤è‡´\n",
    "å®¢æœåœ˜éšŠ\n",
    "\"\"\"\n",
    "\n",
    "# å“è³ªæª¢æŸ¥éˆ\n",
    "quality_check_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ä½ æ˜¯éƒµä»¶å“è³ªå¯©æŸ¥å°ˆå®¶ã€‚è«‹è©•ä¼°é€™å°éƒµä»¶çš„å°ˆæ¥­åº¦ï¼Œçµ¦å‡º1-10åˆ†è©•åˆ†å’Œç°¡çŸ­è©•èªã€‚\"),\n",
    "    (\"human\", \"è©•ä¼°é€™å°éƒµä»¶ï¼š\\n\\n{email}\")\n",
    "])\n",
    "quality_check_chain = quality_check_prompt | model | StrOutputParser()\n",
    "\n",
    "# èªæ°£åˆ†æéˆ\n",
    "tone_analysis_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ä½ æ˜¯èªæ°£åˆ†æå°ˆå®¶ã€‚è«‹åˆ†æé€™å°éƒµä»¶çš„èªæ°£æ˜¯å¦å‹å–„ã€å°ˆæ¥­ã€‚\"),\n",
    "    (\"human\", \"åˆ†æé€™å°éƒµä»¶çš„èªæ°£ï¼š\\n\\n{email}\")\n",
    "])\n",
    "tone_analysis_chain = tone_analysis_prompt | model | StrOutputParser()\n",
    "\n",
    "print(\"âœ… åˆ†æéˆå·²å»ºç«‹\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä½¿ç”¨ RunnableParallel ä¸¦è¡ŒåŸ·è¡Œ\n",
    "parallel_chain = RunnableParallel(\n",
    "    formatted_email=RunnableLambda(format_email),\n",
    "    quality_check=RunnableLambda(lambda x: {\"email\": format_email(x)}) | quality_check_chain,\n",
    "    tone_analysis=RunnableLambda(lambda x: {\"email\": format_email(x)}) | tone_analysis_chain\n",
    ")\n",
    "\n",
    "# åˆä½µçµæœ\n",
    "def combine_results(parallel_results):\n",
    "    return f\"\"\"\n",
    "{'='*60}\n",
    "ğŸ“§ æ ¼å¼åŒ–çš„éƒµä»¶å›è¦†ï¼š\n",
    "{'='*60}\n",
    "{parallel_results['formatted_email']}\n",
    "\n",
    "{'='*60}\n",
    "ğŸ“Š AI å“è³ªæª¢æŸ¥çµæœï¼š\n",
    "{'='*60}\n",
    "{parallel_results['quality_check']}\n",
    "\n",
    "{'='*60}\n",
    "ğŸ­ AI èªæ°£åˆ†æçµæœï¼š\n",
    "{'='*60}\n",
    "{parallel_results['tone_analysis']}\n",
    "\"\"\"\n",
    "\n",
    "# å®Œæ•´éˆ\n",
    "parallel_model_chain = (\n",
    "    prompt_template \n",
    "    | model \n",
    "    | StrOutputParser() \n",
    "    | parallel_chain \n",
    "    | RunnableLambda(combine_results)\n",
    ")\n",
    "\n",
    "print(\"âœ… ä¸¦è¡Œæ¨¡å‹éˆå·²å»ºç«‹ï¼\")\n",
    "print(\"æµç¨‹ï¼šä¸» Prompt â†’ ä¸»æ¨¡å‹ â†’ ä¸¦è¡Œè™•ç†ï¼ˆæ ¼å¼åŒ– + å“è³ªæª¢æŸ¥ + èªæ°£åˆ†æï¼‰â†’ åˆä½µçµæœ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_email = \"\"\"\n",
    "æ‚¨å¥½ï¼Œ\n",
    "\n",
    "æˆ‘æœ€è¿‘è³¼è²·äº†è²´å…¬å¸çš„ç”¢å“ï¼Œä½†æ˜¯ç™¼ç¾åŒ…è£æœ‰æå£ã€‚\n",
    "è«‹å•å¯ä»¥é€€è²¨æˆ–æ›è²¨å—ï¼Ÿ\n",
    "\n",
    "ç‹å°æ˜\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ä¸¦è¡Œæ¨¡å‹éˆæ¸¬è©¦çµæœï¼š\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "result = parallel_model_chain.invoke({\"email_content\": customer_email})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š ä¸¦è¡Œæ¨¡å‹éˆç¸½çµ\n",
    "\n",
    "### âœ… å„ªé»\n",
    "- **æ•ˆç‡é«˜**ï¼šä¸¦è¡ŒåŸ·è¡Œï¼Œç¯€çœç¸½é«”æ™‚é–“\n",
    "- **å¤šè§’åº¦åˆ†æ**ï¼šåŒæ™‚å¾ä¸åŒè§’åº¦è©•ä¼°å…§å®¹\n",
    "- **çµæ§‹æ¸…æ™°**ï¼šæ¯å€‹åˆ†æä»»å‹™ç¨ç«‹ä¸”æ˜ç¢º\n",
    "\n",
    "### âš ï¸ æ³¨æ„äº‹é …\n",
    "- **è³‡æºæ¶ˆè€—**ï¼šåŒæ™‚èª¿ç”¨å¤šå€‹æ¨¡å‹æœƒå¢åŠ è³‡æºä½¿ç”¨\n",
    "- **éœ€è¦åˆä½µé‚è¼¯**ï¼šéœ€è¦é¡å¤–è™•ç†ä¾†åˆä½µçµæœ\n",
    "\n",
    "### ğŸ”— ç›¸é—œæŠ€è¡“\n",
    "- [ä¸²è¯æ¨¡å‹éˆ](5_chains_sequential_model_ollama.ipynb)ï¼šé †åºåŸ·è¡Œ\n",
    "- [é–‰åŒ…æ¨¡å‹éˆ](7_chains_closure_model_ollama.ipynb)ï¼šéˆæ´»æ§åˆ¶\n",
    "- [å‹•æ…‹æç¤ºéˆ](9_chains_dynamic_prompt_ollama.ipynb)ï¼šæ™ºèƒ½è·¯ç”±"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}