{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# å‹•æ…‹æç¤ºéˆ (Dynamic Prompt Chains) - Gemini ç‰ˆæœ¬ â­\n",
    "\n",
    "ä½¿ç”¨ Google Gemini å¯¦ç¾å‹•æ…‹ Prompt æº–å‚™ï¼Œé€™æ˜¯è™•ç†è¤‡é›œé‚è¼¯çš„æ¨è–¦æœ€ä½³å¯¦è¸ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableLambda\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "load_dotenv()\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-exp\")\n",
    "print(\"âœ… Gemini æ¨¡å‹å·²å»ºç«‹\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ä½ æ˜¯å°ˆæ¥­çš„å®¢æœä»£è¡¨ã€‚\"),\n",
    "    (\"human\", \"è«‹å›è¦†ï¼š\\n\\n{email_content}\")\n",
    "])\n",
    "\n",
    "def prepare_quality_check_prompt(reply):\n",
    "    formatted = f\"è¦ªæ„›çš„å®¢æˆ¶ï¼Œ\\n\\n{reply}\\n\\næ­¤è‡´\\nå®¢æœåœ˜éšŠ\"\n",
    "    \n",
    "    if \"é€€è²¨\" in reply or \"æ›è²¨\" in reply:\n",
    "        focus = \"è«‹ç‰¹åˆ¥æ³¨æ„é€€æ›è²¨æ”¿ç­–èªªæ˜æ˜¯å¦æ¸…æ¥šã€‚\"\n",
    "    elif \"æŠ±æ­‰\" in reply:\n",
    "        focus = \"è«‹ç‰¹åˆ¥æ³¨æ„é“æ­‰èª æ„å’Œè£œå„Ÿæªæ–½ã€‚\"\n",
    "    else:\n",
    "        focus = \"è«‹è©•ä¼°æ•´é«”å°ˆæ¥­åº¦å’Œå‹å–„åº¦ã€‚\"\n",
    "    \n",
    "    return {\"email\": formatted, \"focus\": focus}\n",
    "\n",
    "dynamic_quality_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ä½ æ˜¯éƒµä»¶å“è³ªå°ˆå®¶ã€‚{focus}\"),\n",
    "    (\"human\", \"è©•ä¼°ï¼š\\n\\n{email}\")\n",
    "])\n",
    "\n",
    "dynamic_chain = (\n",
    "    prompt_template\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    "    | RunnableLambda(prepare_quality_check_prompt)\n",
    "    | dynamic_quality_prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"âœ… å‹•æ…‹æç¤ºéˆå·²å»ºç«‹ï¼ˆæ¨è–¦æœ€ä½³å¯¦è¸ï¼‰\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = dynamic_chain.invoke({\"email_content\": \"ç”¢å“åŒ…è£æå£ï¼Œå¯ä»¥é€€æ›è²¨å—ï¼Ÿ\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š ç¸½çµ\n",
    "\n",
    "å‹•æ…‹æç¤ºéˆæ˜¯æœ€æ¨è–¦çš„æ–¹æ³•ï¼Œçµåˆäº†é«˜éˆæ´»æ€§å’Œå„ªç§€çš„å¯ç¶­è­·æ€§ã€‚\n",
    "\n",
    "### ğŸ”— ç›¸é—œæŠ€è¡“\n",
    "- [ä¸²è¯æ¨¡å‹éˆ](5_chains_sequential_model_gemini.ipynb)\n",
    "- [é–‰åŒ…æ¨¡å‹éˆ](7_chains_closure_model_gemini.ipynb)\n",
    "- [ä¸¦è¡Œæ¨¡å‹éˆ](8_chains_parallel_model_gemini.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
