# ç¸½çµèˆ‡åƒè€ƒ

> ğŸ“– **é–±è®€æ™‚é–“**ï¼šç´„ 10 åˆ†é˜ | [è¿”å›ä¸»é ](README.md)

æœ¬æ–‡æª”æä¾›å¿«é€ŸæŸ¥è©¢è¡¨ã€ç¸½çµå’Œå¸¸ç”¨åƒè€ƒè³‡æ–™ï¼Œæ–¹ä¾¿ä½ éš¨æ™‚æŸ¥é–±ã€‚

---

## ğŸ“‘ ç›®éŒ„

- [åç¨® Chain é¡å‹å°ç…§è¡¨](#-åç¨®-chain-é¡å‹å°ç…§è¡¨)
- [æ ¸å¿ƒæ¦‚å¿µå›é¡§](#-æ ¸å¿ƒæ¦‚å¿µå›é¡§)
- [å¸¸è¦‹å•é¡Œ FAQ](#-å¸¸è¦‹å•é¡Œ-faq)
- [ç–‘é›£æ’è§£](#ï¸-ç–‘é›£æ’è§£)
- [è¡“èªè¡¨](#-è¡“èªè¡¨)
- [ä¸‹ä¸€æ­¥å­¸ç¿’å»ºè­°](#-ä¸‹ä¸€æ­¥å­¸ç¿’å»ºè­°)
- [ç›¸é—œè³‡æº](#-ç›¸é—œè³‡æº)

---

## ğŸ”¢ åç¨® Chain é¡å‹å°ç…§è¡¨

| é †åº | é¡å‹ | é›£åº¦ | ä¸»è¦ç”¨é€” | é—œéµæŠ€è¡“ | é©ç”¨å ´æ™¯ | å¯¦éš›ç¯„ä¾‹ |
|------|------|------|----------|----------|----------|----------|
| **1** | [åŸºç¤éˆ](CHAINS_GUIDE.md#1ï¸âƒ£-åŸºç¤éˆ-basic-chains---å…¥é–€å¿…å­¸) | â­ | åŸºæœ¬ AI æµç¨‹ | LCEL èªæ³• | å…¥é–€å­¸ç¿’ã€ç°¡å–®å•ç­” | æ™ºèƒ½å•ç­”ç³»çµ± |
| **2** | [æ“´å±•éˆ](CHAINS_GUIDE.md#2ï¸âƒ£-æ“´å±•éˆ-extended-chains---è‡ªå®šç¾©è™•ç†) | â­â­ | è‡ªå®šç¾©è™•ç† | RunnableLambda | æ•¸æ“šè½‰æ›ã€å¾Œè™•ç† | æ™ºèƒ½éƒµä»¶å›è¦† |
| **3** | [ä¸¦è¡Œéˆ](CHAINS_GUIDE.md#3ï¸âƒ£-ä¸¦è¡Œéˆ-parallel-chains---æ•ˆç‡å„ªåŒ–) | â­â­â­ | æ•ˆç‡å„ªåŒ– | RunnableParallel | å¤šä»»å‹™è™•ç†ã€æ•ˆèƒ½æå‡ | é¤å»³è©•è«–åˆ†æ |
| **4** | [åˆ†æ”¯éˆ](CHAINS_GUIDE.md#4ï¸âƒ£-åˆ†æ”¯éˆ-branching-chains---æ™ºèƒ½è·¯ç”±) | â­â­â­ | æ™ºèƒ½è·¯ç”± | RunnableBranch | æ¢ä»¶åˆ¤æ–·ã€è‡ªå‹•åˆ†é¡ | æ™ºèƒ½å­¸ç¿’åŠ©æ‰‹ |
| **5** | [ä¸²è¯æ¨¡å‹éˆ](CHAINS_GUIDE.md#5ï¸âƒ£-ä¸²è¯æ¨¡å‹éˆ-sequential-model-chains---å¤šæ­¥é©Ÿè™•ç†) | â­â­â­ | å¤šæ­¥é©Ÿè™•ç† | å¤šæ¨¡å‹é †åºèª¿ç”¨ | å…§å®¹é€æ­¥å„ªåŒ– | éƒµä»¶ç”Ÿæˆâ†’æ ¼å¼åŒ–â†’æ”¹é€² |
| **6** | [å…§éƒ¨é‹ä½œ](CHAINS_GUIDE.md#6ï¸âƒ£-éˆçš„å…§éƒ¨é‹ä½œ-chains-under-the-hood---æ·±å…¥ç†è§£) | â­â­â­â­ | åº•å±¤æ§åˆ¶ | RunnableSequence | é™¤éŒ¯å„ªåŒ–ã€ç²¾ç´°æ§åˆ¶ | æ–‡å­—æ‘˜è¦ç³»çµ± |
| **7** | [é–‰åŒ…æ¨¡å‹éˆ](CHAINS_GUIDE.md#7ï¸âƒ£-é–‰åŒ…æ¨¡å‹éˆ-closure-model-chains---å®Œå…¨æ§åˆ¶) | â­â­â­â­ | å®Œå…¨æ§åˆ¶ | Lambda é–‰åŒ…èª¿ç”¨ | è¤‡é›œé‚è¼¯ã€æ—¥èªŒè¨˜éŒ„ | éƒµä»¶å“è³ªæª¢æŸ¥ |
| **8** | [ä¸¦è¡Œæ¨¡å‹éˆ](CHAINS_GUIDE.md#8ï¸âƒ£-ä¸¦è¡Œæ¨¡å‹éˆ-parallel-model-chains---å¤šè§’åº¦åˆ†æ) | â­â­â­â­ | å¤šè§’åº¦åˆ†æ | ä¸¦è¡Œæ¨¡å‹èª¿ç”¨ | å¤šç¶­åº¦è©•ä¼° | éƒµä»¶å“è³ª+èªæ°£åˆ†æ |
| **9** | [å‹•æ…‹æç¤ºéˆ](CHAINS_GUIDE.md#9ï¸âƒ£-å‹•æ…‹æç¤ºéˆ-dynamic-prompt-chains---æ¨è–¦æœ€ä½³å¯¦è¸-â­) â­ | â­â­â­â­â­ | æ™ºèƒ½è‡ªé©æ‡‰ | å‹•æ…‹ Prompt æº–å‚™ | æ ¹æ“šå…§å®¹èª¿æ•´é‚è¼¯ | æ™ºèƒ½éƒµä»¶åˆ†æ |
| **10** | [Lambda æ¨¡å‹æ•´åˆ](CHAINS_GUIDE.md#ğŸ”Ÿ-lambda-æ¨¡å‹æ•´åˆ-lambda-model-integration---ç¶œåˆé€²éš) | â­â­â­â­â­ | ç¶œåˆé€²éš | å››ç¨®æ–¹æ³•ç¶œåˆ | å­¸ç¿’åƒè€ƒã€æ–¹æ³•å°æ¯” | ç¶œåˆéƒµä»¶è™•ç† |

---

## ğŸ¯ æ ¸å¿ƒæ¦‚å¿µå›é¡§

### Chain æ˜¯ä»€éº¼ï¼Ÿ

**Chain** æ˜¯ LangChain çš„æ ¸å¿ƒï¼Œå®ƒè² è²¬å°‡å„ç¨®åŠŸèƒ½æ¨¡çµ„ä¸²è¯æˆè‡ªå‹•åŒ–çš„å·¥ä½œæµã€‚

```python
# æœ€åŸºæœ¬çš„ Chain
chain = prompt_template | model | StrOutputParser()
```

### LCEL æ˜¯ä»€éº¼ï¼Ÿ

**LCEL (LangChain Expression Language)** æ˜¯ç•¶å‰å®šç¾©å’Œå»ºç«‹ Chain çš„æœ€ä½³å¯¦è¸ï¼Œå®ƒä½¿ç”¨ç›´è§€çš„ç®¡é“ç¬¦è™Ÿ `|` ä¾†çµ„åˆå…ƒä»¶ã€‚

### LCEL çš„æ ¸å¿ƒå„ªå‹¢

1. **ç›´è§€æ˜“è®€**ï¼š`prompt | model | parser` æ¸…æ¥šè¡¨é”è³‡æ–™æµå‹•
2. **å¼·å¤§åŠŸèƒ½**ï¼šè‡ªå‹•æ”¯æ´ streamingã€batchã€async
3. **çµ„åˆæ€§å¼·**ï¼šå¯è¼•æ˜“ä¸²æ¥è¤‡é›œå…ƒä»¶

### æ¨è–¦çš„å­¸ç¿’é †åº

```
åŸºç¤å…¥é–€ â†’ é€²éšæ‡‰ç”¨ â†’ æ·±åº¦æŒæ¡ â†’ æœ€ä½³å¯¦è¸
   â†“           â†“           â†“          â†“
 1ï¸âƒ£2ï¸âƒ£      3ï¸âƒ£4ï¸âƒ£5ï¸âƒ£      6ï¸âƒ£7ï¸âƒ£8ï¸âƒ£      9ï¸âƒ£ğŸ”Ÿ
```

---

## â“ å¸¸è¦‹å•é¡Œ FAQ

### Q1: ä»€éº¼æ™‚å€™ä½¿ç”¨ä¸¦è¡Œéˆï¼Ÿ

**A:** ç•¶ä½ éœ€è¦åŒæ™‚åŸ·è¡Œå¤šå€‹**ç¨ç«‹**çš„åˆ†æä»»å‹™æ™‚ã€‚

```python
# ä¾‹å¦‚ï¼šåŒæ™‚åˆ†æç”¢å“çš„å„ªé»å’Œç¼ºé»
parallel_chain = RunnableParallel(
    pros=analyze_pros_chain,
    cons=analyze_cons_chain
)
```

**é—œéµ**ï¼šä»»å‹™å¿…é ˆæ˜¯ç¨ç«‹çš„ï¼Œäº’ä¸ä¾è³´ã€‚

---

### Q2: åˆ†æ”¯éˆå’Œä¸¦è¡Œéˆçš„å·®åˆ¥ï¼Ÿ

**A:**
- **åˆ†æ”¯éˆ**ï¼šæ ¹æ“šæ¢ä»¶**é¸æ“‡ä¸€å€‹**è™•ç†è·¯å¾‘
- **ä¸¦è¡Œéˆ**ï¼š**åŒæ™‚åŸ·è¡Œå¤šå€‹**è™•ç†è·¯å¾‘

```python
# åˆ†æ”¯éˆï¼šåªåŸ·è¡Œä¸€å€‹
branches = RunnableBranch(
    (condition1, chain1),  # åªåŸ·è¡Œç¬¦åˆæ¢ä»¶çš„é€™ä¸€å€‹
    (condition2, chain2),
    default_chain
)

# ä¸¦è¡Œéˆï¼šå…¨éƒ¨åŸ·è¡Œ
parallel = RunnableParallel(
    task1=chain1,  # åŒæ™‚åŸ·è¡Œ
    task2=chain2,  # åŒæ™‚åŸ·è¡Œ
    task3=chain3   # åŒæ™‚åŸ·è¡Œ
)
```

---

### Q3: å¦‚ä½•é¸æ“‡ Ollama é‚„æ˜¯ Geminiï¼Ÿ

**A:**

| é¸æ“‡ Ollama å¦‚æœä½ ... | é¸æ“‡ Gemini å¦‚æœä½ ... |
|---------------------|---------------------|
| âœ… æ³¨é‡éš±ç§å’Œæ•¸æ“šå®‰å…¨ | âœ… éœ€è¦æœ€æ–° AI èƒ½åŠ› |
| âœ… æƒ³è¦æ§åˆ¶æˆæœ¬ | âœ… è¿½æ±‚æœ€é«˜ç²¾åº¦ |
| âœ… éœ€è¦é›¢ç·šä½¿ç”¨ | âœ… æƒ³è¦é›²ç«¯éƒ¨ç½² |
| âœ… æœ‰è¶³å¤ çš„ç¡¬é«”è³‡æº | âœ… ä¸æƒ³ç¶­è­·ç’°å¢ƒ |

**å»ºè­°**ï¼šé–‹ç™¼ç”¨ Ollamaï¼Œç”Ÿç”¢ç”¨ Geminiã€‚

---

### Q4: å¯ä»¥æ··åˆä½¿ç”¨ä¸åŒé¡å‹çš„éˆå—ï¼Ÿ

**A:** ç•¶ç„¶å¯ä»¥ï¼å¯¦éš›ä¸Šï¼Œè¤‡é›œçš„æ‡‰ç”¨é€šå¸¸æœƒçµ„åˆå¤šç¨®éˆé¡å‹ã€‚

```python
# æ··åˆä½¿ç”¨ç¯„ä¾‹
complex_chain = (
    prompt
    | model
    | StrOutputParser()
    | RunnableBranch(  # åˆ†æ”¯éˆ
        (condition1, parallel_chain1),  # ä¸¦è¡Œéˆ
        (condition2, sequential_chain),  # ä¸²è¯éˆ
        default_chain
    )
)
```

---

### Q5: Lambda æ¨¡å‹æ•´åˆä»€éº¼æ™‚å€™ä½¿ç”¨ï¼Ÿ

**A:** æ¨è–¦ä½¿ç”¨**å‹•æ…‹æç¤ºéˆ**ï¼ˆæ–¹æ³• 4ï¼‰ï¼Œè€Œä¸æ˜¯é–‰åŒ…æ–¹å¼ã€‚

```python
# âœ… æ¨è–¦ï¼šå‹•æ…‹æç¤ºéˆ
def prepare_prompt(reply):
    # åªæº–å‚™æ•¸æ“šï¼Œä¸èª¿ç”¨æ¨¡å‹
    return {"email": reply, "focus": determine_focus(reply)}

chain = (
    RunnableLambda(prepare_prompt)
    | dynamic_prompt  # Prompt æ¸…æ™°å¯è¦‹
    | model           # æ¨¡å‹èª¿ç”¨æ¸…æ™°å¯è¦‹
)

# âŒ ä¸æ¨è–¦ï¼šé–‰åŒ…æ–¹å¼
def process(reply):
    result = model.invoke(...)  # éš±è—åœ¨å‡½æ•¸å…§ï¼Œä¸æ˜“ç¶­è­·
    return result
```

---

## ğŸ› ï¸ ç–‘é›£æ’è§£

### å•é¡Œ 1ï¼šChain åŸ·è¡Œå¾ˆæ…¢

**å¯èƒ½åŸå› **ï¼š
1. é †åºåŸ·è¡Œå¤šå€‹ç¨ç«‹ä»»å‹™
2. æ¨¡å‹åƒæ•¸è¨­ç½®ä¸ç•¶
3. æ²’æœ‰ä½¿ç”¨ batch è™•ç†

**è§£æ±ºæ–¹æ¡ˆ**ï¼š

```python
# âŒ æ…¢ï¼šé †åºåŸ·è¡Œ
result1 = chain1.invoke(input1)
result2 = chain2.invoke(input2)

# âœ… å¿«ï¼šä¸¦è¡ŒåŸ·è¡Œ
parallel_chain = RunnableParallel(r1=chain1, r2=chain2)
results = parallel_chain.invoke({"input1": ..., "input2": ...})

# âœ… å¿«ï¼šbatch è™•ç†
results = chain.batch([input1, input2, input3])
```

---

### å•é¡Œ 2ï¼šè¼¸å‡ºæ ¼å¼ä¸ç©©å®š

**å¯èƒ½åŸå› **ï¼š
1. Prompt ä¸å¤ æ˜ç¢º
2. æº«åº¦åƒæ•¸å¤ªé«˜
3. æ²’æœ‰ä½¿ç”¨ Output Parser

**è§£æ±ºæ–¹æ¡ˆ**ï¼š

```python
# âœ… æ˜ç¢ºçš„ Prompt
prompt = ChatPromptTemplate.from_template(
    "è«‹ä»¥ JSON æ ¼å¼å›ç­”ï¼Œå¿…é ˆåŒ…å« 'answer' å’Œ 'confidence' æ¬„ä½ï¼š{question}"
)

# âœ… é™ä½æº«åº¦
model = OllamaLLM(model="llama3.2", temperature=0.1)

# âœ… ä½¿ç”¨çµæ§‹åŒ–è¼¸å‡º
from langchain.output_parsers import PydanticOutputParser
parser = PydanticOutputParser(pydantic_object=MySchema)
```

---

### å•é¡Œ 3ï¼šè¨˜æ†¶é«”ä¸è¶³

**å¯èƒ½åŸå› **ï¼š
1. æ¨¡å‹å¤ªå¤§
2. åŒæ™‚è™•ç†å¤ªå¤šè«‹æ±‚
3. æ²’æœ‰é‡‹æ”¾è³‡æº

**è§£æ±ºæ–¹æ¡ˆ**ï¼š

```python
# âœ… ä½¿ç”¨è¼ƒå°çš„æ¨¡å‹
model = OllamaLLM(model="llama3.2:1b")  # è€Œä¸æ˜¯ 70b

# âœ… é™åˆ¶ä¸¦è¡Œæ•¸é‡
from concurrent.futures import ThreadPoolExecutor
with ThreadPoolExecutor(max_workers=3) as executor:
    results = list(executor.map(chain.invoke, inputs))

# âœ… åŠæ™‚æ¸…ç†
import gc
gc.collect()
```

---

### å•é¡Œ 4ï¼šéŒ¯èª¤è™•ç†ä¸ç•¶

**è§£æ±ºæ–¹æ¡ˆ**ï¼š

```python
from langchain.schema.runnable import RunnableLambda

def safe_invoke(input_data):
    try:
        return chain.invoke(input_data)
    except TimeoutError:
        return {"error": "timeout"}
    except Exception as e:
        logger.error(f"éŒ¯èª¤: {e}")
        return {"error": str(e)}

safe_chain = RunnableLambda(safe_invoke)
```

---

## ğŸ“– è¡“èªè¡¨

| è¡“èª | èªªæ˜ |
|------|------|
| **Chain** | å°‡å¤šå€‹ AI å…ƒä»¶ä¸²è¯èµ·ä¾†çš„å·¥ä½œæµ |
| **LCEL** | LangChain Expression Languageï¼Œä½¿ç”¨ `\|` ç¬¦è™Ÿçµ„åˆå…ƒä»¶çš„èªæ³• |
| **Runnable** | å¯åŸ·è¡Œçš„å…ƒä»¶ï¼Œæ‰€æœ‰ Chain éƒ½æ˜¯ Runnable |
| **RunnableLambda** | å°‡ Python å‡½æ•¸åŒ…è£æˆ Runnable |
| **RunnableParallel** | ä¸¦è¡ŒåŸ·è¡Œå¤šå€‹ Runnable |
| **RunnableBranch** | æ ¹æ“šæ¢ä»¶é¸æ“‡ä¸åŒçš„ Runnable |
| **RunnableSequence** | é †åºåŸ·è¡Œå¤šå€‹ Runnable |
| **Prompt Template** | æç¤ºæ¨¡æ¿ï¼Œç”¨æ–¼æ ¼å¼åŒ–è¼¸å…¥ |
| **Output Parser** | è¼¸å‡ºè§£æå™¨ï¼Œç”¨æ–¼è§£ææ¨¡å‹è¼¸å‡º |
| **Streaming** | ä¸²æµè¼¸å‡ºï¼Œåƒ ChatGPT ä¸€æ¨£é€å­—é¡¯ç¤º |
| **Batch** | æ‰¹æ¬¡è™•ç†ï¼Œä¸€æ¬¡è™•ç†å¤šå€‹è¼¸å…¥ |
| **Async** | éåŒæ­¥èª¿ç”¨ï¼Œæå‡ä¸¦ç™¼æ•ˆèƒ½ |
| **RAG** | Retrieval-Augmented Generationï¼Œæª¢ç´¢å¢å¼·ç”Ÿæˆ |
| **Memory** | è¨˜æ†¶æ¨¡çµ„ï¼Œç”¨æ–¼ä¿å­˜å°è©±æ­·å² |
| **Agent** | æ™ºèƒ½ä»£ç†ï¼Œèƒ½è‡ªä¸»ä½¿ç”¨å·¥å…·å’Œæ±ºç­– |

---

## ğŸ”¥ ä¸‹ä¸€æ­¥å­¸ç¿’å»ºè­°

### é€²éšä¸»é¡Œ

#### 1. RAG (æª¢ç´¢å¢å¼·ç”Ÿæˆ)
çµåˆå¤–éƒ¨è³‡æ–™åº«çš„æ™ºèƒ½å•ç­”ç³»çµ±ã€‚

```python
# RAG Chain ç¯„ä¾‹
rag_chain = (
    {"context": retriever, "question": RunnablePassthrough()}
    | prompt
    | model
    | StrOutputParser()
)
```

**æ¨è–¦è³‡æº**ï¼š
- [LangChain RAG æ•™ç¨‹](https://python.langchain.com/docs/use_cases/question_answering/)

---

#### 2. Agents
è®“ AI è‡ªä¸»ä½¿ç”¨å·¥å…·å’Œæ±ºç­–ã€‚

```python
# Agent ç¯„ä¾‹
from langchain.agents import create_react_agent

agent = create_react_agent(llm, tools, prompt)
```

**æ¨è–¦è³‡æº**ï¼š
- [LangChain Agents æ•™ç¨‹](https://python.langchain.com/docs/modules/agents/)

---

#### 3. Memory
å¯¦ç¾å°è©±è¨˜æ†¶å’Œä¸Šä¸‹æ–‡ç®¡ç†ã€‚

```python
# Memory ç¯„ä¾‹
from langchain.memory import ConversationBufferMemory

memory = ConversationBufferMemory()
```

**æ¨è–¦è³‡æº**ï¼š
- [LangChain Memory æ•™ç¨‹](https://python.langchain.com/docs/modules/memory/)

---

#### 4. Streaming
å¯¦ç¾å³æ™‚å›æ‡‰å’Œä¸²æµè¼¸å‡ºã€‚

```python
# å·²å…§å»ºåœ¨ LCEL ä¸­
for chunk in chain.stream(input):
    print(chunk, end="", flush=True)
```

---

#### 5. Batch Processing
å¤§é‡è³‡æ–™çš„æ‰¹æ¬¡è™•ç†ã€‚

```python
# å·²å…§å»ºåœ¨ LCEL ä¸­
results = chain.batch(inputs)
```

---

### å¯¦æˆ°å°ˆæ¡ˆå»ºè­°

#### åˆç´šï¼ˆå®Œæˆå¿«é€Ÿå¯¦æˆ°è·¯å¾‘å¾Œï¼‰
1. **FAQ æ™ºèƒ½å•ç­”ç³»çµ±** - åŸºç¤éˆ + æ“´å±•éˆ
2. **å•†å“è©•è«–åˆ†æå·¥å…·** - ä¸¦è¡Œéˆ
3. **éƒµä»¶è‡ªå‹•å›è¦†ç³»çµ±** - åˆ†æ”¯éˆ

#### é€²éšï¼ˆå®Œæˆæ·±åº¦ç†è§£è·¯å¾‘å¾Œï¼‰
4. **å¤šåŠŸèƒ½å…§å®¹å‰µä½œåŠ©æ‰‹** - ä¸²è¯æ¨¡å‹éˆ + å‹•æ…‹æç¤ºéˆ
5. **æ™ºèƒ½å®¢æœå®Œæ•´ç³»çµ±** - åˆ†æ”¯éˆ + ä¸¦è¡Œéˆ + Memory
6. **ä¼æ¥­ç´šå…§å®¹åˆ†æå¹³å°** - ä¸¦è¡Œæ¨¡å‹éˆ + å‹•æ…‹æç¤ºéˆ

---

## ğŸ“š ç›¸é—œè³‡æº

### å®˜æ–¹æ–‡æª”
- [LangChain å®˜æ–¹æ–‡æª”](https://python.langchain.com/)
- [LCEL è©³ç´°æŒ‡å—](https://python.langchain.com/docs/expression_language/)
- [LangChain API åƒè€ƒ](https://python.langchain.com/api_reference/)

### ç¤¾ç¾¤è³‡æº
- [LangChain GitHub](https://github.com/langchain-ai/langchain)
- [LangChain Discord](https://discord.gg/langchain)
- [LangChain Twitter](https://twitter.com/langchainai)

### æ¨¡å‹è³‡æº
- [Ollama å®˜ç¶²](https://ollama.ai/)
- [Ollama æ¨¡å‹åº«](https://ollama.ai/library)
- [Google Gemini API](https://ai.google.dev/)

### å·¥å…·è³‡æº
- [Gradio å®˜æ–¹æ–‡æª”](https://www.gradio.app/)
- [Python dotenv](https://pypi.org/project/python-dotenv/)

---

## ğŸ“Š å­¸ç¿’æˆæœæª¢æ ¸è¡¨

å®Œæˆæ‰€æœ‰å­¸ç¿’å¾Œï¼Œä½ æ‡‰è©²èƒ½å¤ ï¼š

### åŸºç¤èƒ½åŠ›
- [ ] ç†è§£ Chain çš„æ¦‚å¿µå’Œç”¨é€”
- [ ] ä½¿ç”¨ LCEL èªæ³•å»ºç«‹åŸºæœ¬ Chain
- [ ] çŸ¥é“ä½•æ™‚ä½¿ç”¨ä¸åŒé¡å‹çš„ Chain
- [ ] èƒ½é–±è®€å’Œç†è§£ä»–äººçš„ Chain ä»£ç¢¼

### å¯¦æˆ°èƒ½åŠ›
- [ ] ç¨ç«‹é–‹ç™¼ç°¡å–®çš„ AI æ‡‰ç”¨
- [ ] ä½¿ç”¨ä¸¦è¡Œéˆæå‡æ•ˆç‡
- [ ] å¯¦ç¾æ¢ä»¶åˆ¤æ–·å’Œè·¯ç”±
- [ ] è¨­è¨ˆå¤šæ­¥é©Ÿè™•ç†æµç¨‹

### é€²éšèƒ½åŠ›
- [ ] ç†è§£ LCEL çš„åº•å±¤æ©Ÿåˆ¶
- [ ] å„ªåŒ– Chain çš„æ•ˆèƒ½
- [ ] è™•ç†éŒ¯èª¤å’Œé‚Šç•Œæƒ…æ³
- [ ] è¨­è¨ˆå¯ç¶­è­·çš„è¤‡é›œç³»çµ±

### å°ˆå®¶èƒ½åŠ›
- [ ] ç‚ºåœ˜éšŠåˆ¶å®šæœ€ä½³å¯¦è¸
- [ ] åˆ†æå’Œå„ªåŒ–ç¾æœ‰ç³»çµ±
- [ ] è¨­è¨ˆä¼æ¥­ç´šæ‡‰ç”¨æ¶æ§‹
- [ ] æŒ‡å°ä»–äººå­¸ç¿’ LangChain

---

## ğŸ“ çµèª

æ­å–œä½ å®Œæˆ LangChain Chains çš„å­¸ç¿’ï¼

è¨˜ä½ï¼š
- âœ¨ **å„ªå…ˆä½¿ç”¨å‹•æ…‹æç¤ºéˆ**ï¼ˆæ–¹æ³• 9ï¼‰
- ğŸš€ **å¾ç°¡å–®é–‹å§‹**ï¼Œä¸è¦éåº¦è¨­è¨ˆ
- ğŸ“ **å¤šå¯¦ä½œç·´ç¿’**ï¼Œç†è«–çµåˆå¯¦è¸
- ğŸ” **æŒçºŒå„ªåŒ–**ï¼Œè¿½æ±‚æ›´å¥½çš„è§£æ±ºæ–¹æ¡ˆ

ç¥ä½ åœ¨ AI é–‹ç™¼çš„é“è·¯ä¸Šè¶Šèµ°è¶Šé ï¼ğŸ‰

---

## ğŸ”— ç›¸é—œæ–‡æª”

- ğŸ“– [Chain é¡å‹å®Œæ•´æŒ‡å—](CHAINS_GUIDE.md) - 10 ç¨® Chain è©³ç´°èªªæ˜
- ğŸ“š [å­¸ç¿’è·¯å¾‘å»ºè­°](LEARNING_PATHS.md) - é¸æ“‡é©åˆä½ çš„å­¸ç¿’è·¯ç·š
- ğŸ’¼ [å¯¦æˆ°æ¡ˆä¾‹](PRACTICAL_CASES.md) - çœŸå¯¦æ‡‰ç”¨å ´æ™¯
- ğŸ”§ [æŠ€è¡“æ·±å…¥æŒ‡å—](TECHNICAL_GUIDE.md) - LCEL å’Œæœ€ä½³å¯¦è¸
- [è¿”å›ä¸»é ](README.md)
