"""
æ¡ˆä¾‹ 1: æ™ºèƒ½å®¢æœç³»çµ±
åŠŸèƒ½ï¼šè‡ªå‹•è™•ç†å®¢æˆ¶è«®è©¢ï¼Œæ ¹æ“šå•é¡Œé¡å‹æä¾›ä¸åŒçš„å›æ‡‰
ä½¿ç”¨æŠ€è¡“ï¼šåˆ†æ”¯éˆ (RunnableBranch) + æ“´å±•éˆ (RunnableLambda)

ğŸ¤– AI è¼”åŠ©æç¤ºï¼š
ä½ å¯ä»¥ä½¿ç”¨ AI å”åŠ©å®Œæˆä»¥ä¸‹ä»»å‹™ï¼š

1. å»ºç«‹åŸºç¤çµæ§‹
   Prompt: "å¹«æˆ‘ä½¿ç”¨ langchain å’Œ gradio å»ºç«‹ä¸€å€‹æ™ºèƒ½å®¢æœç³»çµ±çš„åŸºç¤æ¶æ§‹ï¼Œéœ€è¦åŒ…å«ç’°å¢ƒè¨­å®šã€æ¨¡å‹åˆå§‹åŒ–ã€ä»¥åŠ Gradio ä»‹é¢"

2. è¨­è¨ˆ Prompt æ¨¡æ¿
   Prompt: "ç‚ºå®¢æœç³»çµ±è¨­è¨ˆ 4 ç¨®ä¸åŒçš„ ChatPromptTemplateï¼šæŠ•è¨´è™•ç†ã€ç”¢å“è«®è©¢ã€é€€æ›è²¨è«‹æ±‚ã€ä¸€èˆ¬å•é¡Œï¼Œæ¯ç¨®éƒ½è¦æœ‰é©ç•¶çš„ system å’Œ human è¨Šæ¯"

3. å¯¦ä½œåˆ†æ”¯é‚è¼¯
   Prompt: "ä½¿ç”¨ RunnableBranch å»ºç«‹æ¢ä»¶åˆ†æ”¯ï¼Œæ ¹æ“šå®¢æˆ¶å•é¡Œä¸­çš„é—œéµå­—ï¼ˆæŠ•è¨´ã€é€€è²¨ã€åƒ¹æ ¼ç­‰ï¼‰è‡ªå‹•é¸æ“‡å°æ‡‰çš„è™•ç†æµç¨‹"

4. æ ¼å¼åŒ–è¼¸å‡º
   Prompt: "å»ºç«‹ä¸€å€‹ format_customer_service_response å‡½æ•¸ï¼Œä½¿ç”¨ RunnableLambda åŒ…è£ï¼Œç‚ºå®¢æœå›è¦†æ·»åŠ ç¾åŒ–æ ¼å¼ã€æ™‚é–“æˆ³è¨˜å’Œè¯çµ¡è³‡è¨Š"

5. å®Œæ•´æ•´åˆ
   Prompt: "å°‡åˆ†æ”¯éˆå’Œæ ¼å¼åŒ–å‡½æ•¸çµ„åˆæˆå®Œæ•´çš„ customer_service_chainï¼Œä¸¦æ•´åˆåˆ° Gradio ä»‹é¢ä¸­"
"""

import gradio as gr
from dotenv import load_dotenv
from langchain.prompts import ChatPromptTemplate
from langchain.schema.output_parser import StrOutputParser
from langchain.schema.runnable import RunnableBranch, RunnableLambda
from langchain_ollama.llms import OllamaLLM
from datetime import datetime

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

# å»ºç«‹æ¨¡å‹
model = OllamaLLM(model="llama3.2:latest")

# å®šç¾©ä¸åŒé¡å‹çš„å®¢æœæ¨¡æ¿
# ğŸ’¡ AI æç¤ºï¼šå¯ä»¥è«‹ AI å¹«ä½ è¨­è¨ˆæ›´å¤šå°ˆæ¥­çš„ prompt æ¨¡æ¿
# Prompt: "ç‚ºå®¢æœç³»çµ±å†å¢åŠ  2 ç¨®å ´æ™¯ï¼šæŠ€è¡“æ”¯æ´å’Œå¸³è™Ÿå•é¡Œï¼Œè¨­è¨ˆå°æ‡‰çš„ ChatPromptTemplate"
complaint_template = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯å°ˆæ¥­çš„å®¢æœäººå“¡ï¼Œè™•ç†å®¢æˆ¶æŠ•è¨´ã€‚è«‹ä¿æŒåŒç†å¿ƒï¼Œæä¾›è§£æ±ºæ–¹æ¡ˆã€‚\næ‰€æœ‰å›è¦†ä½¿ç”¨ç¹é«”ä¸­æ–‡"),
    ("human", "å®¢æˆ¶æŠ•è¨´ï¼š{question}")
])

inquiry_template = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯å°ˆæ¥­çš„å®¢æœäººå“¡ï¼Œå›ç­”ç”¢å“è«®è©¢ã€‚è«‹æä¾›è©³ç´°ä¸”æº–ç¢ºçš„è³‡è¨Šã€‚\næ‰€æœ‰å›è¦†ä½¿ç”¨ç¹é«”ä¸­æ–‡"),
    ("human", "å®¢æˆ¶è«®è©¢ï¼š{question}")
])

refund_template = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯å°ˆæ¥­çš„å®¢æœäººå“¡ï¼Œè™•ç†é€€æ›è²¨è«‹æ±‚ã€‚è«‹èªªæ˜é€€æ›è²¨æµç¨‹å’Œæ³¨æ„äº‹é …ã€‚\næ‰€æœ‰å›è¦†ä½¿ç”¨ç¹é«”ä¸­æ–‡"),
    ("human", "é€€æ›è²¨è«‹æ±‚ï¼š{question}")
])

general_template = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯å‹å–„çš„å®¢æœäººå“¡ï¼Œå›ç­”ä¸€èˆ¬å•é¡Œã€‚\næ‰€æœ‰å›è¦†ä½¿ç”¨ç¹é«”ä¸­æ–‡"),
    ("human", "å®¢æˆ¶å•é¡Œï¼š{question}")
])

# å»ºç«‹åˆ†æ”¯éˆ - æ ¹æ“šå•é¡Œé¡å‹é¸æ“‡ä¸åŒçš„è™•ç†æ–¹å¼
customer_service_branch = RunnableBranch(
    # æŠ•è¨´åˆ†æ”¯
    (
        lambda x: any(keyword in x.get("question", "") for keyword in ["æŠ•è¨´", "æŠ±æ€¨", "ä¸æ»¿æ„", "ç³Ÿç³•", "å·®å‹"]),
        complaint_template | model | StrOutputParser()
    ),
    # é€€æ›è²¨åˆ†æ”¯
    (
        lambda x: any(keyword in x.get("question", "") for keyword in ["é€€è²¨", "æ›è²¨", "é€€æ¬¾", "é€€éŒ¢", "ä¸æƒ³è¦"]),
        refund_template | model | StrOutputParser()
    ),
    # ç”¢å“è«®è©¢åˆ†æ”¯
    (
        lambda x: any(keyword in x.get("question", "") for keyword in ["åƒ¹æ ¼", "åŠŸèƒ½", "è¦æ ¼", "å¦‚ä½•ä½¿ç”¨", "æ€éº¼ç”¨"]),
        inquiry_template | model | StrOutputParser()
    ),
    # é è¨­åˆ†æ”¯
    general_template | model | StrOutputParser()
)

# æ·»åŠ æ ¼å¼åŒ–åŠŸèƒ½ - æ“´å±•éˆ
# ğŸ’¡ AI æç¤ºï¼šå®¢è£½åŒ–è¼¸å‡ºæ ¼å¼
# Prompt: "ä¿®æ”¹ format_customer_service_response å‡½æ•¸ï¼Œæ ¹æ“šä¸åŒå•é¡Œé¡å‹é¡¯ç¤ºä¸åŒçš„æ ¼å¼å’Œåœ–ç¤º"
def format_customer_service_response(reply):
    """æ ¼å¼åŒ–å®¢æœå›è¦†ï¼Œæ·»åŠ æ™‚é–“æˆ³è¨˜å’Œæ¨™æº–æ ¼å¼"""
    formatted = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           å®¢æœç³»çµ±å›è¦† - {datetime.now().strftime('%Y-%m-%d %H:%M')}           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

{reply}

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ğŸ’¡ å…¶ä»–æœå‹™ï¼š
   â€¢ å®¢æœå°ˆç·šï¼š0800-123-456
   â€¢ ç·šä¸Šå®¢æœï¼šé€±ä¸€è‡³é€±äº” 09:00-18:00
   â€¢ Emailï¼šservice@example.com

æ„Ÿè¬æ‚¨çš„ä¾†ä¿¡ï¼Œç¥æ‚¨æœ‰ç¾å¥½çš„ä¸€å¤©ï¼
    """
    return formatted.strip()

# çµ„åˆå®Œæ•´çš„å®¢æœç³»çµ±éˆ
customer_service_chain = (
    customer_service_branch
    | RunnableLambda(format_customer_service_response)
)

# å»ºç«‹ Gradio ä»‹é¢
# ğŸ’¡ AI æç¤ºï¼šåŠ å…¥é€²éšåŠŸèƒ½
# Prompt: "ç‚ºå®¢æœç³»çµ±åŠ å…¥å°è©±æ­·å²è¨˜éŒ„åŠŸèƒ½ï¼Œä½¿ç”¨ Gradio çš„ Chatbot å…ƒä»¶å»ºç«‹å¤šè¼ªå°è©±"
def process_customer_inquiry(question):
    """è™•ç†å®¢æˆ¶è«®è©¢"""
    if not question.strip():
        return "âš ï¸ è«‹è¼¸å…¥æ‚¨çš„å•é¡Œ"

    try:
        response = customer_service_chain.invoke({"question": question})
        return response
    except Exception as e:
        return f"âŒ ç³»çµ±éŒ¯èª¤ï¼š{str(e)}"

# é è¨­ç¯„ä¾‹å•é¡Œ
examples = [
    ["æˆ‘å°ä½ å€‘çš„ç”¢å“å¾ˆä¸æ»¿æ„ï¼Œå“è³ªå¤ªå·®äº†ï¼"],
    ["è«‹å•é€™å€‹ç”¢å“æœ‰ä»€éº¼åŠŸèƒ½ï¼Ÿ"],
    ["æˆ‘æƒ³è¦é€€è²¨ï¼Œå¯ä»¥å—ï¼Ÿ"],
    ["ä½ å€‘çš„ç‡Ÿæ¥­æ™‚é–“æ˜¯ï¼Ÿ"]
]

# å»ºç«‹ Gradio ä»‹é¢
with gr.Blocks(title="æ™ºèƒ½å®¢æœç³»çµ±", theme=gr.themes.Soft()) as demo:
    gr.Markdown("""
    # ğŸ¤– æ™ºèƒ½å®¢æœç³»çµ±

    ## ç³»çµ±åŠŸèƒ½
    æœ¬ç³»çµ±ä½¿ç”¨ **åˆ†æ”¯éˆ (RunnableBranch)** å’Œ **æ“´å±•éˆ (RunnableLambda)** æŠ€è¡“ï¼š
    - ğŸ” è‡ªå‹•è­˜åˆ¥å•é¡Œé¡å‹ï¼ˆæŠ•è¨´ã€é€€æ›è²¨ã€ç”¢å“è«®è©¢ã€ä¸€èˆ¬å•é¡Œï¼‰
    - ğŸ¯ é‡å°ä¸åŒé¡å‹æä¾›å°ˆæ¥­å›æ‡‰
    - ğŸ“ è‡ªå‹•æ ¼å¼åŒ–å›è¦†å…§å®¹
    - â° æ·»åŠ æ™‚é–“æˆ³è¨˜å’Œè¯çµ¡è³‡è¨Š

    ## ä½¿ç”¨èªªæ˜
    åœ¨ä¸‹æ–¹è¼¸å…¥æ‚¨çš„å•é¡Œï¼Œç³»çµ±æœƒè‡ªå‹•åˆ†é¡ä¸¦æä¾›é©ç•¶çš„å›æ‡‰ã€‚
    """)

    with gr.Row():
        with gr.Column():
            question_input = gr.Textbox(
                label="è«‹è¼¸å…¥æ‚¨çš„å•é¡Œ",
                placeholder="ä¾‹å¦‚ï¼šæˆ‘æƒ³è¦é€€è²¨...",
                lines=3
            )
            submit_btn = gr.Button("ğŸš€ é€å‡ºå•é¡Œ", variant="primary")

        with gr.Column():
            response_output = gr.Textbox(
                label="å®¢æœå›è¦†",
                lines=15,
                show_copy_button=True
            )

    gr.Examples(
        examples=examples,
        inputs=question_input,
        label="ç¯„ä¾‹å•é¡Œ"
    )

    submit_btn.click(
        fn=process_customer_inquiry,
        inputs=question_input,
        outputs=response_output
    )

    question_input.submit(
        fn=process_customer_inquiry,
        inputs=question_input,
        outputs=response_output
    )

if __name__ == "__main__":
    demo.launch(share=False, server_name="0.0.0.0", server_port=7860)
