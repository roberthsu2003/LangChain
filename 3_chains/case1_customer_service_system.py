"""
æ¡ˆä¾‹ 1: æ™ºèƒ½å®¢æœç³»çµ±
åŠŸèƒ½ï¼šè‡ªå‹•è™•ç†å®¢æˆ¶è«®è©¢ï¼Œæ ¹æ“šå•é¡Œé¡å‹æä¾›ä¸åŒçš„å›æ‡‰
ä½¿ç”¨æŠ€è¡“ï¼šåˆ†æ”¯éˆ (RunnableBranch) + æ“´å±•éˆ (RunnableLambda)
"""

import gradio as gr
from dotenv import load_dotenv
from langchain.prompts import ChatPromptTemplate
from langchain.schema.output_parser import StrOutputParser
from langchain.schema.runnable import RunnableBranch, RunnableLambda
from langchain_ollama.llms import OllamaLLM
from datetime import datetime

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

# å»ºç«‹æ¨¡å‹
model = OllamaLLM(model="llama3.2:latest")

# å®šç¾©ä¸åŒé¡å‹çš„å®¢æœæ¨¡æ¿
complaint_template = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯å°ˆæ¥­çš„å®¢æœäººå“¡ï¼Œè™•ç†å®¢æˆ¶æŠ•è¨´ã€‚è«‹ä¿æŒåŒç†å¿ƒï¼Œæä¾›è§£æ±ºæ–¹æ¡ˆã€‚"),
    ("human", "å®¢æˆ¶æŠ•è¨´ï¼š{question}")
])

inquiry_template = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯å°ˆæ¥­çš„å®¢æœäººå“¡ï¼Œå›ç­”ç”¢å“è«®è©¢ã€‚è«‹æä¾›è©³ç´°ä¸”æº–ç¢ºçš„è³‡è¨Šã€‚"),
    ("human", "å®¢æˆ¶è«®è©¢ï¼š{question}")
])

refund_template = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯å°ˆæ¥­çš„å®¢æœäººå“¡ï¼Œè™•ç†é€€æ›è²¨è«‹æ±‚ã€‚è«‹èªªæ˜é€€æ›è²¨æµç¨‹å’Œæ³¨æ„äº‹é …ã€‚"),
    ("human", "é€€æ›è²¨è«‹æ±‚ï¼š{question}")
])

general_template = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯å‹å–„çš„å®¢æœäººå“¡ï¼Œå›ç­”ä¸€èˆ¬å•é¡Œã€‚"),
    ("human", "å®¢æˆ¶å•é¡Œï¼š{question}")
])

# å»ºç«‹åˆ†æ”¯éˆ - æ ¹æ“šå•é¡Œé¡å‹é¸æ“‡ä¸åŒçš„è™•ç†æ–¹å¼
customer_service_branch = RunnableBranch(
    # æŠ•è¨´åˆ†æ”¯
    (
        lambda x: any(keyword in x.get("question", "") for keyword in ["æŠ•è¨´", "æŠ±æ€¨", "ä¸æ»¿æ„", "ç³Ÿç³•", "å·®å‹"]),
        complaint_template | model | StrOutputParser()
    ),
    # é€€æ›è²¨åˆ†æ”¯
    (
        lambda x: any(keyword in x.get("question", "") for keyword in ["é€€è²¨", "æ›è²¨", "é€€æ¬¾", "é€€éŒ¢", "ä¸æƒ³è¦"]),
        refund_template | model | StrOutputParser()
    ),
    # ç”¢å“è«®è©¢åˆ†æ”¯
    (
        lambda x: any(keyword in x.get("question", "") for keyword in ["åƒ¹æ ¼", "åŠŸèƒ½", "è¦æ ¼", "å¦‚ä½•ä½¿ç”¨", "æ€éº¼ç”¨"]),
        inquiry_template | model | StrOutputParser()
    ),
    # é è¨­åˆ†æ”¯
    general_template | model | StrOutputParser()
)

# æ·»åŠ æ ¼å¼åŒ–åŠŸèƒ½ - æ“´å±•éˆ
def format_customer_service_response(reply):
    """æ ¼å¼åŒ–å®¢æœå›è¦†ï¼Œæ·»åŠ æ™‚é–“æˆ³è¨˜å’Œæ¨™æº–æ ¼å¼"""
    formatted = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           å®¢æœç³»çµ±å›è¦† - {datetime.now().strftime('%Y-%m-%d %H:%M')}           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

{reply}

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ğŸ’¡ å…¶ä»–æœå‹™ï¼š
   â€¢ å®¢æœå°ˆç·šï¼š0800-123-456
   â€¢ ç·šä¸Šå®¢æœï¼šé€±ä¸€è‡³é€±äº” 09:00-18:00
   â€¢ Emailï¼šservice@example.com

æ„Ÿè¬æ‚¨çš„ä¾†ä¿¡ï¼Œç¥æ‚¨æœ‰ç¾å¥½çš„ä¸€å¤©ï¼
    """
    return formatted.strip()

# çµ„åˆå®Œæ•´çš„å®¢æœç³»çµ±éˆ
customer_service_chain = (
    customer_service_branch
    | RunnableLambda(format_customer_service_response)
)

# å»ºç«‹ Gradio ä»‹é¢
def process_customer_inquiry(question):
    """è™•ç†å®¢æˆ¶è«®è©¢"""
    if not question.strip():
        return "âš ï¸ è«‹è¼¸å…¥æ‚¨çš„å•é¡Œ"

    try:
        response = customer_service_chain.invoke({"question": question})
        return response
    except Exception as e:
        return f"âŒ ç³»çµ±éŒ¯èª¤ï¼š{str(e)}"

# é è¨­ç¯„ä¾‹å•é¡Œ
examples = [
    ["æˆ‘å°ä½ å€‘çš„ç”¢å“å¾ˆä¸æ»¿æ„ï¼Œå“è³ªå¤ªå·®äº†ï¼"],
    ["è«‹å•é€™å€‹ç”¢å“æœ‰ä»€éº¼åŠŸèƒ½ï¼Ÿ"],
    ["æˆ‘æƒ³è¦é€€è²¨ï¼Œå¯ä»¥å—ï¼Ÿ"],
    ["ä½ å€‘çš„ç‡Ÿæ¥­æ™‚é–“æ˜¯ï¼Ÿ"]
]

# å»ºç«‹ Gradio ä»‹é¢
with gr.Blocks(title="æ™ºèƒ½å®¢æœç³»çµ±", theme=gr.themes.Soft()) as demo:
    gr.Markdown("""
    # ğŸ¤– æ™ºèƒ½å®¢æœç³»çµ±

    ## ç³»çµ±åŠŸèƒ½
    æœ¬ç³»çµ±ä½¿ç”¨ **åˆ†æ”¯éˆ (RunnableBranch)** å’Œ **æ“´å±•éˆ (RunnableLambda)** æŠ€è¡“ï¼š
    - ğŸ” è‡ªå‹•è­˜åˆ¥å•é¡Œé¡å‹ï¼ˆæŠ•è¨´ã€é€€æ›è²¨ã€ç”¢å“è«®è©¢ã€ä¸€èˆ¬å•é¡Œï¼‰
    - ğŸ¯ é‡å°ä¸åŒé¡å‹æä¾›å°ˆæ¥­å›æ‡‰
    - ğŸ“ è‡ªå‹•æ ¼å¼åŒ–å›è¦†å…§å®¹
    - â° æ·»åŠ æ™‚é–“æˆ³è¨˜å’Œè¯çµ¡è³‡è¨Š

    ## ä½¿ç”¨èªªæ˜
    åœ¨ä¸‹æ–¹è¼¸å…¥æ‚¨çš„å•é¡Œï¼Œç³»çµ±æœƒè‡ªå‹•åˆ†é¡ä¸¦æä¾›é©ç•¶çš„å›æ‡‰ã€‚
    """)

    with gr.Row():
        with gr.Column():
            question_input = gr.Textbox(
                label="è«‹è¼¸å…¥æ‚¨çš„å•é¡Œ",
                placeholder="ä¾‹å¦‚ï¼šæˆ‘æƒ³è¦é€€è²¨...",
                lines=3
            )
            submit_btn = gr.Button("ğŸš€ é€å‡ºå•é¡Œ", variant="primary")

        with gr.Column():
            response_output = gr.Textbox(
                label="å®¢æœå›è¦†",
                lines=15,
                show_copy_button=True
            )

    gr.Examples(
        examples=examples,
        inputs=question_input,
        label="ç¯„ä¾‹å•é¡Œ"
    )

    submit_btn.click(
        fn=process_customer_inquiry,
        inputs=question_input,
        outputs=response_output
    )

    question_input.submit(
        fn=process_customer_inquiry,
        inputs=question_input,
        outputs=response_output
    )

if __name__ == "__main__":
    demo.launch(share=False, server_name="0.0.0.0", server_port=7860)
