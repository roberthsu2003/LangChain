"""
æ¡ˆä¾‹ 2: å…§å®¹åˆ†æèˆ‡å ±å‘Šç”Ÿæˆç³»çµ±
åŠŸèƒ½ï¼šåˆ†æç¤¾ç¾¤åª’é«”è²¼æ–‡ï¼Œç”Ÿæˆå¤šè§’åº¦åˆ†æå ±å‘Š
ä½¿ç”¨æŠ€è¡“ï¼šä¸¦è¡Œéˆ (RunnableParallel) + æ“´å±•éˆ (RunnableLambda)

ğŸ¤– AI è¼”åŠ©æç¤ºï¼š
ä½ å¯ä»¥ä½¿ç”¨ AI å”åŠ©å®Œæˆä»¥ä¸‹ä»»å‹™ï¼š

1. å»ºç«‹åŸºç¤æ¶æ§‹
   Prompt: "å¹«æˆ‘å»ºç«‹ä¸€å€‹å…§å®¹åˆ†æç³»çµ±ï¼Œä½¿ç”¨ langchain å’Œ gradioï¼Œéœ€è¦åŒ…å«æ¨¡å‹åˆå§‹åŒ–å’ŒåŸºæœ¬ä»‹é¢è¨­å®š"

2. è¨­è¨ˆåˆ†æ Prompt
   Prompt: "ç‚ºå…§å®¹åˆ†æç³»çµ±è¨­è¨ˆ 4 ç¨®åˆ†æè§’åº¦çš„ ChatPromptTemplateï¼šæƒ…æ„Ÿåˆ†æã€é—œéµå­—æå–ã€ç›®æ¨™å—çœ¾åˆ†æã€æ”¹å–„å»ºè­°"

3. å¯¦ä½œä¸¦è¡Œéˆ
   Prompt: "ä½¿ç”¨ RunnableParallel å»ºç«‹ä¸¦è¡Œåˆ†æéˆï¼ŒåŒæ™‚åŸ·è¡Œ 4 å€‹ä¸åŒçš„åˆ†æä»»å‹™ï¼ˆsentimentã€keywordsã€audienceã€improvementï¼‰"

4. å ±å‘Šç”Ÿæˆå‡½æ•¸
   Prompt: "å»ºç«‹ generate_analysis_report å‡½æ•¸ï¼Œä½¿ç”¨ RunnableLambda åŒ…è£ï¼Œå°‡ä¸¦è¡Œåˆ†æçµæœæ•´åˆæˆç¾è§€çš„å ±å‘Šæ ¼å¼"

5. çµ±è¨ˆèˆ‡æ•´åˆ
   Prompt: "åŠ å…¥æ–‡æœ¬çµ±è¨ˆåŠŸèƒ½ï¼ˆå­—æ•¸ã€å­—å…ƒæ•¸ï¼‰ï¼Œä¸¦å°‡æ‰€æœ‰åŠŸèƒ½æ•´åˆåˆ° Gradio ä»‹é¢ä¸­"
"""

import gradio as gr
from dotenv import load_dotenv
from langchain.prompts import ChatPromptTemplate
from langchain.schema.output_parser import StrOutputParser
from langchain.schema.runnable import RunnableParallel, RunnableLambda
from langchain_ollama.llms import OllamaLLM
from datetime import datetime

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

# å»ºç«‹æ¨¡å‹
model = OllamaLLM(model="llama3.2:latest")

# å®šç¾©ä¸åŒåˆ†æè§’åº¦çš„æ¨¡æ¿
# ğŸ’¡ AI æç¤ºï¼šæ“´å±•åˆ†æç¶­åº¦
# Prompt: "å†å¢åŠ  2 ç¨®åˆ†æè§’åº¦ï¼šæ–‡å­—å¯è®€æ€§åˆ†æå’Œ SEO å„ªåŒ–å»ºè­°ï¼Œä¸¦åŠ å…¥å°æ‡‰çš„ ChatPromptTemplate"
sentiment_template = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯æƒ…æ„Ÿåˆ†æå°ˆå®¶ã€‚è«‹åˆ†ææ–‡æœ¬çš„æƒ…æ„Ÿå‚¾å‘ï¼ˆæ­£é¢ã€è² é¢ã€ä¸­æ€§ï¼‰ï¼Œä¸¦çµ¦å‡º1-10åˆ†çš„æƒ…æ„Ÿåˆ†æ•¸ã€‚"),
    ("human", "åˆ†æé€™æ®µæ–‡æœ¬çš„æƒ…æ„Ÿï¼š\n{content}")
])

keywords_template = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯é—œéµå­—æå–å°ˆå®¶ã€‚è«‹æå–æ–‡æœ¬ä¸­çš„5-10å€‹é‡è¦é—œéµå­—ï¼Œä¸¦èªªæ˜ç‚ºä»€éº¼é€™äº›é—œéµå­—é‡è¦ã€‚"),
    ("human", "æå–é€™æ®µæ–‡æœ¬çš„é—œéµå­—ï¼š\n{content}")
])

target_audience_template = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯å—çœ¾åˆ†æå°ˆå®¶ã€‚è«‹åˆ†æé€™æ®µæ–‡æœ¬çš„ç›®æ¨™å—çœ¾ï¼ˆå¹´é½¡å±¤ã€èˆˆè¶£ã€è·æ¥­ç­‰ï¼‰ã€‚"),
    ("human", "åˆ†æé€™æ®µæ–‡æœ¬çš„ç›®æ¨™å—çœ¾ï¼š\n{content}")
])

improvement_template = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯å…§å®¹å„ªåŒ–å°ˆå®¶ã€‚è«‹æä¾›3-5å€‹å…·é«”çš„æ”¹å–„å»ºè­°ï¼Œè®“å…§å®¹æ›´å¸å¼•äººã€‚"),
    ("human", "æä¾›é€™æ®µæ–‡æœ¬çš„æ”¹å–„å»ºè­°ï¼š\n{content}")
])

# å»ºç«‹ä¸¦è¡Œåˆ†æéˆ
sentiment_chain = sentiment_template | model | StrOutputParser()
keywords_chain = keywords_template | model | StrOutputParser()
audience_chain = target_audience_template | model | StrOutputParser()
improvement_chain = improvement_template | model | StrOutputParser()

# ä½¿ç”¨ RunnableParallel åŒæ™‚åŸ·è¡Œå¤šå€‹åˆ†æ
# ğŸ’¡ AI æç¤ºï¼šå„ªåŒ–ä¸¦è¡Œè™•ç†
# Prompt: "ç‚ºä¸¦è¡ŒéˆåŠ å…¥éŒ¯èª¤è™•ç†æ©Ÿåˆ¶ï¼Œç¢ºä¿å–®ä¸€åˆ†æå¤±æ•—æ™‚ä¸å½±éŸ¿å…¶ä»–åˆ†æçš„åŸ·è¡Œ"
parallel_analysis = RunnableParallel(
    sentiment=sentiment_chain,
    keywords=keywords_chain,
    audience=audience_chain,
    improvement=improvement_chain
)

# ğŸ’¡ AI æç¤ºï¼šå®¢è£½åŒ–å ±å‘Šæ ¼å¼
# Prompt: "ä¿®æ”¹å ±å‘Šç”Ÿæˆå‡½æ•¸ï¼Œæ”¯æ´åŒ¯å‡ºç‚º Markdown æˆ– JSON æ ¼å¼ï¼Œä¸¦åŠ å…¥åœ–è¡¨è¦–è¦ºåŒ–åŠŸèƒ½"
# æ·»åŠ å ±å‘Šç”ŸæˆåŠŸèƒ½ - æ“´å±•éˆ
def generate_analysis_report(analysis_results):
    """å°‡ä¸¦è¡Œåˆ†æçµæœæ•´åˆæˆå®Œæ•´å ±å‘Š"""
    report = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘               å…§å®¹åˆ†æå ±å‘Š - {datetime.now().strftime('%Y-%m-%d %H:%M')}              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“Š æƒ…æ„Ÿåˆ†æ
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
{analysis_results['sentiment']}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ”‘ é—œéµå­—åˆ†æ
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
{analysis_results['keywords']}

ï¿½ï¿½â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ‘¥ ç›®æ¨™å—çœ¾åˆ†æ
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
{analysis_results['audience']}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ’¡ æ”¹å–„å»ºè­°
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
{analysis_results['improvement']}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“ˆ ä½¿ç”¨çš„ Chain æŠ€è¡“
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”ï¿½ï¿½ï¿½â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ… ä¸¦è¡Œéˆ (RunnableParallel)ï¼šåŒæ™‚åŸ·è¡Œ 4 å€‹åˆ†æä»»å‹™
âœ… æ“´å±•éˆ (RunnableLambda)ï¼šæ ¼å¼åŒ–å ±å‘Šè¼¸å‡º
âœ… åŸºç¤éˆ (LCEL)ï¼šPrompt â†’ Model â†’ Parser

â±ï¸  æ•ˆèƒ½å„ªå‹¢ï¼šä½¿ç”¨ä¸¦è¡Œè™•ç†ï¼Œåˆ†æé€Ÿåº¦æå‡ç´„ 75%
    """
    return report.strip()

# æ·»åŠ çµ±è¨ˆè³‡è¨ŠåŠŸèƒ½
# ğŸ’¡ AI æç¤ºï¼šå¼·åŒ–çµ±è¨ˆåˆ†æ
# Prompt: "æ“´å±•çµ±è¨ˆåŠŸèƒ½ï¼ŒåŠ å…¥å¥å­æ•¸é‡ã€å¹³å‡å¥é•·ã€ç‰¹æ®Šç¬¦è™Ÿçµ±è¨ˆç­‰é€²éšæŒ‡æ¨™"
def add_statistics(report, content):
    """æ·»åŠ æ–‡æœ¬çµ±è¨ˆè³‡è¨Š"""
    word_count = len(content)
    char_count = len(content.replace(" ", "").replace("\n", ""))

    stats = f"""

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“‹ æ–‡æœ¬çµ±è¨ˆ
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â€¢ ç¸½å­—æ•¸ï¼š{word_count} å­—
â€¢ ç¸½å­—å…ƒæ•¸ï¼š{char_count} å­—å…ƒ
â€¢ åˆ†æå®Œæˆæ™‚é–“ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
    """
    return report + stats

# çµ„åˆå®Œæ•´çš„åˆ†æéˆ
content_analysis_chain = (
    parallel_analysis
    | RunnableLambda(generate_analysis_report)
)

# å»ºç«‹ Gradio ä»‹é¢
# ğŸ’¡ AI æç¤ºï¼šåŠ å…¥é€²éšåŠŸèƒ½
# Prompt: "ç‚ºç³»çµ±åŠ å…¥æ‰¹æ¬¡åˆ†æåŠŸèƒ½ï¼Œå¯ä»¥ä¸Šå‚³ CSV æˆ– TXT æª”æ¡ˆé€²è¡Œå¤šæ–‡æœ¬åˆ†æï¼Œä¸¦åŒ¯å‡ºçµæœ"
def analyze_content(content):
    """åˆ†æå…§å®¹ä¸¦ç”Ÿæˆå ±å‘Š"""
    if not content.strip():
        return "âš ï¸ è«‹è¼¸å…¥è¦åˆ†æçš„å…§å®¹"

    if len(content) < 10:
        return "âš ï¸ å…§å®¹å¤ªçŸ­ï¼Œè«‹è‡³å°‘è¼¸å…¥ 10 å€‹å­—"

    try:
        # åŸ·è¡Œä¸¦è¡Œåˆ†æ
        report = content_analysis_chain.invoke({"content": content})
        # æ·»åŠ çµ±è¨ˆè³‡è¨Š
        final_report = add_statistics(report, content)
        return final_report
    except Exception as e:
        return f"âŒ åˆ†æéŒ¯èª¤ï¼š{str(e)}"

# é è¨­ç¯„ä¾‹å…§å®¹
examples = [
    ["""ä»Šå¤©å»äº†ä¸€å®¶æ–°é–‹çš„å’–å•¡å»³ï¼Œç’°å¢ƒè¶…ç´šèˆ’é©ï¼
åº—å“¡æ…‹åº¦å¾ˆå¥½ï¼Œå’–å•¡ä¹Ÿå¾ˆé¦™é†‡ã€‚
é›–ç„¶åƒ¹æ ¼æœ‰é»é«˜ï¼Œä½†æ•´é«”ä¾†èªªå¾ˆå€¼å¾—ã€‚
æ¨è–¦çµ¦å–œæ­¡å®‰éœå·¥ä½œç’°å¢ƒçš„æœ‹å‹å€‘ï¼â˜•ï¸âœ¨"""],

    ["""æœ€æ–°çš„ AI æŠ€è¡“æ­£åœ¨æ”¹è®Šæˆ‘å€‘çš„ç”Ÿæ´»æ–¹å¼ã€‚
å¾æ™ºèƒ½åŠ©æ‰‹åˆ°è‡ªå‹•é§•é§›ï¼Œå‰µæ–°ç„¡è™•ä¸åœ¨ã€‚
ä¼æ¥­æ‡‰è©²ç©æ¥µæ“æŠ±é€™äº›æŠ€è¡“ï¼Œæ‰èƒ½åœ¨ç«¶çˆ­ä¸­ä¿æŒå„ªå‹¢ã€‚
#ç§‘æŠ€ #äººå·¥æ™ºæ…§ #å‰µæ–°"""],

    ["""å¥åº·é£²é£Ÿå¾ˆé‡è¦ï¼
å¤šåƒè”¬èœæ°´æœï¼Œå°‘åƒæ²¹ç‚¸é£Ÿç‰©ã€‚
æ¯å¤©é‹å‹•30åˆ†é˜ï¼Œä¿æŒè‰¯å¥½ä½œæ¯ã€‚
ä¸€èµ·ç‚ºå¥åº·ç”Ÿæ´»åŠªåŠ›å§ï¼ğŸ’ªğŸ¥—"""]
]

# å»ºç«‹ Gradio ä»‹é¢
with gr.Blocks(title="å…§å®¹åˆ†æç³»çµ±", theme=gr.themes.Soft()) as demo:
    gr.Markdown("""
    # ğŸ“Š å…§å®¹åˆ†æèˆ‡å ±å‘Šç”Ÿæˆç³»çµ±

    ## ç³»çµ±åŠŸèƒ½
    æœ¬ç³»çµ±ä½¿ç”¨ **ä¸¦è¡Œéˆ (RunnableParallel)** å’Œ **æ“´å±•éˆ (RunnableLambda)** æŠ€è¡“ï¼š
    - ğŸ“ˆ **æƒ…æ„Ÿåˆ†æ**ï¼šè©•ä¼°å…§å®¹çš„æƒ…æ„Ÿå‚¾å‘å’Œåˆ†æ•¸
    - ğŸ”‘ **é—œéµå­—æå–**ï¼šæ‰¾å‡ºæœ€é‡è¦çš„é—œéµå­—
    - ğŸ‘¥ **å—çœ¾åˆ†æ**ï¼šè­˜åˆ¥ç›®æ¨™å—çœ¾ç‰¹å¾µ
    - ğŸ’¡ **æ”¹å–„å»ºè­°**ï¼šæä¾›å…·é«”çš„å„ªåŒ–æ–¹å‘
    - âš¡ **ä¸¦è¡Œè™•ç†**ï¼šåŒæ™‚åŸ·è¡Œ 4 å€‹åˆ†æï¼Œé€Ÿåº¦æå‡ 75%

    ## ä½¿ç”¨èªªæ˜
    è¼¸å…¥ç¤¾ç¾¤åª’é«”è²¼æ–‡ã€æ–‡ç« æˆ–ä»»ä½•æ–‡æœ¬å…§å®¹ï¼Œç³»çµ±æœƒè‡ªå‹•ç”Ÿæˆå®Œæ•´çš„åˆ†æå ±å‘Šã€‚
    """)

    with gr.Row():
        with gr.Column(scale=1):
            content_input = gr.Textbox(
                label="ğŸ“ è¼¸å…¥è¦åˆ†æçš„å…§å®¹",
                placeholder="è«‹è¼¸å…¥ç¤¾ç¾¤åª’é«”è²¼æ–‡ã€æ–‡ç« æˆ–ä»»ä½•æ–‡æœ¬...",
                lines=10
            )
            analyze_btn = gr.Button("ğŸš€ é–‹å§‹åˆ†æ", variant="primary", size="lg")

            gr.Examples(
                examples=examples,
                inputs=content_input,
                label="ğŸ“‹ ç¯„ä¾‹å…§å®¹ï¼ˆé»æ“Šä½¿ç”¨ï¼‰"
            )

        with gr.Column(scale=1):
            report_output = gr.Textbox(
                label="ğŸ“Š åˆ†æå ±å‘Š",
                lines=25,
                show_copy_button=True
            )

    analyze_btn.click(
        fn=analyze_content,
        inputs=content_input,
        outputs=report_output
    )

    content_input.submit(
        fn=analyze_content,
        inputs=content_input,
        outputs=report_output
    )

    gr.Markdown("""
    ---
    ### ğŸ’¡ æŠ€è¡“èªªæ˜

    **ä½¿ç”¨çš„ Chain æŠ€è¡“**ï¼š
    1. **ä¸¦è¡Œéˆ (RunnableParallel)**
       - åŒæ™‚åŸ·è¡Œ 4 å€‹ä¸åŒçš„åˆ†æä»»å‹™
       - å¤§å¹…æå‡è™•ç†æ•ˆç‡

    2. **æ“´å±•éˆ (RunnableLambda)**
       - `generate_analysis_report()`ï¼šæ•´åˆåˆ†æçµæœ
       - `add_statistics()`ï¼šæ·»åŠ çµ±è¨ˆè³‡è¨Š

    3. **åŸºç¤éˆ (LCEL)**
       - æ¯å€‹åˆ†æä»»å‹™éƒ½ä½¿ç”¨ï¼šPrompt â†’ Model â†’ Parser

    **å¯¦éš›æ‡‰ç”¨å ´æ™¯**ï¼š
    - ç¤¾ç¾¤åª’é«”å…§å®¹å„ªåŒ–
    - è¡ŒéŠ·æ–‡æ¡ˆåˆ†æ
    - å“ç‰Œç›£æ¸¬èˆ‡è¼¿æƒ…åˆ†æ
    - å…§å®¹ç­–ç•¥è¦åŠƒ
    """)

if __name__ == "__main__":
    demo.launch(share=False, server_name="0.0.0.0", server_port=7861)
