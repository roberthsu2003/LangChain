{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG 基礎入門\n",
    "\n",
    "本範例展示：\n",
    "1. **第1個儲存格**：建立向量資料庫\n",
    "2. **第2個儲存格**：查詢向量資料庫\n",
    "\n",
    "學習目標：理解如何將文本轉換為向量並進行相似度檢索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 第1個儲存格：建立向量資料庫\n\nimport os\nfrom langchain.text_splitter import CharacterTextSplitter\nfrom langchain_community.document_loaders import TextLoader\nfrom langchain_community.vectorstores import Chroma\nfrom langchain_community.embeddings import HuggingFaceEmbeddings\n\n# 定義包含文字檔案的目錄和持久化目錄\ncurrent_dir = os.path.dirname(os.path.abspath(\"__file__\"))\nfile_path = os.path.join(current_dir, \"books\", \"智慧型手機使用手冊.txt\")\npersistent_directory = os.path.join(current_dir, \"db\", \"chroma_db_chinese_nb\")\n\n# 檢查 Chroma 向量存儲是否已存在\nif not os.path.exists(persistent_directory):\n    print(\"持久化目錄不存在。正在初始化向量存儲...\")\n\n    # 確保文字檔案存在\n    if not os.path.exists(file_path):\n        raise FileNotFoundError(\n            f\"檔案 {file_path} 不存在。請檢查路徑。\"\n        )\n\n    # 從檔案讀取文字內容\n    loader = TextLoader(file_path)\n    documents = loader.load()\n\n    # 將文件分割成塊\n    # chunk_size=1000: 每個文本區塊最多 1000 個字元\n    # chunk_overlap=0: 區塊之間不重疊\n    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n    docs = text_splitter.split_documents(documents)\n\n    # 顯示分割文件的資訊\n    print(\"\\n--- 文件塊資訊 ---\")\n    print(f\"文件塊數量: {len(docs)}\")\n    print(f\"範例塊:\\n{docs[0].page_content}\\n\")\n\n    # 建立嵌入模型\n    print(\"\\n--- 正在建立嵌入 ---\")\n    print(\"使用 Jina Embeddings v2（繁體中文開源模型）\")\n    embeddings = HuggingFaceEmbeddings(\n        model_name=\"jinaai/jina-embeddings-v2-base-zh\"\n    )\n    print(\"\\n--- 完成建立嵌入 ---\")\n\n    # 建立向量存儲並自動持久化\n    print(\"\\n--- 正在建立向量存儲 ---\")\n    db = Chroma.from_documents(\n        docs, embeddings, persist_directory=persistent_directory)\n    print(\"\\n--- 完成建立向量存儲 ---\")\n\nelse:\n    print(\"向量存儲已存在。無需初始化。\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 第2個儲存格：查詢向量資料庫\n\nimport os\nfrom langchain_community.vectorstores import Chroma\nfrom langchain_community.embeddings import HuggingFaceEmbeddings\n\n# 定義持久化目錄\ncurrent_dir = os.path.dirname(os.path.abspath(\"__file__\"))\npersistent_directory = os.path.join(current_dir, \"db\", \"chroma_db_chinese_nb\")\n\n# 定義嵌入模型（使用開源繁體中文模型）\nembeddings = HuggingFaceEmbeddings(model_name=\"jinaai/jina-embeddings-v2-base-zh\")\n\n# 使用嵌入函數載入現有的向量存儲\ndb = Chroma(persist_directory=persistent_directory,\n            embedding_function=embeddings)\n\n# 定義使用者的問題\nquery = \"如何設定指紋辨識？\"\n\n# 根據查詢檢索相關文件\n# search_type=\"similarity_score_threshold\": 使用相似度分數閾值過濾\n# k=3: 返回最多 3 個相關文件\n# score_threshold=0.9: 只返回相似度分數 >= 0.9 的文件\nretriever = db.as_retriever(\n    search_type=\"similarity_score_threshold\",\n    search_kwargs={\"k\": 3, \"score_threshold\": 0.9},\n)\nrelevant_docs = retriever.invoke(query)\n\n# 顯示相關結果及元數據\nprint(\"\\n--- 相關文件 ---\")\nfor i, doc in enumerate(relevant_docs, 1):\n    print(f\"文件 {i}:\\n{doc.page_content}\\n\")\n    if doc.metadata:\n        print(f\"來源: {doc.metadata.get('source', 'Unknown')}\\n\")"
  },
  {
   "cell_type": "code",
   "source": "# 第3個儲存格：整合 Chain - 建立簡單的 RAG 問答鏈\n\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.runnables import RunnablePassthrough\nfrom langchain_ollama import ChatOllama\n\n# 定義使用者的問題\nquestion = \"如何設定指紋辨識？\"\n\nprint(f\"問題: {question}\\n\")\n\n# 步驟 1: 從向量資料庫檢索相關文件\nprint(\"=\" * 60)\nprint(\"步驟 1: 從向量資料庫檢索相關文件\")\nprint(\"=\" * 60)\n\nretriever = db.as_retriever(\n    search_type=\"similarity\",\n    search_kwargs={\"k\": 2}  # 只取最相關的 2 個文件\n)\nretrieved_docs = retriever.invoke(question)\n\nprint(f\"找到 {len(retrieved_docs)} 個相關文件\\n\")\nfor i, doc in enumerate(retrieved_docs, 1):\n    print(f\"文件 {i} (前100字):\")\n    print(doc.page_content[:100] + \"...\\n\")\n\n# 步驟 2: 建立 RAG Chain\nprint(\"=\" * 60)\nprint(\"步驟 2: 建立 RAG Chain\")\nprint(\"=\" * 60)\n\n# 定義提示模板\ntemplate = \"\"\"你是一個智慧型手機的客服助手。請根據以下參考資料回答使用者的問題。\n\n參考資料：\n{context}\n\n使用者問題：{question}\n\n請用繁體中文回答，並且：\n1. 只根據參考資料回答，不要編造內容\n2. 如果參考資料中沒有答案，請誠實說「我在資料中找不到相關資訊」\n3. 回答要清楚、具體、有條理\n\n回答：\"\"\"\n\nprompt = ChatPromptTemplate.from_template(template)\n\n# 建立 LLM（使用本地 Ollama）\nllm = ChatOllama(model=\"llama3.2\", temperature=0)\n\n# 定義文件格式化函數\ndef format_docs(docs):\n    return \"\\n\\n\".join(doc.page_content for doc in docs)\n\n# 建立完整的 RAG Chain\n# RunnablePassthrough() 讓 question 直接傳遞下去\n# retriever | format_docs 將檢索結果格式化為 context\nrag_chain = (\n    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n    | prompt\n    | llm\n    | StrOutputParser()\n)\n\nprint(\"✅ RAG Chain 建立完成\\n\")\n\n# 步驟 3: 執行 RAG Chain 並取得答案\nprint(\"=\" * 60)\nprint(\"步驟 3: 執行 RAG Chain\")\nprint(\"=\" * 60)\n\nanswer = rag_chain.invoke(question)\n\nprint(f\"\\n【AI 回答】\\n{answer}\\n\")\n\nprint(\"=\" * 60)\nprint(\"RAG Chain 流程總結\")\nprint(\"=\" * 60)\nprint(\"1. 使用者提問 → 向量檢索找相關文件\")\nprint(\"2. 將文件和問題組合成提示詞\")\nprint(\"3. 送給 LLM 生成答案\")\nprint(\"4. 解析並返回答案\")\nprint(\"\\n💡 這就是從 Chain 3 學到的技巧應用在 RAG 上！\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}