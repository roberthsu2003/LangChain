{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG åŸºç¤å…¥é–€\n",
    "\n",
    "æœ¬ç¯„ä¾‹å±•ç¤ºï¼š\n",
    "1. **ç¬¬1å€‹å„²å­˜æ ¼**ï¼šå»ºç«‹å‘é‡è³‡æ–™åº«\n",
    "2. **ç¬¬2å€‹å„²å­˜æ ¼**ï¼šæŸ¥è©¢å‘é‡è³‡æ–™åº«\n",
    "3. **ç¬¬3å€‹å„²å­˜æ ¼ä»¥å¾Œ**: æ•´åˆchainçš„åŠŸèƒ½\n",
    "\n",
    "å­¸ç¿’ç›®æ¨™ï¼šç†è§£å¦‚ä½•å°‡æ–‡æœ¬è½‰æ›ç‚ºå‘é‡ä¸¦é€²è¡Œç›¸ä¼¼åº¦æª¢ç´¢\n",
    "\n",
    "æœ€å¾Œï¼Œæˆ‘å€‘æœƒä»‹ç´¹å¦‚ä½•ä½¿ç”¨ Dict å’Œ RunnablePassthrough ä¾†å¯¦ç¾ç›¸åŒçš„ RAG æµç¨‹ï¼Œä¸¦ä¸”æœƒä»‹ç´¹ Dict çš„å¯¦éš›é‹ä½œæµç¨‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¬¬1å€‹å„²å­˜æ ¼ï¼šå»ºç«‹å‘é‡è³‡æ–™åº«\n",
    "\n",
    "import os\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "import chromadb\n",
    "\n",
    "# å®šç¾©åŒ…å«æ–‡å­—æª”æ¡ˆçš„ç›®éŒ„å’ŒæŒä¹…åŒ–ç›®éŒ„\n",
    "current_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "file_path = os.path.join(current_dir, \"books\", \"æ™ºæ…§å‹æ‰‹æ©Ÿä½¿ç”¨æ‰‹å†Š.txt\")\n",
    "persistent_directory = os.path.join(current_dir, \"db\", \"chroma_db_jina\")\n",
    "\n",
    "# æª¢æŸ¥ Chroma å‘é‡å­˜å„²æ˜¯å¦å·²å­˜åœ¨\n",
    "if not os.path.exists(persistent_directory):\n",
    "    print(\"æŒä¹…åŒ–ç›®éŒ„ä¸å­˜åœ¨ã€‚æ­£åœ¨åˆå§‹åŒ–å‘é‡è³‡æ–™åº«...\")\n",
    "\n",
    "    # ç¢ºä¿æ–‡å­—æª”æ¡ˆå­˜åœ¨\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(\n",
    "            f\"æª”æ¡ˆ {file_path} ä¸å­˜åœ¨ã€‚è«‹æª¢æŸ¥è·¯å¾‘ã€‚\"\n",
    "        )\n",
    "\n",
    "    # å¾æª”æ¡ˆè®€å–æ–‡å­—å…§å®¹\n",
    "    loader = TextLoader(file_path)\n",
    "    documents = loader.load()\n",
    "\n",
    "    # å°‡æ–‡ä»¶åˆ†å‰²æˆå¡Š\n",
    "    # chunk_size=1000: æ¯å€‹æ–‡æœ¬å€å¡Šæœ€å¤š 1000 å€‹å­—å…ƒ\n",
    "    # chunk_overlap=0: å€å¡Šä¹‹é–“ä¸é‡ç–Š\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "\n",
    "    # é¡¯ç¤ºåˆ†å‰²æ–‡ä»¶çš„è³‡è¨Š\n",
    "    print(\"\\n--- æ–‡ä»¶å¡Šè³‡è¨Š ---\")\n",
    "    print(f\"æ–‡ä»¶å¡Šæ•¸é‡: {len(docs)}\")\n",
    "    print(f\"ç¯„ä¾‹å¡Š:\\n{docs[0].page_content}\\n\")\n",
    "\n",
    "    # å»ºç«‹åµŒå…¥æ¨¡å‹\n",
    "    print(\"\\n--- æ­£åœ¨å»ºç«‹åµŒå…¥ ---\")\n",
    "    print(\"ä½¿ç”¨ Jina Embeddings v2ï¼ˆç¹é«”ä¸­æ–‡é–‹æºæ¨¡å‹ï¼‰\")\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=\"jinaai/jina-embeddings-v2-base-zh\"\n",
    "    )\n",
    "    print(\"\\n--- å®Œæˆå»ºç«‹åµŒå…¥ ---\")\n",
    "\n",
    "    # å»ºç«‹å‘é‡å­˜å„²ä¸¦è‡ªå‹•æŒä¹…åŒ–\n",
    "    print(\"\\n--- æ­£åœ¨å»ºç«‹å‘é‡å­˜å„² ---\")\n",
    "    \n",
    "    # ä½¿ç”¨ PersistentClient ä»¥é¿å…æ¬Šé™å•é¡Œ\n",
    "    client = chromadb.PersistentClient(path=persistent_directory)\n",
    "    \n",
    "    db = Chroma.from_documents(\n",
    "        docs, \n",
    "        embeddings, \n",
    "        client=client,\n",
    "        collection_name=\"smartphone_manual\"\n",
    "    )\n",
    "    print(\"\\n--- å®Œæˆå»ºç«‹å‘é‡å­˜å„² ---\")\n",
    "\n",
    "else:\n",
    "    print(\"å‘é‡å­˜å„²å·²å­˜åœ¨ã€‚ç„¡éœ€åˆå§‹åŒ–ã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¬¬2å€‹å„²å­˜æ ¼ï¼šæŸ¥è©¢å‘é‡è³‡æ–™åº«\n",
    "\n",
    "import os\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "import chromadb\n",
    "\n",
    "# å®šç¾©æŒä¹…åŒ–ç›®éŒ„\n",
    "current_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "persistent_directory = os.path.join(current_dir, \"db\", \"chroma_db_jina\")\n",
    "\n",
    "# å®šç¾©åµŒå…¥æ¨¡å‹ï¼ˆä½¿ç”¨é–‹æºç¹é«”ä¸­æ–‡æ¨¡å‹ï¼‰\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"jinaai/jina-embeddings-v2-base-zh\")\n",
    "\n",
    "# ä½¿ç”¨ PersistentClient è¼‰å…¥ç¾æœ‰çš„å‘é‡å­˜å„²\n",
    "client = chromadb.PersistentClient(path=persistent_directory)\n",
    "\n",
    "db = Chroma(\n",
    "    client=client,\n",
    "    collection_name=\"smartphone_manual\",\n",
    "    embedding_function=embeddings\n",
    ")\n",
    "\n",
    "# å®šç¾©ä½¿ç”¨è€…çš„å•é¡Œ\n",
    "query = \"å¦‚ä½•è¨­å®šæŒ‡ç´‹è¾¨è­˜ï¼Ÿ\"\n",
    "\n",
    "# æ ¹æ“šæŸ¥è©¢æª¢ç´¢ç›¸é—œæ–‡ä»¶\n",
    "# search_type=\"similarity\": ä½¿ç”¨ç›¸ä¼¼åº¦æœå°‹ï¼ˆé è¨­æ–¹æ³•ï¼‰\n",
    "# k=3: è¿”å›æœ€ç›¸é—œçš„ 3 å€‹æ–‡ä»¶\n",
    "# æ³¨æ„ï¼šç”±æ–¼æŸäº› embedding æ¨¡å‹çš„ç›¸ä¼¼åº¦åˆ†æ•¸å¯èƒ½ä¸åœ¨ 0-1 ç¯„åœå…§ï¼Œ\n",
    "#      å› æ­¤ä½¿ç”¨ç°¡å–®çš„ similarity æœå°‹è€Œé similarity_score_threshold\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3},\n",
    ")\n",
    "relevant_docs = retriever.invoke(query)\n",
    "\n",
    "# é¡¯ç¤ºç›¸é—œçµæœåŠå…ƒæ•¸æ“š\n",
    "print(\"\\n--- ç›¸é—œæ–‡ä»¶ ---\")\n",
    "for i, doc in enumerate(relevant_docs, 1):\n",
    "    print(f\"æ–‡ä»¶ {i}:\\n{doc.page_content}\\n\")\n",
    "    if doc.metadata:\n",
    "        print(f\"ä¾†æº: {doc.metadata.get('source', 'Unknown')}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¸‹ä¸€å€‹å„²å­˜æ ¼ï¼šæ•´åˆ Chain - ä½¿ç”¨ RunnableLambda çš„å‚³çµ±åšæ³•ï¼ˆå’Œä¸Šä¸€å€‹ Chain å¯¦ç¾ç›¸åŒçš„ RAG æµç¨‹ï¼‰\n",
    "# é€™è£¡çš„åšæ³•ï¼Œå…¶å¯¦å’Œä¸Šä¸€å€‹å„²å­˜æ ¼ï¼ˆdict + RunnablePassthroughï¼‰åŠŸèƒ½æ˜¯ä¸€æ¨£çš„ï¼Œåªæ˜¯èªæ³•ä¸åŒ\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "question = \"å¦‚ä½•è¨­å®šæŒ‡ç´‹è¾¨è­˜ï¼Ÿ\"\n",
    "print(f\"å•é¡Œ: {question}\\n\")\n",
    "\n",
    "# (æ­¥é©Ÿå±•ç¤ºï¼šå’Œä¸‹ä¸€æ ¼ä¸€æ¨£ï¼Œå– 2 ç­†ç›¸é—œæ–‡ä»¶)\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 2}\n",
    ")\n",
    "retrieved_docs = retriever.invoke(question)\n",
    "print(f\"æ‰¾åˆ° {len(retrieved_docs)} å€‹ç›¸é—œæ–‡ä»¶\\n\")\n",
    "for i, doc in enumerate(retrieved_docs, 1):\n",
    "    print(f\"æ–‡ä»¶ {i} (å‰100å­—):\")\n",
    "    print(doc.page_content[:100] + \"...\\n\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"å»ºç«‹ RAG Chainï¼ˆRunnableLambda å‚³çµ±åšæ³•ï¼‰\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# å’Œä¸Šä¸€å€‹å„²å­˜æ ¼ä¸€æ¨£çš„ prompt è¨­è¨ˆ\n",
    "template = \"\"\"ä½ æ˜¯ä¸€å€‹æ™ºæ…§å‹æ‰‹æ©Ÿçš„å®¢æœåŠ©æ‰‹ã€‚è«‹æ ¹æ“šä»¥ä¸‹åƒè€ƒè³‡æ–™å›ç­”ä½¿ç”¨è€…çš„å•é¡Œã€‚\n",
    "\n",
    "åƒè€ƒè³‡æ–™ï¼š\n",
    "{context}\n",
    "\n",
    "ä½¿ç”¨è€…å•é¡Œï¼š{question}\n",
    "\n",
    "è«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”ï¼Œä¸¦ä¸”ï¼š\n",
    "1. åªæ ¹æ“šåƒè€ƒè³‡æ–™å›ç­”ï¼Œä¸è¦ç·¨é€ å…§å®¹\n",
    "2. å¦‚æœåƒè€ƒè³‡æ–™ä¸­æ²’æœ‰ç­”æ¡ˆï¼Œè«‹èª å¯¦èªªã€Œæˆ‘åœ¨è³‡æ–™ä¸­æ‰¾ä¸åˆ°ç›¸é—œè³‡è¨Šã€\n",
    "3. å›ç­”è¦æ¸…æ¥šã€å…·é«”ã€æœ‰æ¢ç†\n",
    "\n",
    "å›ç­”ï¼š\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "llm = ChatOllama(model=\"llama3.2\", temperature=0)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "def retrieve_docs(question):\n",
    "    docs = retriever.invoke(question)\n",
    "    return format_docs(docs)\n",
    "\n",
    "# æ³¨æ„é€™é‚Š: å…¶å¯¦ combine_context_and_question åªæ˜¯ identity mappingï¼Œå’Œ Passthrough/dict ç”¨æ³•è¡¨ç¾ä¸€è‡´\n",
    "def combine_context_and_question(inputs):\n",
    "    return {\"context\": inputs[\"context\"], \"question\": inputs[\"question\"]}\n",
    "\n",
    "rag_chain = (\n",
    "    RunnableLambda(lambda x: {\"context\": retrieve_docs(x), \"question\": x})\n",
    "    | RunnableLambda(combine_context_and_question)\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"âœ… RAG Chain å»ºç«‹å®Œæˆï¼ˆRunnableLambda å¯«æ³•ï¼Œè·Ÿä¸Šä¸€æ ¼åŠŸèƒ½ä¸€æ¨£ï¼Œåªæ˜¯èªæ³•ä¸åŒï¼‰\\n\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"åŸ·è¡Œ RAG Chain\")\n",
    "print(\"=\" * 60)\n",
    "answer = rag_chain.invoke(question)\n",
    "\n",
    "print(f\"\\nã€AI å›ç­”ã€‘\\n{answer}\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¬¬4å€‹å„²å­˜æ ¼ï¼šæ•´åˆ Chain - å»ºç«‹ç°¡å–®çš„ RAG å•ç­”éˆ\n",
    "# ChainéŠå…§ä½¿ç”¨dict,å’ŒRunnablePassthrough,retriever\n",
    "# è§€å¿µèªªæ˜,è«‹çœ‹ä¸‹æ–¹é‡è¦è§€å¿µ\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# å®šç¾©ä½¿ç”¨è€…çš„å•é¡Œ\n",
    "question = \"å¦‚ä½•è¨­å®šæŒ‡ç´‹è¾¨è­˜ï¼Ÿ\"\n",
    "\n",
    "print(f\"å•é¡Œ: {question}\\n\")\n",
    "\n",
    "# æ­¥é©Ÿ 1: å¾å‘é‡è³‡æ–™åº«æª¢ç´¢ç›¸é—œæ–‡ä»¶\n",
    "print(\"=\" * 60)\n",
    "print(\"æ­¥é©Ÿ 1: å¾å‘é‡è³‡æ–™åº«æª¢ç´¢ç›¸é—œæ–‡ä»¶\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 2}  # åªå–æœ€ç›¸é—œçš„ 2 å€‹æ–‡ä»¶\n",
    ")\n",
    "retrieved_docs = retriever.invoke(question)\n",
    "\n",
    "print(f\"æ‰¾åˆ° {len(retrieved_docs)} å€‹ç›¸é—œæ–‡ä»¶\\n\")\n",
    "for i, doc in enumerate(retrieved_docs, 1):\n",
    "    print(f\"æ–‡ä»¶ {i} (å‰100å­—):\")\n",
    "    print(doc.page_content[:100] + \"...\\n\")\n",
    "\n",
    "# æ­¥é©Ÿ 2: å»ºç«‹ RAG Chain\n",
    "print(\"=\" * 60)\n",
    "print(\"æ­¥é©Ÿ 2: å»ºç«‹ RAG Chain\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# å®šç¾©æç¤ºæ¨¡æ¿\n",
    "template = \"\"\"ä½ æ˜¯ä¸€å€‹æ™ºæ…§å‹æ‰‹æ©Ÿçš„å®¢æœåŠ©æ‰‹ã€‚è«‹æ ¹æ“šä»¥ä¸‹åƒè€ƒè³‡æ–™å›ç­”ä½¿ç”¨è€…çš„å•é¡Œã€‚\n",
    "\n",
    "åƒè€ƒè³‡æ–™ï¼š\n",
    "{context}\n",
    "\n",
    "ä½¿ç”¨è€…å•é¡Œï¼š{question}\n",
    "\n",
    "è«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”ï¼Œä¸¦ä¸”ï¼š\n",
    "1. åªæ ¹æ“šåƒè€ƒè³‡æ–™å›ç­”ï¼Œä¸è¦ç·¨é€ å…§å®¹\n",
    "2. å¦‚æœåƒè€ƒè³‡æ–™ä¸­æ²’æœ‰ç­”æ¡ˆï¼Œè«‹èª å¯¦èªªã€Œæˆ‘åœ¨è³‡æ–™ä¸­æ‰¾ä¸åˆ°ç›¸é—œè³‡è¨Šã€\n",
    "3. å›ç­”è¦æ¸…æ¥šã€å…·é«”ã€æœ‰æ¢ç†\n",
    "\n",
    "å›ç­”ï¼š\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# å»ºç«‹ LLMï¼ˆä½¿ç”¨æœ¬åœ° Ollamaï¼‰\n",
    "llm = ChatOllama(model=\"llama3.2\", temperature=0)\n",
    "\n",
    "# å®šç¾©æ–‡ä»¶æ ¼å¼åŒ–å‡½æ•¸\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "# å»ºç«‹å®Œæ•´çš„ RAG Chain\n",
    "# RunnablePassthrough() è®“ question ç›´æ¥å‚³éä¸‹å»\n",
    "# retriever | format_docs å°‡æª¢ç´¢çµæœæ ¼å¼åŒ–ç‚º context\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"âœ… RAG Chain å»ºç«‹å®Œæˆ\\n\")\n",
    "\n",
    "# æ­¥é©Ÿ 3: åŸ·è¡Œ RAG Chain ä¸¦å–å¾—ç­”æ¡ˆ\n",
    "print(\"=\" * 60)\n",
    "print(\"æ­¥é©Ÿ 3: åŸ·è¡Œ RAG Chain\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "answer = rag_chain.invoke(question)\n",
    "\n",
    "print(f\"\\nã€AI å›ç­”ã€‘\\n{answer}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“š é‡è¦è§€å¿µï¼šç†è§£ Dict åœ¨ LangChain ä¸­çš„ç”¨æ³•\n",
    "\n",
    "### ğŸ¯ ç‚ºä»€éº¼ RAG Chain å…§ä½¿ç”¨ Dictï¼Ÿ\n",
    "\n",
    "åœ¨ RAGï¼ˆæª¢ç´¢å¢å¼·ç”Ÿæˆï¼‰ç³»çµ±ä¸­ï¼Œæˆ‘å€‘éœ€è¦åŒæ™‚è™•ç†**å…©å€‹ä¸åŒçš„è³‡æ–™æµ**ï¼š\n",
    "\n",
    "1. **ä½¿ç”¨è€…å•é¡Œ**ï¼ˆquestionï¼‰- éœ€è¦åŸå°ä¸å‹•åœ°å‚³éçµ¦ LLM\n",
    "2. **æª¢ç´¢åˆ°çš„ä¸Šä¸‹æ–‡**ï¼ˆcontextï¼‰- éœ€è¦ç¶“éæ ¼å¼åŒ–è™•ç†å¾Œå‚³éçµ¦ LLM\n",
    "\n",
    "### ğŸ”§ Dict çš„æ ¸å¿ƒä½œç”¨\n",
    "\n",
    "**Dict å°±åƒä¸€å€‹ã€Œè³‡æ–™æ•´åˆå™¨ã€**ï¼Œå®ƒèƒ½å¤ ï¼š\n",
    "\n",
    "```python\n",
    "# Dict çš„çµæ§‹åŒ–è™•ç†æ–¹å¼\n",
    "{\n",
    "    \"context\": retriever | format_docs,    # è™•ç†æª¢ç´¢åˆ°çš„æ–‡ä»¶\n",
    "    \"question\": RunnablePassthrough()      # ç›´æ¥å‚³éåŸå§‹å•é¡Œ\n",
    "}\n",
    "```\n",
    "\n",
    "### ğŸ“ å¯¦éš›ç¯„ä¾‹èªªæ˜\n",
    "\n",
    "è®“æˆ‘å€‘çœ‹çœ‹æ‚¨ç­†è¨˜æœ¬ä¸­çš„å¯¦éš›ç¨‹å¼ç¢¼ï¼š\n",
    "\n",
    "```4:4:4_rag/1_rag_basics.ipynb\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "```\n",
    "\n",
    "### ğŸ” è©³ç´°é‹ä½œæµç¨‹\n",
    "\n",
    "1. **è¼¸å…¥éšæ®µ**ï¼š\n",
    "   - ä½¿ç”¨è€…å•é¡Œï¼š`\"å¦‚ä½•è¨­å®šæŒ‡ç´‹è¾¨è­˜ï¼Ÿ\"`\n",
    "\n",
    "2. **Dict è™•ç†éšæ®µ**ï¼š\n",
    "   - `\"context\"` éµï¼šåŸ·è¡Œ `retriever | format_docs`\n",
    "     - æª¢ç´¢ç›¸é—œæ–‡ä»¶\n",
    "     - æ ¼å¼åŒ–ç‚ºå­—ä¸²\n",
    "   - `\"question\"` éµï¼šåŸ·è¡Œ `RunnablePassthrough()`\n",
    "     - ç›´æ¥å‚³éåŸå§‹å•é¡Œ\n",
    "\n",
    "3. **è¼¸å‡ºéšæ®µ**ï¼š\n",
    "   ```python\n",
    "   {\n",
    "       \"context\": \"iPhone 15 æœ‰æŒ‡ç´‹è¾¨è­˜åŠŸèƒ½ï¼Œè¨­å®šæ­¥é©Ÿï¼š1. é€²å…¥è¨­å®š 2. é¸æ“‡ Touch ID 3. æ·»åŠ æŒ‡ç´‹...\",\n",
    "       \"question\": \"å¦‚ä½•è¨­å®šæŒ‡ç´‹è¾¨è­˜ï¼Ÿ\"\n",
    "   }\n",
    "   ```\n",
    "\n",
    "### ğŸ’¡ ç‚ºä»€éº¼ä¸ä½¿ç”¨å…¶ä»–æ–¹æ³•ï¼Ÿ\n",
    "\n",
    "**âŒ å¦‚æœä¸ç”¨ Dictï¼Œæœƒé‡åˆ°çš„å•é¡Œï¼š**\n",
    "\n",
    "```python\n",
    "# éŒ¯èª¤åšæ³•ï¼šç„¡æ³•åŒæ™‚è™•ç†å…©å€‹è³‡æ–™æµ\n",
    "def wrong_approach(question):\n",
    "    context = retriever.invoke(question)  # åªèƒ½è™•ç†ä¸€å€‹æµç¨‹\n",
    "    return context  # å•é¡Œè³‡è¨Šä¸Ÿå¤±äº†\n",
    "```\n",
    "\n",
    "**âœ… ä½¿ç”¨ Dict çš„å„ªå‹¢ï¼š**\n",
    "\n",
    "1. **ä¸¦è¡Œè™•ç†**ï¼šåŒæ™‚è™•ç†å¤šå€‹è³‡æ–™æµ\n",
    "2. **çµæ§‹æ¸…æ™°**ï¼šæ˜ç¢ºçš„éµå€¼å°å°æ‡‰é—œä¿‚\n",
    "3. **å¯æ“´å±•æ€§**ï¼šå®¹æ˜“æ·»åŠ æ–°çš„æ¬„ä½\n",
    "4. **é¡å‹å®‰å…¨**ï¼šæ¯å€‹æ¬„ä½éƒ½æœ‰æ˜ç¢ºçš„ç”¨é€”\n",
    "\n",
    "### ğŸ¨ èˆ‡ Prompt Template çš„å®Œç¾é…åˆ\n",
    "\n",
    "Dict çš„è¼¸å‡ºæœƒè‡ªå‹•å°æ‡‰åˆ° Prompt Template ä¸­çš„è®Šæ•¸ï¼š\n",
    "\n",
    "```python\n",
    "template = \"\"\"\n",
    "åƒè€ƒè³‡æ–™ï¼š{context}    # â† å°æ‡‰ Dict ä¸­çš„ \"context\" éµ\n",
    "ä½¿ç”¨è€…å•é¡Œï¼š{question}  # â† å°æ‡‰ Dict ä¸­çš„ \"question\" éµ\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "### ğŸš€ å¯¦éš›æ‡‰ç”¨å ´æ™¯\n",
    "\n",
    "Dict åœ¨ RAG ä¸­çš„æ‡‰ç”¨ä¸åƒ…é™æ–¼åŸºæœ¬çš„å•é¡Œ-ä¸Šä¸‹æ–‡é…å°ï¼Œé‚„å¯ä»¥æ“´å±•åˆ°ï¼š\n",
    "\n",
    "```python\n",
    "# æ“´å±•çš„ Dict ç”¨æ³•\n",
    "{\n",
    "    \"context\": retriever | format_docs,\n",
    "    \"question\": RunnablePassthrough(),\n",
    "    \"user_id\": lambda x: get_user_id(x),      # æ–°å¢ï¼šä½¿ç”¨è€… ID\n",
    "    \"timestamp\": lambda x: get_timestamp(),   # æ–°å¢ï¼šæ™‚é–“æˆ³\n",
    "    \"conversation_history\": lambda x: get_history(x)  # æ–°å¢ï¼šå°è©±æ­·å²\n",
    "}\n",
    "```\n",
    "\n",
    "### ğŸ“‹ ç¸½çµ\n",
    "\n",
    "**Dict åœ¨ RAG Chain ä¸­çš„æ ¸å¿ƒåƒ¹å€¼ï¼š**\n",
    "\n",
    "1. **è³‡æ–™æ•´åˆ**ï¼šå°‡å¤šå€‹è™•ç†æµç¨‹çš„çµæœæ•´åˆåœ¨ä¸€èµ·\n",
    "2. **æµç¨‹æ§åˆ¶**ï¼šè®“ä¸åŒçš„è³‡æ–™æµèƒ½å¤ ä¸¦è¡Œè™•ç†\n",
    "3. **çµæ§‹åŒ–ç®¡ç†**ï¼šæä¾›æ¸…æ™°çš„éµå€¼å°å°æ‡‰é—œä¿‚\n",
    "4. **æ“´å±•æ€§**ï¼šå®¹æ˜“æ·»åŠ æ–°çš„è™•ç†æµç¨‹\n",
    "\n",
    "LangChain çš„ RAG å¯¦ä½œä¸­ï¼ŒDict æ˜¯ä¸å¯æˆ–ç¼ºçš„é‡è¦çµ„ä»¶ï¼å®ƒè®“æˆ‘å€‘èƒ½å¤ å„ªé›…åœ°è™•ç†è¤‡é›œçš„å¤šè³‡æ–™æµå ´æ™¯ï¼ŒåŒæ™‚ä¿æŒç¨‹å¼ç¢¼çš„æ¸…æ™°å’Œå¯ç¶­è­·æ€§ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä»‹ç´¹retriever\n",
    "- ç‚ºä»€éº¼retrieverå¯ä»¥æ”¾åœ¨chainå…§,\n",
    "- ç‚ºä»€éº¼æœƒè‡ªå‹•åŸ·è¡Œinvoke()\n",
    "- å‚³å‡ºä¾†çš„æ˜¯ä»€éº¼?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” Retriever æ·±åº¦è§£æ\n",
    "\n",
    "### ğŸ¯ ä»€éº¼æ˜¯ Retrieverï¼Ÿ\n",
    "\n",
    "**Retrieverï¼ˆæª¢ç´¢å™¨ï¼‰** æ˜¯ RAG ç³»çµ±ä¸­çš„æ ¸å¿ƒçµ„ä»¶ï¼Œè² è²¬å¾å‘é‡è³‡æ–™åº«ä¸­æª¢ç´¢èˆ‡ä½¿ç”¨è€…å•é¡Œç›¸é—œçš„æ–‡ä»¶ã€‚\n",
    "\n",
    "### ğŸ”§ ç‚ºä»€éº¼ Retriever å¯ä»¥æ”¾åœ¨ Chain å…§ï¼Ÿ\n",
    "\n",
    "#### 1. **Runnable ä»‹é¢å¯¦ç¾**\n",
    "\n",
    "- Retriever å¯¦ç¾äº† LangChain çš„ Runnable ä»‹é¢\n",
    "- format_docsï¼ˆä¸€å€‹æ™®é€šå‡½æ•¸ï¼‰æœƒè‡ªå‹•åŒ…è£æˆ RunnableLambda\n",
    "- RunnablePassthrough() æœ¬èº«å°±æ˜¯ä¸€å€‹ Runnable\n",
    "- ChatPromptTemplate æ˜¯ Runnable\n",
    "- LLM ä¹Ÿæ˜¯ Runnable\n",
    "\n",
    "Retriever å¯¦ç¾äº† LangChain çš„ `Runnable` ä»‹é¢ï¼Œé€™æ„å‘³è‘—å®ƒå¯ä»¥ï¼š\n",
    "\n",
    "```python\n",
    "# Retriever æ˜¯ä¸€å€‹ Runnable ç‰©ä»¶\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 2}\n",
    ")\n",
    "\n",
    "# å¯ä»¥åƒå…¶ä»– Runnable ä¸€æ¨£ä½¿ç”¨ | æ“ä½œç¬¦\n",
    "retriever | format_docs\n",
    "```\n",
    "\n",
    "#### 2. **è‡ªå‹• Chain æ•´åˆ**\n",
    "\n",
    "ç•¶ retriever æ”¾åœ¨ Chain ä¸­æ™‚ï¼ŒLangChain æœƒè‡ªå‹•è™•ç†ï¼š\n",
    "\n",
    "```python\n",
    "# åœ¨ Chain ä¸­çš„ä½¿ç”¨æ–¹å¼\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "```\n",
    "\n",
    "**å…§éƒ¨é‹ä½œæµç¨‹ï¼š**\n",
    "1. è¼¸å…¥å•é¡Œ â†’ retriever\n",
    "2. retriever åŸ·è¡Œæª¢ç´¢ â†’ è¿”å› Document åˆ—è¡¨\n",
    "3. Document åˆ—è¡¨ â†’ format_docs å‡½æ•¸\n",
    "4. æ ¼å¼åŒ–å¾Œçš„æ–‡å­— â†’ å‚³éçµ¦ prompt\n",
    "\n",
    "### âš¡ ç‚ºä»€éº¼æœƒè‡ªå‹•åŸ·è¡Œ invoke()ï¼Ÿ\n",
    "\n",
    "#### 1. **LCELï¼ˆLangChain Expression Languageï¼‰æ©Ÿåˆ¶**\n",
    "\n",
    "ç•¶ Chain åŸ·è¡Œæ™‚ï¼ŒLangChain æœƒè‡ªå‹•èª¿ç”¨æ¯å€‹çµ„ä»¶çš„ `invoke()` æ–¹æ³•ï¼š\n",
    "\n",
    "```python\n",
    "# ç•¶ä½ åŸ·è¡Œ\n",
    "result = rag_chain.invoke(\"å¦‚ä½•è¨­å®šæŒ‡ç´‹è¾¨è­˜ï¼Ÿ\")\n",
    "\n",
    "# LangChain å…§éƒ¨æœƒè‡ªå‹•åŸ·è¡Œï¼š\n",
    "# 1. retriever.invoke(\"å¦‚ä½•è¨­å®šæŒ‡ç´‹è¾¨è­˜ï¼Ÿ\")\n",
    "# 2. format_docs(retriever_result)\n",
    "# 3. prompt.invoke({\"context\": formatted_docs, \"question\": \"å¦‚ä½•è¨­å®šæŒ‡ç´‹è¾¨è­˜ï¼Ÿ\"})\n",
    "# 4. llm.invoke(prompt_result)\n",
    "# 5. StrOutputParser().invoke(llm_result)\n",
    "```\n",
    "\n",
    "#### 2. **è‡ªå‹•åŒ–æµç¨‹æ§åˆ¶**\n",
    "\n",
    "```python\n",
    "# æ‰‹å‹•åŸ·è¡Œ vs è‡ªå‹•åŸ·è¡Œ\n",
    "# æ‰‹å‹•æ–¹å¼ï¼š\n",
    "question = \"å¦‚ä½•è¨­å®šæŒ‡ç´‹è¾¨è­˜ï¼Ÿ\"\n",
    "docs = retriever.invoke(question)  # æ‰‹å‹•èª¿ç”¨\n",
    "formatted_context = format_docs(docs)\n",
    "result = prompt.invoke({\"context\": formatted_context, \"question\": question})\n",
    "\n",
    "# Chain è‡ªå‹•æ–¹å¼ï¼š\n",
    "result = rag_chain.invoke(question)  # è‡ªå‹•èª¿ç”¨æ‰€æœ‰çµ„ä»¶çš„ invoke()\n",
    "```\n",
    "\n",
    "### ğŸ“¤ Retriever å‚³å‡ºä¾†çš„æ˜¯ä»€éº¼ï¼Ÿ\n",
    "\n",
    "#### 1. **Document ç‰©ä»¶åˆ—è¡¨**\n",
    "\n",
    "Retriever è¿”å›çš„æ˜¯ `Document` ç‰©ä»¶çš„åˆ—è¡¨ï¼š\n",
    "\n",
    "```python\n",
    "# retriever.invoke() çš„è¿”å›å€¼\n",
    "retrieved_docs = retriever.invoke(\"å¦‚ä½•è¨­å®šæŒ‡ç´‹è¾¨è­˜ï¼Ÿ\")\n",
    "\n",
    "print(f\"é¡å‹ï¼š{type(retrieved_docs)}\")  # <class 'list'>\n",
    "print(f\"é•·åº¦ï¼š{len(retrieved_docs)}\")   # 2\n",
    "\n",
    "# æ¯å€‹ Document ç‰©ä»¶çš„çµæ§‹\n",
    "for i, doc in enumerate(retrieved_docs):\n",
    "    print(f\"æ–‡ä»¶ {i+1}:\")\n",
    "    print(f\"  å…§å®¹ï¼š{doc.page_content[:100]}...\")\n",
    "    print(f\"  å…ƒæ•¸æ“šï¼š{doc.metadata}\")\n",
    "    print(f\"  é¡å‹ï¼š{type(doc)}\")  # <class 'langchain_core.documents.Document'>\n",
    "```\n",
    "\n",
    "#### 2. **Document ç‰©ä»¶çš„è©³ç´°çµæ§‹**\n",
    "\n",
    "```python\n",
    "# Document ç‰©ä»¶åŒ…å«ï¼š\n",
    "class Document:\n",
    "    page_content: str      # æ–‡ä»¶çš„ä¸»è¦å…§å®¹\n",
    "    metadata: dict         # å…ƒæ•¸æ“šï¼ˆä¾†æºã€é ç¢¼ç­‰ï¼‰\n",
    "    \n",
    "# å¯¦éš›ç¯„ä¾‹ï¼š\n",
    "doc = retrieved_docs[0]\n",
    "print(f\"å…§å®¹ï¼š{doc.page_content}\")\n",
    "print(f\"å…ƒæ•¸æ“šï¼š{doc.metadata}\")\n",
    "# è¼¸å‡ºï¼š\n",
    "# å…§å®¹ï¼šiPhone 15 æœ‰æŒ‡ç´‹è¾¨è­˜åŠŸèƒ½ï¼Œè¨­å®šæ­¥é©Ÿï¼š1. é€²å…¥è¨­å®š 2. é¸æ“‡ Touch ID 3. æ·»åŠ æŒ‡ç´‹...\n",
    "# å…ƒæ•¸æ“šï¼š{'source': '/path/to/smartphone_manual.txt'}\n",
    "```\n",
    "\n",
    "#### 3. **åœ¨ Chain ä¸­çš„è½‰æ›éç¨‹**\n",
    "\n",
    "```python\n",
    "# å®Œæ•´çš„è³‡æ–™æµè½‰æ›\n",
    "def format_docs(docs):\n",
    "    \"\"\"å°‡ Document åˆ—è¡¨è½‰æ›ç‚ºå­—ä¸²\"\"\"\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "# Chain ä¸­çš„è™•ç†æµç¨‹ï¼š\n",
    "# 1. retriever.invoke(question) â†’ [Document, Document, ...]\n",
    "# 2. format_docs(docs) â†’ \"æ–‡ä»¶1å…§å®¹\\n\\næ–‡ä»¶2å…§å®¹\\n\\n...\"\n",
    "# 3. å‚³éçµ¦ prompt çš„ {context} è®Šæ•¸\n",
    "```\n",
    "\n",
    "### ğŸ”„ å¯¦éš›é‹ä½œç¯„ä¾‹\n",
    "\n",
    "è®“æˆ‘å±•ç¤ºä¸€å€‹å®Œæ•´çš„ retriever é‹ä½œéç¨‹ï¼š\n",
    "\n",
    "```python\n",
    "# æ­¥é©Ÿ 1ï¼šå»ºç«‹ retriever\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 2}\n",
    ")\n",
    "\n",
    "# æ­¥é©Ÿ 2ï¼šæ‰‹å‹•åŸ·è¡Œï¼ˆäº†è§£å…§éƒ¨é‹ä½œï¼‰\n",
    "question = \"å¦‚ä½•è¨­å®šæŒ‡ç´‹è¾¨è­˜ï¼Ÿ\"\n",
    "print(f\"å•é¡Œï¼š{question}\")\n",
    "\n",
    "# æª¢ç´¢éç¨‹\n",
    "docs = retriever.invoke(question)\n",
    "print(f\"\\næª¢ç´¢çµæœé¡å‹ï¼š{type(docs)}\")\n",
    "print(f\"æª¢ç´¢åˆ° {len(docs)} å€‹æ–‡ä»¶\")\n",
    "\n",
    "# æŸ¥çœ‹æ¯å€‹ Document\n",
    "for i, doc in enumerate(docs, 1):\n",
    "    print(f\"\\næ–‡ä»¶ {i}:\")\n",
    "    print(f\"  å…§å®¹é•·åº¦ï¼š{len(doc.page_content)} å­—å…ƒ\")\n",
    "    print(f\"  å‰100å­—ï¼š{doc.page_content[:100]}...\")\n",
    "    print(f\"  å…ƒæ•¸æ“šï¼š{doc.metadata}\")\n",
    "\n",
    "# æ­¥é©Ÿ 3ï¼šæ ¼å¼åŒ–è™•ç†\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "formatted_context = format_docs(docs)\n",
    "print(f\"\\næ ¼å¼åŒ–å¾Œçš„ä¸Šä¸‹æ–‡é•·åº¦ï¼š{len(formatted_context)} å­—å…ƒ\")\n",
    "print(f\"æ ¼å¼åŒ–çµæœï¼š{formatted_context[:200]}...\")\n",
    "```\n",
    "\n",
    "### ğŸ“‹ ç¸½çµ\n",
    "\n",
    "**Retriever çš„æ ¸å¿ƒç‰¹æ€§ï¼š**\n",
    "\n",
    "1. **Runnable ä»‹é¢**ï¼šå¯ä»¥ç„¡ç¸«æ•´åˆåˆ° LangChain Chain ä¸­\n",
    "2. **è‡ªå‹• invoke()**ï¼šLCEL æ©Ÿåˆ¶è‡ªå‹•èª¿ç”¨æª¢ç´¢åŠŸèƒ½\n",
    "3. **Document åˆ—è¡¨è¼¸å‡º**ï¼šè¿”å›çµæ§‹åŒ–çš„æ–‡ä»¶ç‰©ä»¶åˆ—è¡¨\n",
    "4. **å…ƒæ•¸æ“šä¿ç•™**ï¼šä¿æŒæ–‡ä»¶çš„ä¾†æºå’Œç›¸é—œè³‡è¨Š\n",
    "5. **å¯é…ç½®æ€§**ï¼šæ”¯æ´ä¸åŒçš„æª¢ç´¢ç­–ç•¥å’Œåƒæ•¸\n",
    "\n",
    "**åœ¨ RAG Chain ä¸­çš„ä½œç”¨ï¼š**\n",
    "- **è¼¸å…¥**ï¼šä½¿ç”¨è€…å•é¡Œï¼ˆå­—ä¸²ï¼‰\n",
    "- **è™•ç†**ï¼šå‘é‡ç›¸ä¼¼åº¦æª¢ç´¢\n",
    "- **è¼¸å‡º**ï¼šç›¸é—œ Document ç‰©ä»¶åˆ—è¡¨\n",
    "- **æ•´åˆ**ï¼šèˆ‡å…¶ä»– Chain çµ„ä»¶ç„¡ç¸«ä¸²æ¥\n",
    "\n",
    "é€™å°±æ˜¯ç‚ºä»€éº¼ retriever èƒ½å¤ å¦‚æ­¤å„ªé›…åœ°æ•´åˆåˆ° LangChain çš„ Chain æ¶æ§‹ä¸­ï¼Œæˆç‚º RAG ç³»çµ±çš„æ ¸å¿ƒçµ„ä»¶ï¼"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
