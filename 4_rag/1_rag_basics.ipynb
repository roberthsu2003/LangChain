{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG åŸºç¤å…¥é–€\n",
    "\n",
    "æœ¬ç¯„ä¾‹å±•ç¤ºï¼š\n",
    "1. **ç¬¬1å€‹å„²å­˜æ ¼**ï¼šå»ºç«‹å‘é‡è³‡æ–™åº«\n",
    "2. **ç¬¬2å€‹å„²å­˜æ ¼**ï¼šæŸ¥è©¢å‘é‡è³‡æ–™åº«\n",
    "\n",
    "å­¸ç¿’ç›®æ¨™ï¼šç†è§£å¦‚ä½•å°‡æ–‡æœ¬è½‰æ›ç‚ºå‘é‡ä¸¦é€²è¡Œç›¸ä¼¼åº¦æª¢ç´¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æŒä¹…åŒ–ç›®éŒ„ä¸å­˜åœ¨ã€‚æ­£åœ¨åˆå§‹åŒ–å‘é‡å­˜å„²...\n",
      "\n",
      "--- æ–‡ä»¶å¡Šè³‡è¨Š ---\n",
      "æ–‡ä»¶å¡Šæ•¸é‡: 6\n",
      "ç¯„ä¾‹å¡Š:\n",
      "æ™ºæ…§å‹æ‰‹æ©Ÿä½¿ç”¨æ‰‹å†Š\n",
      "\n",
      "æ­¡è¿ä½¿ç”¨æ‚¨çš„æ–°æ™ºæ…§å‹æ‰‹æ©Ÿ!æœ¬æ‰‹å†Šå°‡å”åŠ©æ‚¨å¿«é€Ÿä¸Šæ‰‹ä¸¦å……åˆ†åˆ©ç”¨æ‰‹æ©Ÿçš„å„é …åŠŸèƒ½ã€‚\n",
      "\n",
      "ç¬¬ä¸€ç« ï¼šé–‹å§‹ä½¿ç”¨\n",
      "\n",
      "1.1 é–‹ç®±èˆ‡é¦–æ¬¡è¨­å®š\n",
      "æ‰“é–‹åŒ…è£ç›’å¾Œ,æ‚¨æœƒçœ‹åˆ°ä»¥ä¸‹é…ä»¶:\n",
      "- æ™ºæ…§å‹æ‰‹æ©Ÿä¸»æ©Ÿ x1\n",
      "- USB-C å……é›»ç·š x1\n",
      "- å¿«é€Ÿå……é›»å™¨(20W) x1\n",
      "- SIM å¡é€€å¡é‡ x1\n",
      "- ä½¿ç”¨èªªæ˜æ›¸ x1\n",
      "- ä¿å›ºå¡ x1\n",
      "\n",
      "é¦–æ¬¡é–‹æ©Ÿè¨­å®šæ­¥é©Ÿ:\n",
      "1. é•·æŒ‰é›»æºéµ 3 ç§’é–‹æ©Ÿ\n",
      "2. é¸æ“‡èªè¨€(ç¹é«”ä¸­æ–‡)\n",
      "3. é€£æ¥ Wi-Fi ç¶²è·¯\n",
      "4. ç™»å…¥æˆ–å»ºç«‹ Google å¸³è™Ÿ(Android)æˆ– Apple ID(iOS)\n",
      "5. è¨­å®šè¢å¹•é–å®šæ–¹å¼(æŒ‡ç´‹/è‡‰éƒ¨è¾¨è­˜/å¯†ç¢¼)\n",
      "6. åŒæ„æœå‹™æ¢æ¬¾èˆ‡éš±ç§æ¬Šæ”¿ç­–\n",
      "7. å®Œæˆè¨­å®šä¸¦é€²å…¥ä¸»ç•«é¢\n",
      "\n",
      "1.2 SIM å¡å®‰è£\n",
      "1. æ‰¾åˆ°æ‰‹æ©Ÿå´é‚Šçš„ SIM å¡æ§½\n",
      "2. ä½¿ç”¨é€€å¡é‡æ’å…¥å¡æ§½æ—çš„å°å­”\n",
      "3. è¼•è¼•æ¨å…¥ç›´åˆ°å¡æ§½å½ˆå‡º\n",
      "4. å°‡ SIM å¡æ”¾å…¥å¡æ§½(æ³¨æ„ç¼ºè§’æ–¹å‘)\n",
      "5. å°‡å¡æ§½æ¨å›æ‰‹æ©Ÿ\n",
      "6. ç­‰å¾… 5-10 ç§’è­˜åˆ¥ SIM å¡\n",
      "\n",
      "æ”¯æ´çš„ SIM å¡é¡å‹:\n",
      "- Nano-SIM(4FF)æ¨™æº–\n",
      "- é›™å¡é›™å¾…åŠŸèƒ½\n",
      "- 5G/4G LTE ç¶²è·¯\n",
      "\n",
      "ç¬¬äºŒç« :åŸºæœ¬æ“ä½œ\n",
      "\n",
      "2.1 è¢å¹•æ‰‹å‹¢\n",
      "- é»æ“Š:è¼•è§¸ä¸€æ¬¡é–‹å•Ÿæ‡‰ç”¨ç¨‹å¼\n",
      "- é•·æŒ‰:é¡¯ç¤ºæ›´å¤šé¸é …æˆ–ç§»å‹•åœ–ç¤º\n",
      "- æ»‘å‹•:åˆ‡æ›ç•«é¢æˆ–æ²å‹•å…§å®¹\n",
      "- é›™æŒ‡ç¸®æ”¾:æ”¾å¤§æˆ–ç¸®å°åœ–ç‰‡/ç¶²é \n",
      "- å¾ä¸Šå¾€ä¸‹æ»‘:é–‹å•Ÿé€šçŸ¥ä¸­å¿ƒ\n",
      "- å¾ä¸‹å¾€ä¸Šæ»‘:é¡¯ç¤ºå¸¸ç”¨åŠŸèƒ½å¿«æ·éµ\n",
      "\n",
      "2.2 ä¸»ç•«é¢é…ç½®\n",
      "- ç‹€æ…‹åˆ—:é¡¯ç¤ºæ™‚é–“ã€é›»é‡ã€è¨Šè™Ÿå¼·åº¦\n",
      "- é€šçŸ¥åœ–ç¤ºå€:é¡¯ç¤ºæœªè®€è¨Šæ¯ã€ä¾†é›»ç­‰\n",
      "- æ‡‰ç”¨ç¨‹å¼åœ–ç¤º:é»æ“Šé–‹å•Ÿæ‡‰ç”¨ç¨‹å¼\n",
      "- åº•éƒ¨å°èˆªåˆ—:è¿”å›ã€é¦–é ã€å¤šå·¥\n",
      "\n",
      "è‡ªè¨‚ä¸»ç•«é¢:\n",
      "1. é•·æŒ‰æ¡Œé¢ç©ºç™½è™•\n",
      "2. é¸æ“‡ã€Œæ–°å¢å°å·¥å…·ã€æˆ–ã€Œæ¡Œå¸ƒã€\n",
      "3. æ‹–æ›³æ‡‰ç”¨ç¨‹å¼åœ–ç¤ºä¾†é‡æ–°æ’åˆ—\n",
      "4. å»ºç«‹è³‡æ–™å¤¾:å°‡ä¸€å€‹ App æ‹–åˆ°å¦ä¸€å€‹ App ä¸Š\n",
      "\n",
      "2.3 é–å®šè¢å¹•è¨­å®š\n",
      "æ”¯æ´çš„è§£é–æ–¹å¼:\n",
      "- æŒ‡ç´‹è¾¨è­˜(è¢å¹•ä¸‹æŒ‡ç´‹æ„Ÿæ‡‰)\n",
      "- è‡‰éƒ¨è¾¨è­˜(å‰ç½®ç›¸æ©Ÿ)\n",
      "- åœ–å½¢å¯†ç¢¼\n",
      "- PIN ç¢¼(4-6 ä½æ•¸å­—)\n",
      "- å¯†ç¢¼(è‹±æ•¸æ··åˆ)\n",
      "\n",
      "è¨­å®šè§£é–æ–¹å¼:\n",
      "è¨­å®š > å®‰å…¨æ€§èˆ‡éš±ç§ > è¢å¹•é–å®š > é¸æ“‡è§£é–æ–¹å¼\n",
      "\n",
      "ç¬¬ä¸‰ç« :ç›¸æ©ŸåŠŸèƒ½\n",
      "\n",
      "3.1 ç›¸æ©ŸåŸºæœ¬æ“ä½œ\n",
      "å¾Œç½®ä¸»é¡é ­è¦æ ¼:\n",
      "- 5000 è¬ç•«ç´ ä¸»é¡é ­(f/1.8)\n",
      "- 1200 è¬ç•«ç´ è¶…å»£è§’é¡é ­(120Â°)\n",
      "- 800 è¬ç•«ç´ é•·ç„¦é¡é ­(3å€å…‰å­¸è®Šç„¦)\n",
      "\n",
      "\n",
      "--- æ­£åœ¨å»ºç«‹åµŒå…¥ ---\n",
      "ä½¿ç”¨ Jina Embeddings v2ï¼ˆç¹é«”ä¸­æ–‡é–‹æºæ¨¡å‹ï¼‰\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/kb_wcfhj3710_xnyqdgx_v940000gn/T/ipykernel_1183/1628490538.py:42: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n",
      "Some weights of BertModel were not initialized from the model checkpoint at jinaai/jina-embeddings-v2-base-zh and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- å®Œæˆå»ºç«‹åµŒå…¥ ---\n",
      "\n",
      "--- æ­£åœ¨å»ºç«‹å‘é‡å­˜å„² ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertSdpaSelfAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support non-absolute `position_embedding_type` or `output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- å®Œæˆå»ºç«‹å‘é‡å­˜å„² ---\n"
     ]
    }
   ],
   "source": [
    "# ç¬¬1å€‹å„²å­˜æ ¼ï¼šå»ºç«‹å‘é‡è³‡æ–™åº«\n",
    "\n",
    "import os\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# å®šç¾©åŒ…å«æ–‡å­—æª”æ¡ˆçš„ç›®éŒ„å’ŒæŒä¹…åŒ–ç›®éŒ„\n",
    "current_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "file_path = os.path.join(current_dir, \"books\", \"æ™ºæ…§å‹æ‰‹æ©Ÿä½¿ç”¨æ‰‹å†Š.txt\")\n",
    "persistent_directory = os.path.join(current_dir, \"db\", \"chroma_db_chinese_nb\")\n",
    "\n",
    "# æª¢æŸ¥ Chroma å‘é‡å­˜å„²æ˜¯å¦å·²å­˜åœ¨\n",
    "if not os.path.exists(persistent_directory):\n",
    "    print(\"æŒä¹…åŒ–ç›®éŒ„ä¸å­˜åœ¨ã€‚æ­£åœ¨åˆå§‹åŒ–å‘é‡å­˜å„²...\")\n",
    "\n",
    "    # ç¢ºä¿æ–‡å­—æª”æ¡ˆå­˜åœ¨\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(\n",
    "            f\"æª”æ¡ˆ {file_path} ä¸å­˜åœ¨ã€‚è«‹æª¢æŸ¥è·¯å¾‘ã€‚\"\n",
    "        )\n",
    "\n",
    "    # å¾æª”æ¡ˆè®€å–æ–‡å­—å…§å®¹\n",
    "    loader = TextLoader(file_path)\n",
    "    documents = loader.load()\n",
    "\n",
    "    # å°‡æ–‡ä»¶åˆ†å‰²æˆå¡Š\n",
    "    # chunk_size=1000: æ¯å€‹æ–‡æœ¬å€å¡Šæœ€å¤š 1000 å€‹å­—å…ƒ\n",
    "    # chunk_overlap=0: å€å¡Šä¹‹é–“ä¸é‡ç–Š\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "\n",
    "    # é¡¯ç¤ºåˆ†å‰²æ–‡ä»¶çš„è³‡è¨Š\n",
    "    print(\"\\n--- æ–‡ä»¶å¡Šè³‡è¨Š ---\")\n",
    "    print(f\"æ–‡ä»¶å¡Šæ•¸é‡: {len(docs)}\")\n",
    "    print(f\"ç¯„ä¾‹å¡Š:\\n{docs[0].page_content}\\n\")\n",
    "\n",
    "    # å»ºç«‹åµŒå…¥æ¨¡å‹\n",
    "    print(\"\\n--- æ­£åœ¨å»ºç«‹åµŒå…¥ ---\")\n",
    "    print(\"ä½¿ç”¨ Jina Embeddings v2ï¼ˆç¹é«”ä¸­æ–‡é–‹æºæ¨¡å‹ï¼‰\")\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=\"jinaai/jina-embeddings-v2-base-zh\"\n",
    "    )\n",
    "    print(\"\\n--- å®Œæˆå»ºç«‹åµŒå…¥ ---\")\n",
    "\n",
    "    # å»ºç«‹å‘é‡å­˜å„²ä¸¦è‡ªå‹•æŒä¹…åŒ–\n",
    "    print(\"\\n--- æ­£åœ¨å»ºç«‹å‘é‡å­˜å„² ---\")\n",
    "    db = Chroma.from_documents(\n",
    "        docs, embeddings, persist_directory=persistent_directory)\n",
    "    print(\"\\n--- å®Œæˆå»ºç«‹å‘é‡å­˜å„² ---\")\n",
    "\n",
    "else:\n",
    "    print(\"å‘é‡å­˜å„²å·²å­˜åœ¨ã€‚ç„¡éœ€åˆå§‹åŒ–ã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¬¬2å€‹å„²å­˜æ ¼ï¼šæŸ¥è©¢å‘é‡è³‡æ–™åº«\n",
    "\n",
    "import os\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# å®šç¾©æŒä¹…åŒ–ç›®éŒ„\n",
    "current_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "persistent_directory = os.path.join(current_dir, \"db\", \"chroma_db_chinese_nb\")\n",
    "\n",
    "# å®šç¾©åµŒå…¥æ¨¡å‹ï¼ˆä½¿ç”¨é–‹æºç¹é«”ä¸­æ–‡æ¨¡å‹ï¼‰\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"jinaai/jina-embeddings-v2-base-zh\")\n",
    "\n",
    "# ä½¿ç”¨åµŒå…¥å‡½æ•¸è¼‰å…¥ç¾æœ‰çš„å‘é‡å­˜å„²\n",
    "db = Chroma(persist_directory=persistent_directory,\n",
    "            embedding_function=embeddings)\n",
    "\n",
    "# å®šç¾©ä½¿ç”¨è€…çš„å•é¡Œ\n",
    "query = \"å¦‚ä½•è¨­å®šæŒ‡ç´‹è¾¨è­˜ï¼Ÿ\"\n",
    "\n",
    "# æ ¹æ“šæŸ¥è©¢æª¢ç´¢ç›¸é—œæ–‡ä»¶\n",
    "# search_type=\"similarity_score_threshold\": ä½¿ç”¨ç›¸ä¼¼åº¦åˆ†æ•¸é–¾å€¼éæ¿¾\n",
    "# k=3: è¿”å›æœ€å¤š 3 å€‹ç›¸é—œæ–‡ä»¶\n",
    "# score_threshold=0.9: åªè¿”å›ç›¸ä¼¼åº¦åˆ†æ•¸ >= 0.9 çš„æ–‡ä»¶\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\"k\": 3, \"score_threshold\": 0.9},\n",
    ")\n",
    "relevant_docs = retriever.invoke(query)\n",
    "\n",
    "# é¡¯ç¤ºç›¸é—œçµæœåŠå…ƒæ•¸æ“š\n",
    "print(\"\\n--- ç›¸é—œæ–‡ä»¶ ---\")\n",
    "for i, doc in enumerate(relevant_docs, 1):\n",
    "    print(f\"æ–‡ä»¶ {i}:\\n{doc.page_content}\\n\")\n",
    "    if doc.metadata:\n",
    "        print(f\"ä¾†æº: {doc.metadata.get('source', 'Unknown')}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¬¬3å€‹å„²å­˜æ ¼ï¼šæ•´åˆ Chain - å»ºç«‹ç°¡å–®çš„ RAG å•ç­”éˆ\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# å®šç¾©ä½¿ç”¨è€…çš„å•é¡Œ\n",
    "question = \"å¦‚ä½•è¨­å®šæŒ‡ç´‹è¾¨è­˜ï¼Ÿ\"\n",
    "\n",
    "print(f\"å•é¡Œ: {question}\\n\")\n",
    "\n",
    "# æ­¥é©Ÿ 1: å¾å‘é‡è³‡æ–™åº«æª¢ç´¢ç›¸é—œæ–‡ä»¶\n",
    "print(\"=\" * 60)\n",
    "print(\"æ­¥é©Ÿ 1: å¾å‘é‡è³‡æ–™åº«æª¢ç´¢ç›¸é—œæ–‡ä»¶\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 2}  # åªå–æœ€ç›¸é—œçš„ 2 å€‹æ–‡ä»¶\n",
    ")\n",
    "retrieved_docs = retriever.invoke(question)\n",
    "\n",
    "print(f\"æ‰¾åˆ° {len(retrieved_docs)} å€‹ç›¸é—œæ–‡ä»¶\\n\")\n",
    "for i, doc in enumerate(retrieved_docs, 1):\n",
    "    print(f\"æ–‡ä»¶ {i} (å‰100å­—):\")\n",
    "    print(doc.page_content[:100] + \"...\\n\")\n",
    "\n",
    "# æ­¥é©Ÿ 2: å»ºç«‹ RAG Chain\n",
    "print(\"=\" * 60)\n",
    "print(\"æ­¥é©Ÿ 2: å»ºç«‹ RAG Chain\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# å®šç¾©æç¤ºæ¨¡æ¿\n",
    "template = \"\"\"ä½ æ˜¯ä¸€å€‹æ™ºæ…§å‹æ‰‹æ©Ÿçš„å®¢æœåŠ©æ‰‹ã€‚è«‹æ ¹æ“šä»¥ä¸‹åƒè€ƒè³‡æ–™å›ç­”ä½¿ç”¨è€…çš„å•é¡Œã€‚\n",
    "\n",
    "åƒè€ƒè³‡æ–™ï¼š\n",
    "{context}\n",
    "\n",
    "ä½¿ç”¨è€…å•é¡Œï¼š{question}\n",
    "\n",
    "è«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”ï¼Œä¸¦ä¸”ï¼š\n",
    "1. åªæ ¹æ“šåƒè€ƒè³‡æ–™å›ç­”ï¼Œä¸è¦ç·¨é€ å…§å®¹\n",
    "2. å¦‚æœåƒè€ƒè³‡æ–™ä¸­æ²’æœ‰ç­”æ¡ˆï¼Œè«‹èª å¯¦èªªã€Œæˆ‘åœ¨è³‡æ–™ä¸­æ‰¾ä¸åˆ°ç›¸é—œè³‡è¨Šã€\n",
    "3. å›ç­”è¦æ¸…æ¥šã€å…·é«”ã€æœ‰æ¢ç†\n",
    "\n",
    "å›ç­”ï¼š\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# å»ºç«‹ LLMï¼ˆä½¿ç”¨æœ¬åœ° Ollamaï¼‰\n",
    "llm = ChatOllama(model=\"llama3.2\", temperature=0)\n",
    "\n",
    "# å®šç¾©æ–‡ä»¶æ ¼å¼åŒ–å‡½æ•¸\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# å»ºç«‹å®Œæ•´çš„ RAG Chain\n",
    "# RunnablePassthrough() è®“ question ç›´æ¥å‚³éä¸‹å»\n",
    "# retriever | format_docs å°‡æª¢ç´¢çµæœæ ¼å¼åŒ–ç‚º context\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"âœ… RAG Chain å»ºç«‹å®Œæˆ\\n\")\n",
    "\n",
    "# æ­¥é©Ÿ 3: åŸ·è¡Œ RAG Chain ä¸¦å–å¾—ç­”æ¡ˆ\n",
    "print(\"=\" * 60)\n",
    "print(\"æ­¥é©Ÿ 3: åŸ·è¡Œ RAG Chain\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "answer = rag_chain.invoke(question)\n",
    "\n",
    "print(f\"\\nã€AI å›ç­”ã€‘\\n{answer}\\n\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"RAG Chain æµç¨‹ç¸½çµ\")\n",
    "print(\"=\" * 60)\n",
    "print(\"1. ä½¿ç”¨è€…æå• â†’ å‘é‡æª¢ç´¢æ‰¾ç›¸é—œæ–‡ä»¶\")\n",
    "print(\"2. å°‡æ–‡ä»¶å’Œå•é¡Œçµ„åˆæˆæç¤ºè©\")\n",
    "print(\"3. é€çµ¦ LLM ç”Ÿæˆç­”æ¡ˆ\")\n",
    "print(\"4. è§£æä¸¦è¿”å›ç­”æ¡ˆ\")\n",
    "print(\"\\nğŸ’¡ é€™å°±æ˜¯å¾ Chain 3 å­¸åˆ°çš„æŠ€å·§æ‡‰ç”¨åœ¨ RAG ä¸Šï¼\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
