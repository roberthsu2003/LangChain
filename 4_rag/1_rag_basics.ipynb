{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG åŸºç¤å…¥é–€\n",
    "\n",
    "æœ¬ç¯„ä¾‹å±•ç¤ºï¼š\n",
    "1. **ç¬¬1å€‹å„²å­˜æ ¼**ï¼šå»ºç«‹å‘é‡è³‡æ–™åº«\n",
    "2. **ç¬¬2å€‹å„²å­˜æ ¼**ï¼šæŸ¥è©¢å‘é‡è³‡æ–™åº«\n",
    "\n",
    "å­¸ç¿’ç›®æ¨™ï¼šç†è§£å¦‚ä½•å°‡æ–‡æœ¬è½‰æ›ç‚ºå‘é‡ä¸¦é€²è¡Œç›¸ä¼¼åº¦æª¢ç´¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ç¬¬1å€‹å„²å­˜æ ¼ï¼šå»ºç«‹å‘é‡è³‡æ–™åº«\n\nimport os\nfrom langchain.text_splitter import CharacterTextSplitter\nfrom langchain_community.document_loaders import TextLoader\nfrom langchain_community.vectorstores import Chroma\nfrom langchain_community.embeddings import HuggingFaceEmbeddings\n\n# å®šç¾©åŒ…å«æ–‡å­—æª”æ¡ˆçš„ç›®éŒ„å’ŒæŒä¹…åŒ–ç›®éŒ„\ncurrent_dir = os.path.dirname(os.path.abspath(\"__file__\"))\nfile_path = os.path.join(current_dir, \"books\", \"æ™ºæ…§å‹æ‰‹æ©Ÿä½¿ç”¨æ‰‹å†Š.txt\")\npersistent_directory = os.path.join(current_dir, \"db\", \"chroma_db_chinese_nb\")\n\n# æª¢æŸ¥ Chroma å‘é‡å­˜å„²æ˜¯å¦å·²å­˜åœ¨\nif not os.path.exists(persistent_directory):\n    print(\"æŒä¹…åŒ–ç›®éŒ„ä¸å­˜åœ¨ã€‚æ­£åœ¨åˆå§‹åŒ–å‘é‡å­˜å„²...\")\n\n    # ç¢ºä¿æ–‡å­—æª”æ¡ˆå­˜åœ¨\n    if not os.path.exists(file_path):\n        raise FileNotFoundError(\n            f\"æª”æ¡ˆ {file_path} ä¸å­˜åœ¨ã€‚è«‹æª¢æŸ¥è·¯å¾‘ã€‚\"\n        )\n\n    # å¾æª”æ¡ˆè®€å–æ–‡å­—å…§å®¹\n    loader = TextLoader(file_path)\n    documents = loader.load()\n\n    # å°‡æ–‡ä»¶åˆ†å‰²æˆå¡Š\n    # chunk_size=1000: æ¯å€‹æ–‡æœ¬å€å¡Šæœ€å¤š 1000 å€‹å­—å…ƒ\n    # chunk_overlap=0: å€å¡Šä¹‹é–“ä¸é‡ç–Š\n    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n    docs = text_splitter.split_documents(documents)\n\n    # é¡¯ç¤ºåˆ†å‰²æ–‡ä»¶çš„è³‡è¨Š\n    print(\"\\n--- æ–‡ä»¶å¡Šè³‡è¨Š ---\")\n    print(f\"æ–‡ä»¶å¡Šæ•¸é‡: {len(docs)}\")\n    print(f\"ç¯„ä¾‹å¡Š:\\n{docs[0].page_content}\\n\")\n\n    # å»ºç«‹åµŒå…¥æ¨¡å‹\n    print(\"\\n--- æ­£åœ¨å»ºç«‹åµŒå…¥ ---\")\n    print(\"ä½¿ç”¨ Jina Embeddings v2ï¼ˆç¹é«”ä¸­æ–‡é–‹æºæ¨¡å‹ï¼‰\")\n    embeddings = HuggingFaceEmbeddings(\n        model_name=\"jinaai/jina-embeddings-v2-base-zh\"\n    )\n    print(\"\\n--- å®Œæˆå»ºç«‹åµŒå…¥ ---\")\n\n    # å»ºç«‹å‘é‡å­˜å„²ä¸¦è‡ªå‹•æŒä¹…åŒ–\n    print(\"\\n--- æ­£åœ¨å»ºç«‹å‘é‡å­˜å„² ---\")\n    db = Chroma.from_documents(\n        docs, embeddings, persist_directory=persistent_directory)\n    print(\"\\n--- å®Œæˆå»ºç«‹å‘é‡å­˜å„² ---\")\n\nelse:\n    print(\"å‘é‡å­˜å„²å·²å­˜åœ¨ã€‚ç„¡éœ€åˆå§‹åŒ–ã€‚\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ç¬¬2å€‹å„²å­˜æ ¼ï¼šæŸ¥è©¢å‘é‡è³‡æ–™åº«\n\nimport os\nfrom langchain_community.vectorstores import Chroma\nfrom langchain_community.embeddings import HuggingFaceEmbeddings\n\n# å®šç¾©æŒä¹…åŒ–ç›®éŒ„\ncurrent_dir = os.path.dirname(os.path.abspath(\"__file__\"))\npersistent_directory = os.path.join(current_dir, \"db\", \"chroma_db_chinese_nb\")\n\n# å®šç¾©åµŒå…¥æ¨¡å‹ï¼ˆä½¿ç”¨é–‹æºç¹é«”ä¸­æ–‡æ¨¡å‹ï¼‰\nembeddings = HuggingFaceEmbeddings(model_name=\"jinaai/jina-embeddings-v2-base-zh\")\n\n# ä½¿ç”¨åµŒå…¥å‡½æ•¸è¼‰å…¥ç¾æœ‰çš„å‘é‡å­˜å„²\ndb = Chroma(persist_directory=persistent_directory,\n            embedding_function=embeddings)\n\n# å®šç¾©ä½¿ç”¨è€…çš„å•é¡Œ\nquery = \"å¦‚ä½•è¨­å®šæŒ‡ç´‹è¾¨è­˜ï¼Ÿ\"\n\n# æ ¹æ“šæŸ¥è©¢æª¢ç´¢ç›¸é—œæ–‡ä»¶\n# search_type=\"similarity_score_threshold\": ä½¿ç”¨ç›¸ä¼¼åº¦åˆ†æ•¸é–¾å€¼éæ¿¾\n# k=3: è¿”å›æœ€å¤š 3 å€‹ç›¸é—œæ–‡ä»¶\n# score_threshold=0.9: åªè¿”å›ç›¸ä¼¼åº¦åˆ†æ•¸ >= 0.9 çš„æ–‡ä»¶\nretriever = db.as_retriever(\n    search_type=\"similarity_score_threshold\",\n    search_kwargs={\"k\": 3, \"score_threshold\": 0.9},\n)\nrelevant_docs = retriever.invoke(query)\n\n# é¡¯ç¤ºç›¸é—œçµæœåŠå…ƒæ•¸æ“š\nprint(\"\\n--- ç›¸é—œæ–‡ä»¶ ---\")\nfor i, doc in enumerate(relevant_docs, 1):\n    print(f\"æ–‡ä»¶ {i}:\\n{doc.page_content}\\n\")\n    if doc.metadata:\n        print(f\"ä¾†æº: {doc.metadata.get('source', 'Unknown')}\\n\")"
  },
  {
   "cell_type": "code",
   "source": "# ç¬¬3å€‹å„²å­˜æ ¼ï¼šæ•´åˆ Chain - å»ºç«‹ç°¡å–®çš„ RAG å•ç­”éˆ\n\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.runnables import RunnablePassthrough\nfrom langchain_ollama import ChatOllama\n\n# å®šç¾©ä½¿ç”¨è€…çš„å•é¡Œ\nquestion = \"å¦‚ä½•è¨­å®šæŒ‡ç´‹è¾¨è­˜ï¼Ÿ\"\n\nprint(f\"å•é¡Œ: {question}\\n\")\n\n# æ­¥é©Ÿ 1: å¾å‘é‡è³‡æ–™åº«æª¢ç´¢ç›¸é—œæ–‡ä»¶\nprint(\"=\" * 60)\nprint(\"æ­¥é©Ÿ 1: å¾å‘é‡è³‡æ–™åº«æª¢ç´¢ç›¸é—œæ–‡ä»¶\")\nprint(\"=\" * 60)\n\nretriever = db.as_retriever(\n    search_type=\"similarity\",\n    search_kwargs={\"k\": 2}  # åªå–æœ€ç›¸é—œçš„ 2 å€‹æ–‡ä»¶\n)\nretrieved_docs = retriever.invoke(question)\n\nprint(f\"æ‰¾åˆ° {len(retrieved_docs)} å€‹ç›¸é—œæ–‡ä»¶\\n\")\nfor i, doc in enumerate(retrieved_docs, 1):\n    print(f\"æ–‡ä»¶ {i} (å‰100å­—):\")\n    print(doc.page_content[:100] + \"...\\n\")\n\n# æ­¥é©Ÿ 2: å»ºç«‹ RAG Chain\nprint(\"=\" * 60)\nprint(\"æ­¥é©Ÿ 2: å»ºç«‹ RAG Chain\")\nprint(\"=\" * 60)\n\n# å®šç¾©æç¤ºæ¨¡æ¿\ntemplate = \"\"\"ä½ æ˜¯ä¸€å€‹æ™ºæ…§å‹æ‰‹æ©Ÿçš„å®¢æœåŠ©æ‰‹ã€‚è«‹æ ¹æ“šä»¥ä¸‹åƒè€ƒè³‡æ–™å›ç­”ä½¿ç”¨è€…çš„å•é¡Œã€‚\n\nåƒè€ƒè³‡æ–™ï¼š\n{context}\n\nä½¿ç”¨è€…å•é¡Œï¼š{question}\n\nè«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”ï¼Œä¸¦ä¸”ï¼š\n1. åªæ ¹æ“šåƒè€ƒè³‡æ–™å›ç­”ï¼Œä¸è¦ç·¨é€ å…§å®¹\n2. å¦‚æœåƒè€ƒè³‡æ–™ä¸­æ²’æœ‰ç­”æ¡ˆï¼Œè«‹èª å¯¦èªªã€Œæˆ‘åœ¨è³‡æ–™ä¸­æ‰¾ä¸åˆ°ç›¸é—œè³‡è¨Šã€\n3. å›ç­”è¦æ¸…æ¥šã€å…·é«”ã€æœ‰æ¢ç†\n\nå›ç­”ï¼š\"\"\"\n\nprompt = ChatPromptTemplate.from_template(template)\n\n# å»ºç«‹ LLMï¼ˆä½¿ç”¨æœ¬åœ° Ollamaï¼‰\nllm = ChatOllama(model=\"llama3.2\", temperature=0)\n\n# å®šç¾©æ–‡ä»¶æ ¼å¼åŒ–å‡½æ•¸\ndef format_docs(docs):\n    return \"\\n\\n\".join(doc.page_content for doc in docs)\n\n# å»ºç«‹å®Œæ•´çš„ RAG Chain\n# RunnablePassthrough() è®“ question ç›´æ¥å‚³éä¸‹å»\n# retriever | format_docs å°‡æª¢ç´¢çµæœæ ¼å¼åŒ–ç‚º context\nrag_chain = (\n    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n    | prompt\n    | llm\n    | StrOutputParser()\n)\n\nprint(\"âœ… RAG Chain å»ºç«‹å®Œæˆ\\n\")\n\n# æ­¥é©Ÿ 3: åŸ·è¡Œ RAG Chain ä¸¦å–å¾—ç­”æ¡ˆ\nprint(\"=\" * 60)\nprint(\"æ­¥é©Ÿ 3: åŸ·è¡Œ RAG Chain\")\nprint(\"=\" * 60)\n\nanswer = rag_chain.invoke(question)\n\nprint(f\"\\nã€AI å›ç­”ã€‘\\n{answer}\\n\")\n\nprint(\"=\" * 60)\nprint(\"RAG Chain æµç¨‹ç¸½çµ\")\nprint(\"=\" * 60)\nprint(\"1. ä½¿ç”¨è€…æå• â†’ å‘é‡æª¢ç´¢æ‰¾ç›¸é—œæ–‡ä»¶\")\nprint(\"2. å°‡æ–‡ä»¶å’Œå•é¡Œçµ„åˆæˆæç¤ºè©\")\nprint(\"3. é€çµ¦ LLM ç”Ÿæˆç­”æ¡ˆ\")\nprint(\"4. è§£æä¸¦è¿”å›ç­”æ¡ˆ\")\nprint(\"\\nğŸ’¡ é€™å°±æ˜¯å¾ Chain 3 å­¸åˆ°çš„æŠ€å·§æ‡‰ç”¨åœ¨ RAG ä¸Šï¼\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}