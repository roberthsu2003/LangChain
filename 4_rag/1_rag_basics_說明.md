# RAG Chain å¾é›¶é–‹å§‹æ•™å­¸

## ğŸ“š å­¸ç¿’ç›®æ¨™

é€šéæœ¬æ•™å­¸ï¼Œå­¸ç”Ÿå°‡èƒ½å¤ ï¼š
1. ç†è§£ä»€éº¼æ˜¯ RAG å’Œç‚ºä»€éº¼éœ€è¦å®ƒ
2. æŒæ¡ LangChain çš„åŸºæœ¬æ¦‚å¿µå’Œèªæ³•
3. å­¸æœƒé€æ­¥æ§‹å»º RAG Chain
4. äº†è§£æ¯å€‹çµ„ä»¶çš„ä½œç”¨å’Œé‹ä½œåŸç†

---

## ğŸ¯ ç¬¬ä¸€èª²ï¼šä»€éº¼æ˜¯ RAGï¼Ÿ

### **RAG æ˜¯ä»€éº¼ï¼Ÿ**

**RAG = Retrieval-Augmented Generationï¼ˆæª¢ç´¢å¢å¼·ç”Ÿæˆï¼‰**

æƒ³åƒä½ æ˜¯ä¸€å€‹åœ–æ›¸é¤¨ç®¡ç†å“¡ï¼Œç•¶æœ‰äººå•å•é¡Œæ™‚ï¼š
1. **æª¢ç´¢ï¼ˆRetrievalï¼‰**ï¼šå…ˆå»æ‰¾ç›¸é—œçš„æ›¸ç±å’Œè³‡æ–™
2. **å¢å¼·ï¼ˆAugmentedï¼‰**ï¼šæŠŠæ‰¾åˆ°çš„è³‡æ–™æ•´ç†å¥½
3. **ç”Ÿæˆï¼ˆGenerationï¼‰**ï¼šåŸºæ–¼é€™äº›è³‡æ–™ä¾†å›ç­”å•é¡Œ

### **ç‚ºä»€éº¼éœ€è¦ RAGï¼Ÿ**

**å‚³çµ± AI çš„å•é¡Œï¼š**
- çŸ¥è­˜å¯èƒ½éæ™‚
- ç„¡æ³•å­˜å–æœ€æ–°è³‡è¨Š
- å°ç‰¹å®šé ˜åŸŸçŸ¥è­˜æœ‰é™

**RAG çš„å„ªå‹¢ï¼š**
- å¯ä»¥å­˜å–æœ€æ–°è³‡æ–™
- åŸºæ–¼çœŸå¯¦æ–‡ä»¶å›ç­”
- å›ç­”æ›´æº–ç¢ºã€æ›´æœ‰æ ¹æ“š

### **å°ç¯„ä¾‹ï¼šç†è§£ RAG æ¦‚å¿µ**

```python
# å‡è¨­æˆ‘å€‘æœ‰ä¸€å€‹æ–‡ä»¶è³‡æ–™åº«
documents = [
    "iPhone 15 æœ‰æŒ‡ç´‹è¾¨è­˜åŠŸèƒ½ï¼Œè¨­å®šæ­¥é©Ÿï¼š1. é€²å…¥è¨­å®š 2. é¸æ“‡ Touch ID 3. æ·»åŠ æŒ‡ç´‹",
    "MacBook Pro æ”¯æ´ Face IDï¼Œåœ¨ç³»çµ±åå¥½è¨­å®šä¸­å¯ä»¥å•Ÿç”¨",
    "iPad æœ‰é¢å®¹ ID åŠŸèƒ½ï¼Œå¯ä»¥åœ¨è¨­å®šä¸­é€²è¡Œè¨­å®š"
]

# ç•¶ç”¨æˆ¶å•ï¼š"å¦‚ä½•è¨­å®šæŒ‡ç´‹è¾¨è­˜ï¼Ÿ"
question = "å¦‚ä½•è¨­å®šæŒ‡ç´‹è¾¨è­˜ï¼Ÿ"

# RAG ç³»çµ±æœƒï¼š
# 1. æª¢ç´¢ç›¸é—œæ–‡ä»¶ï¼ˆæ‰¾åˆ° iPhone 15 çš„è³‡æ–™ï¼‰
# 2. åŸºæ–¼æª¢ç´¢åˆ°çš„è³‡æ–™å›ç­”å•é¡Œ
```

---

## ğŸ”§ ç¬¬äºŒèª²ï¼šLangChain åŸºç¤æ¦‚å¿µ

### **ä»€éº¼æ˜¯ LangChainï¼Ÿ**

LangChain æ˜¯ä¸€å€‹å¹«åŠ©æˆ‘å€‘æ§‹å»º AI æ‡‰ç”¨çš„å·¥å…·åŒ…ï¼Œå°±åƒæ¨‚é«˜ç©æœ¨ä¸€æ¨£ï¼Œå¯ä»¥çµ„åˆä¸åŒçš„çµ„ä»¶ã€‚

### **æ ¸å¿ƒæ¦‚å¿µï¼šChainï¼ˆéˆï¼‰**

**Chain = æŠŠå¤šå€‹æ­¥é©Ÿä¸²è¯èµ·ä¾†**

```python
# ç°¡å–®çš„ Chain ç¯„ä¾‹
def simple_chain(text):
    # æ­¥é©Ÿ 1ï¼šè½‰å¤§å¯«
    step1 = text.upper()
    # æ­¥é©Ÿ 2ï¼šåŠ é©šå˜†è™Ÿ
    step2 = step1 + "!"
    # æ­¥é©Ÿ 3ï¼šåŠ é•·åº¦
    step3 = f"{step2} (é•·åº¦: {len(step2)})"
    return step3

# æ¸¬è©¦
result = simple_chain("hello")
print(result)  # è¼¸å‡ºï¼šHELLO! (é•·åº¦: 6)
```

### **LangChain çš„ Chain èªæ³•**

```python
# ä½¿ç”¨ | æ“ä½œç¬¦ä¸²è¯æ­¥é©Ÿ
from langchain_core.runnables import RunnableLambda

def upper_case(text):
    return text.upper()

def add_exclamation(text):
    return text + "!"

def add_length(text):
    return f"{text} (é•·åº¦: {len(text)})"

# å‰µå»º Chain
simple_chain = (
    RunnableLambda(upper_case)
    | RunnableLambda(add_exclamation)
    | RunnableLambda(add_length)
)

# æ¸¬è©¦
result = simple_chain.invoke("hello")
print(result)  # è¼¸å‡ºï¼šHELLO! (é•·åº¦: 6)
```

### **å°ç¯„ä¾‹ï¼šç†è§£ Chain çš„é‹ä½œ**

```python
# æ›´ç›´è§€çš„ç¯„ä¾‹
def step1(x):
    print(f"æ­¥é©Ÿ 1: æ”¶åˆ° {x}")
    return x * 2

def step2(x):
    print(f"æ­¥é©Ÿ 2: æ”¶åˆ° {x}")
    return x + 10

def step3(x):
    print(f"æ­¥é©Ÿ 3: æ”¶åˆ° {x}")
    return f"æœ€çµ‚çµæœ: {x}"

# æ‰‹å‹•åŸ·è¡Œ
input_value = 5
result1 = step1(input_value)  # 5 * 2 = 10
result2 = step2(result1)      # 10 + 10 = 20
result3 = step3(result2)      # "æœ€çµ‚çµæœ: 20"
print(result3)

# ä½¿ç”¨ Chain
chain = (
    RunnableLambda(step1)
    | RunnableLambda(step2)
    | RunnableLambda(step3)
)
print(chain.invoke(5))
```

---

## ğŸ§© ç¬¬ä¸‰èª²ï¼šRAG Chain çš„çµ„ä»¶

### **RAG Chain éœ€è¦å“ªäº›çµ„ä»¶ï¼Ÿ**

1. **Retrieverï¼ˆæª¢ç´¢å™¨ï¼‰**ï¼šè² è²¬æ‰¾ç›¸é—œæ–‡ä»¶
2. **Formatterï¼ˆæ ¼å¼åŒ–å™¨ï¼‰**ï¼šæŠŠæ–‡ä»¶æ•´ç†æˆå¯è®€æ ¼å¼
3. **Promptï¼ˆæç¤ºæ¨¡æ¿ï¼‰**ï¼šæº–å‚™çµ¦ AI çš„å•é¡Œ
4. **LLMï¼ˆèªè¨€æ¨¡å‹ï¼‰**ï¼šç”Ÿæˆå›ç­”
5. **Parserï¼ˆè§£æå™¨ï¼‰**ï¼šè™•ç† AI çš„å›ç­”

### **å°ç¯„ä¾‹ï¼šç†è§£æ¯å€‹çµ„ä»¶**

```python
# 1. Retriever ç¯„ä¾‹
def simple_retriever(question):
    """ç°¡å–®çš„æª¢ç´¢å™¨ï¼Œæ ¹æ“šé—œéµå­—æ‰¾æ–‡ä»¶"""
    documents = [
        "iPhone 15 æœ‰æŒ‡ç´‹è¾¨è­˜åŠŸèƒ½ï¼Œè¨­å®šæ­¥é©Ÿï¼š1. é€²å…¥è¨­å®š 2. é¸æ“‡ Touch ID 3. æ·»åŠ æŒ‡ç´‹",
        "MacBook Pro æ”¯æ´ Face IDï¼Œåœ¨ç³»çµ±åå¥½è¨­å®šä¸­å¯ä»¥å•Ÿç”¨",
        "iPad æœ‰é¢å®¹ ID åŠŸèƒ½ï¼Œå¯ä»¥åœ¨è¨­å®šä¸­é€²è¡Œè¨­å®š"
    ]
    
    # ç°¡å–®çš„é—œéµå­—åŒ¹é…
    relevant_docs = []
    for doc in documents:
        if "æŒ‡ç´‹" in question and "æŒ‡ç´‹" in doc:
            relevant_docs.append(doc)
        elif "é¢å®¹" in question and "é¢å®¹" in doc:
            relevant_docs.append(doc)
    
    return relevant_docs

# æ¸¬è©¦æª¢ç´¢å™¨
docs = simple_retriever("å¦‚ä½•è¨­å®šæŒ‡ç´‹è¾¨è­˜ï¼Ÿ")
print("æª¢ç´¢åˆ°çš„æ–‡ä»¶ï¼š")
for i, doc in enumerate(docs, 1):
    print(f"{i}. {doc}")

# 2. Formatter ç¯„ä¾‹
def simple_formatter(docs):
    """æŠŠæ–‡ä»¶åˆ—è¡¨è½‰æˆå­—ä¸²"""
    return "\n\n".join(docs)

# æ¸¬è©¦æ ¼å¼åŒ–å™¨
formatted_docs = simple_formatter(docs)
print(f"\næ ¼å¼åŒ–å¾Œçš„æ–‡ä»¶ï¼š\n{formatted_docs}")

# 3. Prompt ç¯„ä¾‹
def create_prompt(context, question):
    """å‰µå»ºæç¤º"""
    return f"""
åŸºæ–¼ä»¥ä¸‹è³‡æ–™å›ç­”å•é¡Œï¼š

è³‡æ–™ï¼š
{context}

å•é¡Œï¼š{question}

å›ç­”ï¼š
"""

# æ¸¬è©¦æç¤º
prompt = create_prompt(formatted_docs, "å¦‚ä½•è¨­å®šæŒ‡ç´‹è¾¨è­˜ï¼Ÿ")
print(f"\nç”Ÿæˆçš„æç¤ºï¼š\n{prompt}")
```

---

## ğŸ”— ç¬¬å››èª²ï¼šçµ„åˆ RAG Chain

### **é€æ­¥æ§‹å»º RAG Chain**

```python
# æ­¥é©Ÿ 1ï¼šå®šç¾©å„å€‹çµ„ä»¶
def retriever(question):
    documents = [
        "iPhone 15 æœ‰æŒ‡ç´‹è¾¨è­˜åŠŸèƒ½ï¼Œè¨­å®šæ­¥é©Ÿï¼š1. é€²å…¥è¨­å®š 2. é¸æ“‡ Touch ID 3. æ·»åŠ æŒ‡ç´‹",
        "MacBook Pro æ”¯æ´ Face IDï¼Œåœ¨ç³»çµ±åå¥½è¨­å®šä¸­å¯ä»¥å•Ÿç”¨",
        "iPad æœ‰é¢å®¹ ID åŠŸèƒ½ï¼Œå¯ä»¥åœ¨è¨­å®šä¸­é€²è¡Œè¨­å®š"
    ]
    
    relevant_docs = []
    for doc in documents:
        if "æŒ‡ç´‹" in question and "æŒ‡ç´‹" in doc:
            relevant_docs.append(doc)
        elif "é¢å®¹" in question and "é¢å®¹" in doc:
            relevant_docs.append(doc)
    
    return relevant_docs

def formatter(docs):
    return "\n\n".join(docs)

def create_prompt(context, question):
    return f"""
åŸºæ–¼ä»¥ä¸‹è³‡æ–™å›ç­”å•é¡Œï¼š

è³‡æ–™ï¼š
{context}

å•é¡Œï¼š{question}

å›ç­”ï¼š
"""

# æ­¥é©Ÿ 2ï¼šæ‰‹å‹•åŸ·è¡Œ RAG æµç¨‹
def manual_rag(question):
    print(f"å•é¡Œï¼š{question}")
    
    # æª¢ç´¢
    docs = retriever(question)
    print(f"æª¢ç´¢åˆ° {len(docs)} å€‹æ–‡ä»¶")
    
    # æ ¼å¼åŒ–
    context = formatter(docs)
    print(f"æ ¼å¼åŒ–å¾Œé•·åº¦ï¼š{len(context)} å­—å…ƒ")
    
    # å‰µå»ºæç¤º
    prompt = create_prompt(context, question)
    print(f"æç¤ºé•·åº¦ï¼š{len(prompt)} å­—å…ƒ")
    
    return prompt

# æ¸¬è©¦
question = "å¦‚ä½•è¨­å®šæŒ‡ç´‹è¾¨è­˜ï¼Ÿ"
result = manual_rag(question)
print(f"\næœ€çµ‚æç¤ºï¼š\n{result}")
```

### **ä½¿ç”¨ LangChain èªæ³•é‡æ§‹**

```python
from langchain_core.runnables import RunnableLambda

# å‰µå»º Chain
retriever_chain = RunnableLambda(retriever)
formatter_chain = RunnableLambda(formatter)

# çµ„åˆæª¢ç´¢å’Œæ ¼å¼åŒ–
retrieve_and_format = retriever_chain | formatter_chain

# æ¸¬è©¦
question = "å¦‚ä½•è¨­å®šæŒ‡ç´‹è¾¨è­˜ï¼Ÿ"
context = retrieve_and_format.invoke(question)
print(f"æª¢ç´¢ä¸¦æ ¼å¼åŒ–çµæœï¼š\n{context}")
```

---

## ğŸ¨ ç¬¬äº”èª²ï¼šç†è§£ Dict åœ¨ LangChain ä¸­çš„ç”¨æ³•

### **ç‚ºä»€éº¼ RAG Chain ä½¿ç”¨ Dictï¼Ÿ**

åœ¨ RAG ä¸­ï¼Œæˆ‘å€‘éœ€è¦åŒæ™‚è™•ç†ï¼š
- **å•é¡Œ**ï¼šç”¨æˆ¶çš„åŸå§‹å•é¡Œ
- **ä¸Šä¸‹æ–‡**ï¼šæª¢ç´¢åˆ°çš„æ–‡ä»¶å…§å®¹

### **å°ç¯„ä¾‹ï¼šç†è§£ Dict çš„ä½œç”¨**

```python
# å‡è¨­æˆ‘å€‘æœ‰å…©å€‹ç¨ç«‹çš„è™•ç†æµç¨‹
def process_question(question):
    return f"å•é¡Œï¼š{question}"

def process_context(question):
    docs = retriever(question)
    return formatter(docs)

# æ–¹æ³• 1ï¼šåˆ†åˆ¥è™•ç†
question = "å¦‚ä½•è¨­å®šæŒ‡ç´‹è¾¨è­˜ï¼Ÿ"
processed_question = process_question(question)
processed_context = process_context(question)

print(f"è™•ç†å¾Œçš„å•é¡Œï¼š{processed_question}")
print(f"è™•ç†å¾Œçš„ä¸Šä¸‹æ–‡ï¼š{processed_context}")

# æ–¹æ³• 2ï¼šä½¿ç”¨ Dict åŒæ™‚è™•ç†
def process_both(question):
    return {
        "question": process_question(question),
        "context": process_context(question)
    }

result = process_both(question)
print(f"Dict çµæœï¼š{result}")
```

### **LangChain ä¸­çš„ Dict èªæ³•**

```python
from langchain_core.runnables import RunnablePassthrough

# åœ¨ LangChain ä¸­ï¼ŒDict å¯ä»¥é€™æ¨£å¯«ï¼š
def format_docs(docs):
    return "\n\n".join(docs)

# é€™å€‹ Dict æœƒåŒæ™‚è™•ç†å…©å€‹æµç¨‹
input_processor = {
    "context": retriever_chain | RunnableLambda(format_docs),
    "question": RunnablePassthrough()  # ç›´æ¥å‚³éåŸå§‹å•é¡Œ
}

# æ¸¬è©¦
question = "å¦‚ä½•è¨­å®šæŒ‡ç´‹è¾¨è­˜ï¼Ÿ"
result = input_processor.invoke(question)
print(f"Dict è™•ç†çµæœï¼š{result}")
```

---

## ğŸš€ ç¬¬å…­èª²ï¼šå®Œæ•´çš„ RAG Chain

### **æœ€çµ‚çš„ RAG Chain çµæ§‹**

```python
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate

# 1. å®šç¾©çµ„ä»¶
def format_docs(docs):
    return "\n\n".join([doc.page_content for doc in docs])

# 2. å‰µå»ºæç¤ºæ¨¡æ¿
template = """
åŸºæ–¼ä»¥ä¸‹è³‡æ–™å›ç­”å•é¡Œï¼š

è³‡æ–™ï¼š
{context}

å•é¡Œï¼š{question}

è«‹æä¾›è©³ç´°çš„å›ç­”ï¼š
"""
prompt = ChatPromptTemplate.from_template(template)

# 3. å‰µå»º LLMï¼ˆé€™è£¡ç”¨å‡è¨­çš„ï¼‰
def mock_llm(messages):
    return "æ ¹æ“šè³‡æ–™ï¼ŒiPhone 15 çš„æŒ‡ç´‹è¾¨è­˜è¨­å®šæ­¥é©Ÿå¦‚ä¸‹ï¼š1. é€²å…¥è¨­å®š 2. é¸æ“‡ Touch ID 3. æ·»åŠ æŒ‡ç´‹"

# 4. çµ„åˆå®Œæ•´çš„ RAG Chain
rag_chain = (
    {"context": retriever | RunnableLambda(format_docs), "question": RunnablePassthrough()}
    | prompt
    | RunnableLambda(mock_llm)
    | StrOutputParser()
)

# 5. æ¸¬è©¦
question = "å¦‚ä½•è¨­å®šæŒ‡ç´‹è¾¨è­˜ï¼Ÿ"
result = rag_chain.invoke(question)
print(f"RAG å›ç­”ï¼š{result}")
```

### **æ‹†è§£åŸ·è¡Œæµç¨‹**

```python
# æ‰‹å‹•åŸ·è¡Œæ¯å€‹æ­¥é©Ÿï¼Œå¹«åŠ©ç†è§£
question = "å¦‚ä½•è¨­å®šæŒ‡ç´‹è¾¨è­˜ï¼Ÿ"

print("=" * 50)
print("æ­¥é©Ÿ 1ï¼šæª¢ç´¢æ–‡ä»¶")
print("=" * 50)
docs = retriever.invoke(question)
print(f"æª¢ç´¢åˆ° {len(docs)} å€‹æ–‡ä»¶")

print("\n" + "=" * 50)
print("æ­¥é©Ÿ 2ï¼šæ ¼å¼åŒ–æ–‡ä»¶")
print("=" * 50)
context = format_docs(docs)
print(f"æ ¼å¼åŒ–å¾Œé•·åº¦ï¼š{len(context)} å­—å…ƒ")

print("\n" + "=" * 50)
print("æ­¥é©Ÿ 3ï¼šæº–å‚™è¼¸å…¥")
print("=" * 50)
inputs = {"context": context, "question": question}
print(f"è¼¸å…¥å­—å…¸ï¼š{inputs}")

print("\n" + "=" * 50)
print("æ­¥é©Ÿ 4ï¼šç”Ÿæˆæç¤º")
print("=" * 50)
formatted_prompt = prompt.format(**inputs)
print(f"æç¤ºé•·åº¦ï¼š{len(formatted_prompt)} å­—å…ƒ")

print("\n" + "=" * 50)
print("æ­¥é©Ÿ 5ï¼šç”Ÿæˆå›ç­”")
print("=" * 50)
response = mock_llm(formatted_prompt)
print(f"AI å›ç­”ï¼š{response}")

print("\n" + "=" * 50)
print("æ­¥é©Ÿ 6ï¼šè§£æè¼¸å‡º")
print("=" * 50)
final_answer = StrOutputParser().parse(response)
print(f"æœ€çµ‚ç­”æ¡ˆï¼š{final_answer}")
```

---

## ğŸ¯ ç¬¬ä¸ƒèª²ï¼šå¯¦ä½œç·´ç¿’

### **ç·´ç¿’ 1ï¼šå»ºç«‹ç°¡å–®çš„ RAG ç³»çµ±**

```python
# å®Œæ•´çš„ç°¡å–® RAG ç³»çµ±
def simple_rag_system():
    # 1. æ–‡ä»¶è³‡æ–™åº«
    documents = [
        "iPhone 15 æœ‰æŒ‡ç´‹è¾¨è­˜åŠŸèƒ½ï¼Œè¨­å®šæ­¥é©Ÿï¼š1. é€²å…¥è¨­å®š 2. é¸æ“‡ Touch ID 3. æ·»åŠ æŒ‡ç´‹",
        "MacBook Pro æ”¯æ´ Face IDï¼Œåœ¨ç³»çµ±åå¥½è¨­å®šä¸­å¯ä»¥å•Ÿç”¨",
        "iPad æœ‰é¢å®¹ ID åŠŸèƒ½ï¼Œå¯ä»¥åœ¨è¨­å®šä¸­é€²è¡Œè¨­å®š",
        "Android æ‰‹æ©Ÿæ”¯æ´æŒ‡ç´‹è¾¨è­˜ï¼Œåœ¨å®‰å…¨è¨­å®šä¸­å¯ä»¥æ‰¾åˆ°ç›¸é—œé¸é …"
    ]
    
    # 2. æª¢ç´¢å™¨
    def retriever(question):
        relevant_docs = []
        for doc in documents:
            if any(keyword in doc for keyword in question.split()):
                relevant_docs.append(doc)
        return relevant_docs[:2]  # æœ€å¤šè¿”å› 2 å€‹æ–‡ä»¶
    
    # 3. æ ¼å¼åŒ–å™¨
    def formatter(docs):
        return "\n\n".join([f"æ–‡ä»¶ {i+1}: {doc}" for i, doc in enumerate(docs)])
    
    # 4. æç¤ºç”Ÿæˆå™¨
    def create_prompt(context, question):
        return f"""
åŸºæ–¼ä»¥ä¸‹è³‡æ–™å›ç­”å•é¡Œï¼š

{context}

å•é¡Œï¼š{question}

è«‹æä¾›ç°¡æ½”æ˜ç¢ºçš„å›ç­”ï¼š
"""
    
    # 5. æ¨¡æ“¬ AI å›ç­”
    def mock_ai(prompt):
        if "æŒ‡ç´‹" in prompt:
            return "æ ¹æ“šè³‡æ–™ï¼ŒæŒ‡ç´‹è¾¨è­˜çš„è¨­å®šæ­¥é©Ÿé€šå¸¸æ˜¯ï¼š1. é€²å…¥è¨­å®š 2. é¸æ“‡ Touch ID æˆ–æŒ‡ç´‹è¾¨è­˜ 3. æ·»åŠ æŒ‡ç´‹"
        elif "é¢å®¹" in prompt:
            return "æ ¹æ“šè³‡æ–™ï¼Œé¢å®¹ ID çš„è¨­å®šé€šå¸¸åœ¨ç³»çµ±åå¥½è¨­å®šæˆ–è¨­å®šä¸­çš„å®‰å…¨é¸é …è£¡å¯ä»¥æ‰¾åˆ°"
        else:
            return "æŠ±æ­‰ï¼Œæˆ‘æ²’æœ‰æ‰¾åˆ°ç›¸é—œçš„è³‡æ–™ä¾†å›ç­”æ‚¨çš„å•é¡Œã€‚"
    
    # 6. çµ„åˆ RAG ç³»çµ±
    def rag_pipeline(question):
        print(f"ğŸ” å•é¡Œï¼š{question}")
        
        # æª¢ç´¢
        docs = retriever(question)
        print(f"ğŸ“š æª¢ç´¢åˆ° {len(docs)} å€‹ç›¸é—œæ–‡ä»¶")
        
        # æ ¼å¼åŒ–
        context = formatter(docs)
        print(f"ğŸ“ æ ¼å¼åŒ–å¾Œé•·åº¦ï¼š{len(context)} å­—å…ƒ")
        
        # ç”Ÿæˆæç¤º
        prompt = create_prompt(context, question)
        
        # ç”Ÿæˆå›ç­”
        answer = mock_ai(prompt)
        print(f"ğŸ¤– AI å›ç­”ï¼š{answer}")
        
        return answer
    
    return rag_pipeline

# æ¸¬è©¦ RAG ç³»çµ±
rag = simple_rag_system()

print("=" * 60)
print("æ¸¬è©¦å•é¡Œ 1ï¼šå¦‚ä½•è¨­å®šæŒ‡ç´‹è¾¨è­˜ï¼Ÿ")
print("=" * 60)
rag("å¦‚ä½•è¨­å®šæŒ‡ç´‹è¾¨è­˜ï¼Ÿ")

print("\n" + "=" * 60)
print("æ¸¬è©¦å•é¡Œ 2ï¼šé¢å®¹ ID æ€éº¼è¨­å®šï¼Ÿ")
print("=" * 60)
rag("é¢å®¹ ID æ€éº¼è¨­å®šï¼Ÿ")
```

### **ç·´ç¿’ 2ï¼šç†è§£ Chain çš„ä¸²è¯**

```python
# å»ºç«‹ä¸€å€‹è™•ç†æ–‡å­—çš„ Chain
def build_text_processing_chain():
    def step1(text):
        print(f"æ­¥é©Ÿ 1ï¼šæ”¶åˆ° '{text}'")
        return text.upper()
    
    def step2(text):
        print(f"æ­¥é©Ÿ 2ï¼šæ”¶åˆ° '{text}'")
        return text + "!"
    
    def step3(text):
        print(f"æ­¥é©Ÿ 3ï¼šæ”¶åˆ° '{text}'")
        return f"çµæœï¼š{text}"
    
    # ä½¿ç”¨ LangChain èªæ³•
    from langchain_core.runnables import RunnableLambda
    
    chain = (
        RunnableLambda(step1)
        | RunnableLambda(step2)
        | RunnableLambda(step3)
    )
    
    return chain

# æ¸¬è©¦ Chain
chain = build_text_processing_chain()
result = chain.invoke("hello")
print(f"\næœ€çµ‚çµæœï¼š{result}")
```

### **ç·´ç¿’ 3ï¼šæ¯”è¼ƒä¸åŒ Chain å¯«æ³•**

```python
# æ–¹æ³• 1ï¼šæ‰‹å‹•ä¸²è¯
def manual_chain(text):
    step1_result = text.upper()
    step2_result = step1_result + "!"
    step3_result = f"çµæœï¼š{step2_result}"
    return step3_result

# æ–¹æ³• 2ï¼šä½¿ç”¨ LangChain Chain
from langchain_core.runnables import RunnableLambda

def upper_case(text):
    return text.upper()

def add_exclamation(text):
    return text + "!"

def add_prefix(text):
    return f"çµæœï¼š{text}"

langchain_chain = (
    RunnableLambda(upper_case)
    | RunnableLambda(add_exclamation)
    | RunnableLambda(add_prefix)
)

# æ¯”è¼ƒå…©ç¨®æ–¹æ³•
test_text = "hello world"

print("æ–¹æ³• 1ï¼ˆæ‰‹å‹•ä¸²è¯ï¼‰ï¼š")
result1 = manual_chain(test_text)
print(result1)

print("\næ–¹æ³• 2ï¼ˆLangChain Chainï¼‰ï¼š")
result2 = langchain_chain.invoke(test_text)
print(result2)

print(f"\nçµæœç›¸åŒï¼š{result1 == result2}")
```

### **ç·´ç¿’ 4ï¼šç†è§£ Dict åœ¨ Chain ä¸­çš„ä½œç”¨**

```python
# æ¨¡æ“¬ RAG ä¸­çš„ Dict ç”¨æ³•
def demonstrate_dict_usage():
    def process_question(question):
        return f"è™•ç†å¾Œçš„å•é¡Œï¼š{question}"
    
    def process_context(question):
        # æ¨¡æ“¬æª¢ç´¢éç¨‹
        mock_docs = ["æ–‡ä»¶ 1ï¼šiPhone è¨­å®š", "æ–‡ä»¶ 2ï¼šMacBook è¨­å®š"]
        return "\n".join(mock_docs)
    
    # æ–¹æ³• 1ï¼šåˆ†åˆ¥è™•ç†
    question = "å¦‚ä½•è¨­å®šæŒ‡ç´‹ï¼Ÿ"
    processed_q = process_question(question)
    processed_c = process_context(question)
    
    print("æ–¹æ³• 1ï¼šåˆ†åˆ¥è™•ç†")
    print(f"å•é¡Œï¼š{processed_q}")
    print(f"ä¸Šä¸‹æ–‡ï¼š{processed_c}")
    
    # æ–¹æ³• 2ï¼šä½¿ç”¨ Dict åŒæ™‚è™•ç†
    def process_both(question):
        return {
            "question": process_question(question),
            "context": process_context(question)
        }
    
    print("\næ–¹æ³• 2ï¼šä½¿ç”¨ Dict åŒæ™‚è™•ç†")
    result = process_both(question)
    print(f"Dict çµæœï¼š{result}")
    
    return result

# æ¸¬è©¦
demonstrate_dict_usage()
```

---

## ğŸ”§ ç¬¬å…«èª²ï¼šLCEL æ·±åº¦è§£æ

### **ä»€éº¼æ˜¯ LCELï¼Ÿ**

**LCEL (LangChain Expression Language)** æ˜¯ LangChain çš„æ ¸å¿ƒèªæ³•ï¼Œè®“ä½ å¯ä»¥ç”¨ `|` æ“ä½œç¬¦ä¸²è¯å„ç¨®çµ„ä»¶ã€‚

### **LCEL çš„è‡ªå‹•åŒ…è£æ©Ÿåˆ¶**

```python
# ä½ å¯«çš„ä»£ç¢¼
retriever | format_docs

# LCEL å…§éƒ¨å¯¦éš›åŸ·è¡Œ
retriever | RunnableLambda(format_docs)
```

**LCEL æœƒè‡ªå‹•æª¢æ¸¬ï¼š**
- å¦‚æœå³é‚Šæ˜¯ `Runnable` ç‰©ä»¶ â†’ ç›´æ¥ä½¿ç”¨
- å¦‚æœå³é‚Šæ˜¯æ™®é€šå‡½æ•¸ â†’ è‡ªå‹•åŒ…è£æˆ `RunnableLambda`
- å¦‚æœå³é‚Šæ˜¯å­—å…¸ â†’ è‡ªå‹•åŒ…è£æˆ `RunnableParallel`

### **å°ç¯„ä¾‹ï¼šç†è§£è‡ªå‹•åŒ…è£**

```python
from langchain_core.runnables import RunnableLambda

# å®šç¾©ä¸€å€‹æ™®é€šå‡½æ•¸
def multiply_by_two(x):
    return x * 2

# æ–¹æ³• 1ï¼šæ‰‹å‹•åŒ…è£
manual_wrapper = RunnableLambda(multiply_by_two)

# æ–¹æ³• 2ï¼šLCEL è‡ªå‹•åŒ…è£ï¼ˆåœ¨ Chain ä¸­ï¼‰
def create_chain():
    # é€™è£¡ LCEL æœƒè‡ªå‹•æŠŠ multiply_by_two åŒ…è£æˆ RunnableLambda
    return RunnableLambda(lambda x: x) | multiply_by_two

# æ¸¬è©¦
test_value = 5
result1 = manual_wrapper.invoke(test_value)
result2 = create_chain().invoke(test_value)

print(f"æ‰‹å‹•åŒ…è£çµæœï¼š{result1}")
print(f"LCEL è‡ªå‹•åŒ…è£çµæœï¼š{result2}")
print(f"çµæœç›¸åŒï¼š{result1 == result2}")
```

---

## ğŸ¯ ç¬¬ä¹èª²ï¼šå¯¦æˆ°ç·´ç¿’

### **ç·´ç¿’ 1ï¼šå»ºç«‹å®Œæ•´çš„ RAG Chain**

```python
# å®Œæ•´çš„ RAG Chain å¯¦ä½œ
def build_complete_rag_chain():
    from langchain_core.runnables import RunnablePassthrough, RunnableLambda
    from langchain_core.output_parsers import StrOutputParser
    from langchain_core.prompts import ChatPromptTemplate
    
    # 1. æ¨¡æ“¬æª¢ç´¢å™¨
    def mock_retriever(question):
        documents = [
            "iPhone 15 æœ‰æŒ‡ç´‹è¾¨è­˜åŠŸèƒ½ï¼Œè¨­å®šæ­¥é©Ÿï¼š1. é€²å…¥è¨­å®š 2. é¸æ“‡ Touch ID 3. æ·»åŠ æŒ‡ç´‹",
            "MacBook Pro æ”¯æ´ Face IDï¼Œåœ¨ç³»çµ±åå¥½è¨­å®šä¸­å¯ä»¥å•Ÿç”¨",
            "iPad æœ‰é¢å®¹ ID åŠŸèƒ½ï¼Œå¯ä»¥åœ¨è¨­å®šä¸­é€²è¡Œè¨­å®š"
        ]
        
        relevant_docs = []
        for doc in documents:
            if any(keyword in doc for keyword in question.split()):
                relevant_docs.append(doc)
        
        # æ¨¡æ“¬ Document ç‰©ä»¶
        class MockDocument:
            def __init__(self, content):
                self.page_content = content
        
        return [MockDocument(doc) for doc in relevant_docs[:2]]
    
    # 2. æ ¼å¼åŒ–å‡½æ•¸
    def format_docs(docs):
        return "\n\n".join([doc.page_content for doc in docs])
    
    # 3. æç¤ºæ¨¡æ¿
    template = """
åŸºæ–¼ä»¥ä¸‹è³‡æ–™å›ç­”å•é¡Œï¼š

è³‡æ–™ï¼š
{context}

å•é¡Œï¼š{question}

è«‹æä¾›è©³ç´°çš„å›ç­”ï¼š
"""
    prompt = ChatPromptTemplate.from_template(template)
    
    # 4. æ¨¡æ“¬ LLM
    def mock_llm(messages):
        return "æ ¹æ“šæä¾›çš„è³‡æ–™ï¼Œæˆ‘å¯ä»¥ç‚ºæ‚¨æä¾›ç›¸é—œçš„è¨­å®šæ­¥é©Ÿèªªæ˜ã€‚"
    
    # 5. çµ„åˆå®Œæ•´çš„ RAG Chain
    rag_chain = (
        {"context": RunnableLambda(mock_retriever) | RunnableLambda(format_docs), 
         "question": RunnablePassthrough()}
        | prompt
        | RunnableLambda(mock_llm)
        | StrOutputParser()
    )
    
    return rag_chain

# æ¸¬è©¦å®Œæ•´çš„ RAG Chain
rag_chain = build_complete_rag_chain()
question = "å¦‚ä½•è¨­å®šæŒ‡ç´‹è¾¨è­˜ï¼Ÿ"
result = rag_chain.invoke(question)
print(f"RAG Chain å›ç­”ï¼š{result}")
```

### **ç·´ç¿’ 2ï¼šæ‹†è§£ RAG Chain åŸ·è¡Œæµç¨‹**

```python
# æ‰‹å‹•åŸ·è¡Œ RAG Chain çš„æ¯å€‹æ­¥é©Ÿ
def manual_rag_execution():
    question = "å¦‚ä½•è¨­å®šæŒ‡ç´‹è¾¨è­˜ï¼Ÿ"
    
    print("=" * 60)
    print("æ‰‹å‹•åŸ·è¡Œ RAG Chain æµç¨‹")
    print("=" * 60)
    
    # æ­¥é©Ÿ 1ï¼šæª¢ç´¢
    print("æ­¥é©Ÿ 1ï¼šæª¢ç´¢ç›¸é—œæ–‡ä»¶")
    docs = mock_retriever(question)
    print(f"æª¢ç´¢åˆ° {len(docs)} å€‹æ–‡ä»¶")
    for i, doc in enumerate(docs, 1):
        print(f"  æ–‡ä»¶ {i}ï¼š{doc.page_content[:50]}...")
    
    # æ­¥é©Ÿ 2ï¼šæ ¼å¼åŒ–
    print("\næ­¥é©Ÿ 2ï¼šæ ¼å¼åŒ–æ–‡ä»¶")
    context = format_docs(docs)
    print(f"æ ¼å¼åŒ–å¾Œé•·åº¦ï¼š{len(context)} å­—å…ƒ")
    
    # æ­¥é©Ÿ 3ï¼šæº–å‚™è¼¸å…¥
    print("\næ­¥é©Ÿ 3ï¼šæº–å‚™è¼¸å…¥å­—å…¸")
    inputs = {"context": context, "question": question}
    print(f"è¼¸å…¥å­—å…¸çš„éµï¼š{list(inputs.keys())}")
    
    # æ­¥é©Ÿ 4ï¼šç”Ÿæˆæç¤º
    print("\næ­¥é©Ÿ 4ï¼šç”Ÿæˆæç¤º")
    formatted_prompt = prompt.format(**inputs)
    print(f"æç¤ºé•·åº¦ï¼š{len(formatted_prompt)} å­—å…ƒ")
    print(f"æç¤ºå…§å®¹ï¼š{formatted_prompt[:100]}...")
    
    # æ­¥é©Ÿ 5ï¼šç”Ÿæˆå›ç­”
    print("\næ­¥é©Ÿ 5ï¼šç”Ÿæˆå›ç­”")
    response = mock_llm(formatted_prompt)
    print(f"AI å›æ‡‰ï¼š{response}")
    
    # æ­¥é©Ÿ 6ï¼šè§£æè¼¸å‡º
    print("\næ­¥é©Ÿ 6ï¼šè§£æè¼¸å‡º")
    final_answer = StrOutputParser().parse(response)
    print(f"æœ€çµ‚ç­”æ¡ˆï¼š{final_answer}")

# åŸ·è¡Œæ‰‹å‹•æµç¨‹
manual_rag_execution()
```

---

## ğŸ“ ç¸½çµ

### **å­¸ç¿’é‡é»å›é¡§ï¼š**

1. **RAG æ¦‚å¿µ**ï¼šæª¢ç´¢å¢å¼·ç”Ÿæˆï¼Œè®“ AI åŸºæ–¼çœŸå¯¦è³‡æ–™å›ç­”å•é¡Œ
2. **LangChain Chain**ï¼šç”¨ `|` æ“ä½œç¬¦ä¸²è¯å¤šå€‹è™•ç†æ­¥é©Ÿ
3. **Dict ç”¨æ³•**ï¼šåŒæ™‚è™•ç†å¤šå€‹è¼¸å…¥æºï¼ˆå•é¡Œå’Œä¸Šä¸‹æ–‡ï¼‰
4. **LCEL è‡ªå‹•åŒ…è£**ï¼šæ™®é€šå‡½æ•¸è‡ªå‹•è½‰æ›ç‚º RunnableLambda
5. **çµ„ä»¶æ‹†è§£**ï¼šç†è§£æ¯å€‹çµ„ä»¶çš„ä½œç”¨å’Œé‹ä½œæ–¹å¼

### **å¯¦ä½œæŠ€èƒ½ï¼š**

- âœ… èƒ½å¤ å»ºç«‹ç°¡å–®çš„ RAG ç³»çµ±
- âœ… ç†è§£ Chain çš„ä¸²è¯æ©Ÿåˆ¶
- âœ… æŒæ¡ Dict åœ¨ LangChain ä¸­çš„ç”¨æ³•
- âœ… èƒ½å¤ æ‹†è§£å’Œé‡æ§‹ RAG Chain
- âœ… äº†è§£ LCEL çš„è‡ªå‹•åŒ…è£æ©Ÿåˆ¶

### **ä¸‹ä¸€æ­¥å­¸ç¿’å»ºè­°ï¼š**

1. **é€²éš RAG**ï¼šå­¸ç¿’å‘é‡è³‡æ–™åº«å’ŒåµŒå…¥æ¨¡å‹
2. **å¤šæª¢ç´¢å™¨**ï¼šå¯¦ä½œæ··åˆæª¢ç´¢ç­–ç•¥
3. **å°è©±è¨˜æ†¶**ï¼šå»ºç«‹æœ‰è¨˜æ†¶çš„ RAG ç³»çµ±
4. **æ•ˆèƒ½å„ªåŒ–**ï¼šå­¸ç¿’ä¸¦è¡Œè™•ç†å’Œå¿«å–æ©Ÿåˆ¶

### **å¯¦ç”¨æŠ€å·§ï¼š**

- å¾ç°¡å–®çš„ç¯„ä¾‹é–‹å§‹ï¼Œé€æ­¥å¢åŠ è¤‡é›œåº¦
- å¤šä½¿ç”¨ `print` èªå¥ä¾†è§€å¯Ÿæ¯å€‹æ­¥é©Ÿçš„è¼¸å‡º
- æ‰‹å‹•åŸ·è¡Œæµç¨‹ä¾†ç†è§£è‡ªå‹•åŒ–èƒŒå¾Œçš„é‚è¼¯
- å˜—è©¦ä¸åŒçš„ Chain çµ„åˆæ–¹å¼

é€™æ¨£çš„å­¸ç¿’è·¯å¾‘èƒ½å¹«åŠ©å­¸ç”Ÿå¾åŸºç¤æ¦‚å¿µé–‹å§‹ï¼Œé€æ­¥å»ºç«‹å° RAG å’Œ LangChain çš„æ·±å…¥ç†è§£ï¼