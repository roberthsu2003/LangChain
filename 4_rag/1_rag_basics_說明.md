æˆ‘ä¾†å¹«æ‚¨è©³ç´°æ‹†è§£ RAG Chain çš„çµæ§‹ï¼Œä¸¦è§£é‡‹ç‚ºä»€éº¼å¯ä»¥åœ¨ Chain ä¸­ä½¿ç”¨ dictã€‚

è®“æˆ‘å…ˆæŸ¥çœ‹ä¸€ä¸‹æ‚¨çš„ RAG å¯¦ä½œï¼Œç„¶å¾Œç‚ºæ‚¨è©³ç´°èªªæ˜ï¼š


[1 tool called]

ç¾åœ¨è®“æˆ‘ç‚ºæ‚¨è©³ç´°æ‹†è§£ RAG Chain çš„çµæ§‹ï¼š

## ğŸ” RAG Chain æ‹†è§£åˆ†æ

### 1. **RAG Chain çš„å®Œæ•´çµæ§‹**

```python
rag_chain = (
    {"context": retriever | format_docs, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)
```

### 2. **ç‚ºä»€éº¼å¯ä»¥ä½¿ç”¨ dictï¼Ÿ**

é€™æ˜¯ LangChain çš„ä¸€å€‹é‡è¦ç‰¹æ€§ï¼è®“æˆ‘è§£é‡‹ï¼š

#### **Dict ä½œç‚º Runnable çš„ç‰¹æ®Šç”¨æ³•**

åœ¨ LangChain ä¸­ï¼Œ**dict å¯ä»¥è¢«è¦–ç‚ºä¸€å€‹ç‰¹æ®Šçš„ Runnable**ï¼Œå®ƒæœƒï¼š

1. **è‡ªå‹•å±•é–‹éµå€¼å°**ï¼šå°‡ dict çš„æ¯å€‹éµå€¼å°ä½œç‚ºç¨ç«‹çš„è¼¸å…¥
2. **ä¸¦è¡Œè™•ç†**ï¼šåŒæ™‚è™•ç†å¤šå€‹è¼¸å…¥æº
3. **è‡ªå‹•åˆä½µ**ï¼šå°‡çµæœåˆä½µæˆä¸€å€‹ dict å‚³éçµ¦ä¸‹ä¸€å€‹æ­¥é©Ÿ

#### **æ‚¨çš„ RAG Chain å¯¦éš›åŸ·è¡Œæµç¨‹**

```python
# æ­¥é©Ÿ 1: è¼¸å…¥è™•ç† (dict ä½œç‚º Runnable)
{"context": retriever | format_docs, "question": RunnablePassthrough()}
```

**å¯¦éš›åŸ·è¡Œæ™‚ï¼š**
- `retriever | format_docs` â†’ æª¢ç´¢æ–‡ä»¶ä¸¦æ ¼å¼åŒ–
- `RunnablePassthrough()` â†’ ç›´æ¥å‚³éåŸå§‹å•é¡Œ
- çµæœï¼š`{"context": "æ ¼å¼åŒ–çš„æ–‡ä»¶å…§å®¹", "question": "åŸå§‹å•é¡Œ"}`

### 3. **è©³ç´°æ‹†è§£æ¯å€‹çµ„ä»¶**

#### **A. è¼¸å…¥è™•ç†å±¤**
```python
{"context": retriever | format_docs, "question": RunnablePassthrough()}
```

**åŠŸèƒ½ï¼š**
- `retriever`ï¼šå¾å‘é‡è³‡æ–™åº«æª¢ç´¢ç›¸é—œæ–‡ä»¶
- `format_docs`ï¼šå°‡æ–‡ä»¶åˆ—è¡¨è½‰æ›ç‚ºå­—ä¸²
- `RunnablePassthrough()`ï¼šç›´æ¥å‚³éåŸå§‹è¼¸å…¥

#### **B. æç¤ºæ¨¡æ¿å±¤**
```python
prompt = ChatPromptTemplate.from_template(template)
```

**åŠŸèƒ½ï¼š**
- æ¥æ”¶ `{"context": "...", "question": "..."}`
- å°‡è®Šæ•¸å¡«å…¥æ¨¡æ¿
- è¼¸å‡ºæ ¼å¼åŒ–çš„æç¤º

#### **C. èªè¨€æ¨¡å‹å±¤**
```python
llm = ChatOllama(model="llama3.2:latest", temperature=0)
```

**åŠŸèƒ½ï¼š**
- æ¥æ”¶æ ¼å¼åŒ–çš„æç¤º
- ç”Ÿæˆå›ç­”
- è¼¸å‡ºåŸå§‹å›æ‡‰

#### **D. è¼¸å‡ºè§£æå±¤**
```python
StrOutputParser()
```

**åŠŸèƒ½ï¼š**
- å°‡èªè¨€æ¨¡å‹çš„å›æ‡‰è½‰æ›ç‚ºç´”æ–‡å­—å­—ä¸²

### 4. **ç‚ºä»€éº¼ä¸æ˜¯ RunnableLambdaï¼Ÿ**

#### **Dict çš„å„ªå‹¢ï¼š**
1. **ç°¡æ½”æ€§**ï¼šä¸éœ€è¦é¡å¤–çš„å‡½æ•¸å®šç¾©
2. **å¯è®€æ€§**ï¼šæ¸…æ¥šè¡¨é”è¼¸å…¥çµæ§‹
3. **è‡ªå‹•åŒ–**ï¼šLangChain è‡ªå‹•è™•ç†ä¸¦è¡ŒåŸ·è¡Œ

#### **å¦‚æœä½¿ç”¨ RunnableLambda çš„å¯«æ³•ï¼š**
```python
def prepare_inputs(inputs):
    question = inputs
    context = format_docs(retriever.invoke(question))
    return {"context": context, "question": question}

rag_chain = (
    RunnableLambda(prepare_inputs)
    | prompt
    | llm
    | StrOutputParser()
)
```

### 5. **å¯¦éš›åŸ·è¡Œç¯„ä¾‹**

è®“æˆ‘å±•ç¤ºä¸€å€‹å®Œæ•´çš„åŸ·è¡Œæµç¨‹ï¼š

```python
# è¼¸å…¥
question = "å¦‚ä½•è¨­å®šæŒ‡ç´‹è¾¨è­˜?"

# æ­¥é©Ÿ 1: æª¢ç´¢å’Œæ ¼å¼åŒ–
retriever_docs = retriever.invoke(question)  # æª¢ç´¢æ–‡ä»¶
context = format_docs(retriever_docs)         # æ ¼å¼åŒ–æ–‡ä»¶

# æ­¥é©Ÿ 2: æº–å‚™è¼¸å…¥
inputs = {"context": context, "question": question}

# æ­¥é©Ÿ 3: ç”Ÿæˆæç¤º
formatted_prompt = prompt.format(**inputs)

# æ­¥é©Ÿ 4: ç”Ÿæˆå›ç­”
response = llm.invoke(formatted_prompt)

# æ­¥é©Ÿ 5: è§£æè¼¸å‡º
final_answer = StrOutputParser().parse(response)
```

### 6. **æ•™å­¸å»ºè­°**

ä½œç‚ºè€å¸«ï¼Œæ‚¨å¯ä»¥é€™æ¨£æ•™å°å­¸ç”Ÿï¼š

#### **åˆç´šç†è§£ï¼š**
- Dict åœ¨ LangChain ä¸­æ˜¯ç‰¹æ®Šçš„ Runnable
- å®ƒè‡ªå‹•è™•ç†å¤šå€‹è¼¸å…¥æº
- ç°¡åŒ–äº†è¤‡é›œçš„è¼¸å…¥æº–å‚™

#### **é€²éšç†è§£ï¼š**
- Dict å…§éƒ¨ä½¿ç”¨ `RunnableParallel` å¯¦ç¾
- æ”¯æ´ä¸¦è¡Œè™•ç†å¤šå€‹è¼¸å…¥
- è‡ªå‹•åˆä½µçµæœ

#### **å¯¦ä½œç·´ç¿’ï¼š**
1. å…ˆç†è§£æ¯å€‹çµ„ä»¶çš„åŠŸèƒ½
2. é€æ­¥çµ„åˆå„å€‹çµ„ä»¶
3. æ¸¬è©¦ä¸åŒçš„è¼¸å…¥æ ¼å¼
4. æ¯”è¼ƒ dict å’Œ RunnableLambda çš„å·®ç•°

é€™æ¨£çš„æ‹†è§£æ–¹å¼èƒ½å¹«åŠ©å­¸ç”Ÿæ›´å¥½åœ°ç†è§£ RAG Chain çš„é‹ä½œåŸç†ï¼