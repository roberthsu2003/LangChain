{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG å¤šæª”æ¡ˆèˆ‡å…ƒæ•¸æ“š\n",
    "\n",
    "æœ¬ç¯„ä¾‹å±•ç¤ºï¼š\n",
    "1. **ç¬¬1å€‹å„²å­˜æ ¼**ï¼šå»ºç«‹å¤šæª”æ¡ˆå‘é‡è³‡æ–™åº«ï¼ˆå«å…ƒæ•¸æ“šï¼‰\n",
    "2. **ç¬¬2å€‹å„²å­˜æ ¼**ï¼šä½¿ç”¨å…ƒæ•¸æ“šéæ¿¾æŸ¥è©¢\n",
    "\n",
    "å­¸ç¿’ç›®æ¨™ï¼šç†è§£å¦‚ä½•è™•ç†å¤šå€‹ä¾†æºçš„æ–‡ä»¶ä¸¦ä½¿ç”¨å…ƒæ•¸æ“šé€²è¡Œéæ¿¾æª¢ç´¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ç¬¬1å€‹å„²å­˜æ ¼ï¼šå»ºç«‹å¤šæª”æ¡ˆå‘é‡è³‡æ–™åº«ï¼ˆå«å…ƒæ•¸æ“šï¼‰\n\nimport os\nfrom langchain.text_splitter import CharacterTextSplitter\nfrom langchain_community.document_loaders import TextLoader\nfrom langchain_community.vectorstores import Chroma\nfrom langchain_community.embeddings import HuggingFaceEmbeddings\n\n# å®šç¾©åŒ…å«æ–‡å­—æª”æ¡ˆçš„ç›®éŒ„å’ŒæŒä¹…åŒ–ç›®éŒ„\ncurrent_dir = os.path.dirname(os.path.abspath(\"__file__\"))\nbooks_dir = os.path.join(current_dir, \"books\")\ndb_dir = os.path.join(current_dir, \"db\")\npersistent_directory = os.path.join(db_dir, \"chroma_db_with_metadata_chinese_nb\")\n\nprint(f\"æ›¸ç±ç›®éŒ„: {books_dir}\")\nprint(f\"æŒä¹…åŒ–ç›®éŒ„: {persistent_directory}\")\n\n# æª¢æŸ¥ Chroma å‘é‡å­˜å„²æ˜¯å¦å·²å­˜åœ¨\nif not os.path.exists(persistent_directory):\n    print(\"æŒä¹…åŒ–ç›®éŒ„ä¸å­˜åœ¨ã€‚æ­£åœ¨åˆå§‹åŒ–å‘é‡å­˜å„²...\")\n\n    # ç¢ºä¿æ›¸ç±ç›®éŒ„å­˜åœ¨\n    if not os.path.exists(books_dir):\n        raise FileNotFoundError(\n            f\"ç›®éŒ„ {books_dir} ä¸å­˜åœ¨ã€‚è«‹æª¢æŸ¥è·¯å¾‘ã€‚\"\n        )\n\n    # åˆ—å‡ºç›®éŒ„ä¸­æ‰€æœ‰æ–‡å­—æª”æ¡ˆ\n    book_files = [f for f in os.listdir(books_dir) if f.endswith(\".txt\")]\n\n    # å¾æ¯å€‹æª”æ¡ˆè®€å–æ–‡å­—å…§å®¹ä¸¦å„²å­˜å…ƒæ•¸æ“š\n    documents = []\n    for book_file in book_files:\n        file_path = os.path.join(books_dir, book_file)\n        loader = TextLoader(file_path)\n        book_docs = loader.load()\n        for doc in book_docs:\n            # ç‚ºæ¯å€‹æ–‡ä»¶æ·»åŠ å…ƒæ•¸æ“šä»¥æŒ‡ç¤ºå…¶ä¾†æº\n            doc.metadata = {\"source\": book_file}\n            documents.append(doc)\n\n    # å°‡æ–‡ä»¶åˆ†å‰²æˆå¡Š\n    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n    docs = text_splitter.split_documents(documents)\n\n    # é¡¯ç¤ºåˆ†å‰²æ–‡ä»¶çš„è³‡è¨Š\n    print(\"\\n--- æ–‡ä»¶å¡Šè³‡è¨Š ---\")\n    print(f\"æ–‡ä»¶å¡Šæ•¸é‡: {len(docs)}\")\n\n    # å»ºç«‹åµŒå…¥æ¨¡å‹\n    print(\"\\n--- æ­£åœ¨å»ºç«‹åµŒå…¥ ---\")\n    embeddings = HuggingFaceEmbeddings(\n        model_name=\"jinaai/jina-embeddings-v2-base-zh\"\n    )\n    print(\"\\n--- å®Œæˆå»ºç«‹åµŒå…¥ ---\")\n\n    # å»ºç«‹ä¸¦æŒä¹…åŒ–å‘é‡å­˜å„²\n    print(\"\\n--- æ­£åœ¨å»ºç«‹ä¸¦æŒä¹…åŒ–å‘é‡å­˜å„² ---\")\n    db = Chroma.from_documents(\n        docs, embeddings, persist_directory=persistent_directory)\n    print(\"\\n--- å®Œæˆå»ºç«‹ä¸¦æŒä¹…åŒ–å‘é‡å­˜å„² ---\")\n\nelse:\n    print(\"å‘é‡å­˜å„²å·²å­˜åœ¨ã€‚ç„¡éœ€åˆå§‹åŒ–ã€‚\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ç¬¬2å€‹å„²å­˜æ ¼ï¼šä½¿ç”¨å…ƒæ•¸æ“šéæ¿¾æŸ¥è©¢\n\nimport os\nfrom langchain_community.vectorstores import Chroma\nfrom langchain_community.embeddings import HuggingFaceEmbeddings\n\n# å®šç¾©æŒä¹…åŒ–ç›®éŒ„\ncurrent_dir = os.path.dirname(os.path.abspath(\"__file__\"))\ndb_dir = os.path.join(current_dir, \"db\")\npersistent_directory = os.path.join(db_dir, \"chroma_db_with_metadata_chinese_nb\")\n\n# å®šç¾©åµŒå…¥æ¨¡å‹\nembeddings = HuggingFaceEmbeddings(model_name=\"jinaai/jina-embeddings-v2-base-zh\")\n\n# ä½¿ç”¨åµŒå…¥å‡½æ•¸è¼‰å…¥ç¾æœ‰çš„å‘é‡å­˜å„²\ndb = Chroma(persist_directory=persistent_directory,\n            embedding_function=embeddings)\n\n# å®šç¾©ä½¿ç”¨è€…çš„å•é¡Œ\nquery = \"è·¯ç”±å™¨çš„WiFiå¯†ç¢¼å¦‚ä½•æ›´æ”¹ï¼Ÿ\"\n\n# æ ¹æ“šæŸ¥è©¢æª¢ç´¢ç›¸é—œæ–‡ä»¶\n# search_type=\"similarity_score_threshold\": ä½¿ç”¨ç›¸ä¼¼åº¦åˆ†æ•¸é–¾å€¼éæ¿¾\n# k=3: è¿”å›æœ€å¤š 3 å€‹ç›¸é—œæ–‡ä»¶\n# score_threshold=0.1: è¼ƒä½çš„é–¾å€¼ï¼Œå¯ä»¥è¿”å›æ›´å¤šç›¸é—œæ–‡ä»¶\nretriever = db.as_retriever(\n    search_type=\"similarity_score_threshold\",\n    search_kwargs={\"k\": 3, \"score_threshold\": 0.1},\n)\nrelevant_docs = retriever.invoke(query)\n\n# é¡¯ç¤ºç›¸é—œçµæœåŠå…ƒæ•¸æ“š\nprint(\"\\n--- ç›¸é—œæ–‡ä»¶ ---\")\nfor i, doc in enumerate(relevant_docs, 1):\n    print(f\"æ–‡ä»¶ {i}:\\n{doc.page_content}\\n\")\n    print(f\"ä¾†æº: {doc.metadata['source']}\\n\")\n\n# é€²éšæŸ¥è©¢ï¼šåªå¾ç‰¹å®šä¾†æºæª¢ç´¢\nprint(\"\\n--- åªå¾ã€Šè·¯ç”±å™¨è¨­å®šæ‰‹å†Šã€‹æª¢ç´¢ ---\")\n# ä½¿ç”¨ filter åƒæ•¸æŒ‡å®šå…ƒæ•¸æ“šæ¢ä»¶\nspecific_docs = db.similarity_search(\n    query,\n    k=3,\n    filter={\"source\": \"è·¯ç”±å™¨è¨­å®šæ‰‹å†Š.txt\"}\n)\n\nfor i, doc in enumerate(specific_docs, 1):\n    print(f\"æ–‡ä»¶ {i}:\\n{doc.page_content}\\n\")\n    print(f\"ä¾†æº: {doc.metadata['source']}\\n\")"
  },
  {
   "cell_type": "code",
   "source": "# ç¬¬3å€‹å„²å­˜æ ¼ï¼šæ•´åˆ Chain - å¤šä¾†æºæ–‡ä»¶çš„æ™ºæ…§å•ç­”éˆ\n\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.runnables import RunnablePassthrough\nfrom langchain_ollama import ChatOllama\n\n# å®šç¾©ä½¿ç”¨è€…çš„å•é¡Œ\nquestion = \"å¦‚ä½•ä¿é¤Šæ´—è¡£æ©Ÿå’Œè·¯ç”±å™¨ï¼Ÿ\"\n\nprint(f\"â“ ä½¿ç”¨è€…å•é¡Œ: {question}\\n\")\n\n# æ­¥é©Ÿ 1: å¾å¤šå€‹ä¾†æºæª¢ç´¢ç›¸é—œæ–‡ä»¶\nprint(\"=\" * 70)\nprint(\"æ­¥é©Ÿ 1: å¾å¤šå€‹ä¾†æºæª¢ç´¢ç›¸é—œæ–‡ä»¶\")\nprint(\"=\" * 70)\n\nretriever = db.as_retriever(\n    search_type=\"similarity\",\n    search_kwargs={\"k\": 4}  # å–4å€‹ç›¸é—œæ–‡ä»¶ï¼ˆå¯èƒ½ä¾†è‡ªä¸åŒæ‰‹å†Šï¼‰\n)\n\nretrieved_docs = retriever.invoke(question)\n\nprint(f\"âœ… æ‰¾åˆ° {len(retrieved_docs)} å€‹ç›¸é—œæ–‡ä»¶\\n\")\nfor i, doc in enumerate(retrieved_docs, 1):\n    source = doc.metadata.get('source', 'Unknown')\n    print(f\"ğŸ“„ æ–‡ä»¶ {i} - ä¾†æº: {source}\")\n    print(f\"   å…§å®¹: {doc.page_content[:80]}...\\n\")\n\n# æ­¥é©Ÿ 2: å»ºç«‹å¸¶æœ‰ä¾†æºæ¨™è¨»çš„ RAG Chain\nprint(\"=\" * 70)\nprint(\"æ­¥é©Ÿ 2: å»ºç«‹å¤šä¾†æº RAG Chain\")\nprint(\"=\" * 70)\n\n# å®šç¾©æç¤ºæ¨¡æ¿ï¼ˆå¼·èª¿ä¾†æºè³‡è¨Šï¼‰\ntemplate = \"\"\"ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„ç”¢å“å®¢æœåŠ©æ‰‹ã€‚è«‹æ ¹æ“šä»¥ä¸‹å¤šå€‹ç”¢å“æ‰‹å†Šçš„åƒè€ƒè³‡æ–™å›ç­”ä½¿ç”¨è€…çš„å•é¡Œã€‚\n\nåƒè€ƒè³‡æ–™ï¼š\n{context}\n\nä½¿ç”¨è€…å•é¡Œï¼š{question}\n\nå›ç­”è¦æ±‚ï¼š\n1. é‡å°ä¸åŒç”¢å“åˆ†åˆ¥èªªæ˜ï¼ˆå¦‚æœå•é¡Œæ¶‰åŠå¤šå€‹ç”¢å“ï¼‰\n2. åœ¨å›ç­”ä¸­æ¨™è¨»è³‡è¨Šä¾†æºï¼ˆä¾‹å¦‚ï¼šã€Œæ ¹æ“šæ´—è¡£æ©Ÿä½¿ç”¨èªªæ˜...ã€ï¼‰\n3. åªæ ¹æ“šåƒè€ƒè³‡æ–™å›ç­”ï¼Œä¸è¦ç·¨é€ å…§å®¹\n4. å¦‚æœæŸå€‹ç”¢å“çš„è³‡è¨Šä¸è¶³ï¼Œè«‹èªªæ˜\n5. ç”¨æ¢åˆ—å¼æ•´ç†ï¼Œè®“ä½¿ç”¨è€…å®¹æ˜“é–±è®€\n\nå›ç­”ï¼š\"\"\"\n\nprompt = ChatPromptTemplate.from_template(template)\n\n# å»ºç«‹ LLM\nllm = ChatOllama(model=\"llama3.2\", temperature=0)\n\n# å®šç¾©æ–‡ä»¶æ ¼å¼åŒ–å‡½æ•¸ï¼ˆåŒ…å«ä¾†æºè³‡è¨Šï¼‰\ndef format_docs_with_source(docs):\n    formatted = []\n    for i, doc in enumerate(docs, 1):\n        source = doc.metadata.get('source', 'Unknown')\n        formatted.append(f\"ã€ä¾†æº {i}: {source}ã€‘\\n{doc.page_content}\")\n    return \"\\n\\n---\\n\\n\".join(formatted)\n\n# å»ºç«‹å®Œæ•´çš„ RAG Chainï¼ˆæ•´åˆ 3_chains çš„æŠ€å·§ï¼‰\nrag_chain = (\n    {\n        \"context\": retriever | format_docs_with_source, \n        \"question\": RunnablePassthrough()\n    }\n    | prompt\n    | llm\n    | StrOutputParser()\n)\n\nprint(\"âœ… å¤šä¾†æº RAG Chain å»ºç«‹å®Œæˆ\\n\")\n\n# æ­¥é©Ÿ 3: åŸ·è¡Œ Chain ä¸¦å–å¾—æ•´åˆç­”æ¡ˆ\nprint(\"=\" * 70)\nprint(\"æ­¥é©Ÿ 3: åŸ·è¡Œ Chain å–å¾—æ•´åˆç­”æ¡ˆ\")\nprint(\"=\" * 70)\n\nanswer = rag_chain.invoke(question)\n\nprint(f\"\\nğŸ¤– ã€AI æ•´åˆå›ç­”ã€‘\\n\")\nprint(answer)\nprint()\n\n# æ­¥é©Ÿ 4: ç¤ºç¯„ä½¿ç”¨å…ƒæ•¸æ“šéæ¿¾çš„ Chain\nprint(\"=\" * 70)\nprint(\"æ­¥é©Ÿ 4: åªæŸ¥è©¢ç‰¹å®šä¾†æºçš„ Chain\")\nprint(\"=\" * 70)\n\nspecific_question = \"è·¯ç”±å™¨å¦‚ä½•è¨­å®šï¼Ÿ\"\nprint(f\"â“ å•é¡Œ: {specific_question}\\n\")\n\n# å‰µå»ºåªæŸ¥è©¢è·¯ç”±å™¨æ‰‹å†Šçš„æª¢ç´¢å™¨\ndef retrieve_from_router_manual(query):\n    docs = db.similarity_search(\n        query,\n        k=3,\n        filter={\"source\": \"è·¯ç”±å™¨è¨­å®šæ‰‹å†Š.txt\"}\n    )\n    return docs\n\n# å»ºç«‹ç‰¹å®šä¾†æºçš„ Chain\nspecific_chain = (\n    {\n        \"context\": RunnablePassthrough() | retrieve_from_router_manual | format_docs_with_source,\n        \"question\": RunnablePassthrough()\n    }\n    | prompt\n    | llm\n    | StrOutputParser()\n)\n\nspecific_answer = specific_chain.invoke(specific_question)\nprint(f\"ğŸ¤– ã€åªæŸ¥è·¯ç”±å™¨æ‰‹å†Šçš„å›ç­”ã€‘\\n\")\nprint(specific_answer)\nprint()\n\nprint(\"=\" * 70)\nprint(\"ğŸ“š å¤šä¾†æº RAG Chain çš„å„ªå‹¢\")\nprint(\"=\" * 70)\nprint(\"âœ… å¯ä»¥åŒæ™‚æŸ¥è©¢å¤šå€‹ç”¢å“æ‰‹å†Š\")\nprint(\"âœ… è‡ªå‹•æ¨™è¨»è³‡è¨Šä¾†æºï¼Œæ–¹ä¾¿è¿½è¹¤\")\nprint(\"âœ… å¯ä»¥ç”¨ metadata éæ¿¾ç‰¹å®šä¾†æº\")\nprint(\"âœ… æ•´åˆå¤šå€‹æ–‡ä»¶çš„è³‡è¨Šçµ¦å‡ºå®Œæ•´ç­”æ¡ˆ\")\nprint(\"\\nğŸ’¡ é€™å±•ç¤ºäº† Chain 3 ä¸­å­¸åˆ°çš„çµ„åˆæŠ€å·§åœ¨ RAG ä¸­çš„æ‡‰ç”¨ï¼\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}