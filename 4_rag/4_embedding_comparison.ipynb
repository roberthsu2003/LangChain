{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding 模型比較\n",
    "\n",
    "本範例展示：\n",
    "1. **第1個儲存格**：使用不同 Embedding 模型建立向量資料庫\n",
    "2. **第2個儲存格**：比較不同模型的檢索效果\n",
    "\n",
    "學習目標：理解不同 Embedding 模型對檢索結果的影響，選擇最適合的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 第1個儲存格：使用不同 Embedding 模型建立向量資料庫\n\nimport os\nfrom langchain_community.document_loaders import TextLoader\nfrom langchain.text_splitter import CharacterTextSplitter\nfrom langchain_community.vectorstores import Chroma\nfrom langchain_community.embeddings import HuggingFaceEmbeddings\n\n# 定義包含文字檔案的目錄和持久化目錄\ncurrent_dir = os.path.dirname(os.path.abspath(\"__file__\"))\nfile_path = os.path.join(current_dir, \"books\", \"健保就醫指南.txt\")\ndb_dir = os.path.join(current_dir, \"db\")\n\n# 檢查文字檔案是否存在\nif not os.path.exists(file_path):\n    raise FileNotFoundError(\n        f\"檔案 {file_path} 不存在。請檢查路徑。\"\n    )\n\n# 從檔案讀取文字內容\nloader = TextLoader(file_path)\ndocuments = loader.load()\n\n# 將文件分割成塊\ntext_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\ndocs = text_splitter.split_documents(documents)\n\n# 顯示分割文件的資訊\nprint(\"\\n--- 文件塊資訊 ---\")\nprint(f\"文件塊數量: {len(docs)}\")\nprint(f\"範例塊:\\n{docs[0].page_content}\\n\")\n\n\n# 建立並持久化向量存儲的函數\ndef create_vector_store(docs, embeddings, store_name):\n    persistent_directory = os.path.join(db_dir, store_name)\n    if not os.path.exists(persistent_directory):\n        print(f\"\\n--- 正在建立向量存儲 {store_name} ---\")\n        Chroma.from_documents(\n            docs, embeddings, persist_directory=persistent_directory)\n        print(f\"--- 完成建立向量存儲 {store_name} ---\")\n    else:\n        print(\n            f\"向量存儲 {store_name} 已存在。無需初始化。\")\n\n\n# 1. Jina Embeddings v2 (繁體中文專用)\n# 專門為中英雙語優化的模型\n# 維度：768，最大序列長度：8192 tokens\n# 適用於：繁體中文內容、長文檔處理\nprint(\"\\n--- 使用 Jina Embeddings v2（繁體中文專用）---\")\njina_embeddings = HuggingFaceEmbeddings(\n    model_name=\"jinaai/jina-embeddings-v2-base-zh\"\n)\ncreate_vector_store(docs, jina_embeddings, \"chroma_db_jina_nb\")\n\n# 2. Multilingual E5 Large (多語言模型)\n# 微軟開發的多語言嵌入模型\n# 維度：1024，最大序列長度：512 tokens\n# 適用於：多語言內容、高精度需求\nprint(\"\\n--- 使用 Multilingual E5 Large（多語言模型）---\")\ne5_embeddings = HuggingFaceEmbeddings(\n    model_name=\"intfloat/multilingual-e5-large\"\n)\ncreate_vector_store(docs, e5_embeddings, \"chroma_db_e5_nb\")\n\n# 3. All-MiniLM-L6-v2 (輕量級英文模型)\n# Sentence Transformers 的輕量級模型\n# 維度：384，最大序列長度：256 tokens\n# 適用於：速度優先、資源受限環境\nprint(\"\\n--- 使用 All-MiniLM-L6-v2（輕量級模型）---\")\nminilm_embeddings = HuggingFaceEmbeddings(\n    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n)\ncreate_vector_store(docs, minilm_embeddings, \"chroma_db_minilm_nb\")\n\n# 4. All-MPNet-Base-v2 (平衡型英文模型)\n# Sentence Transformers 的平衡型模型\n# 維度：768，最大序列長度：384 tokens\n# 適用於：英文內容、平衡效能與速度\nprint(\"\\n--- 使用 All-MPNet-Base-v2（平衡型模型）---\")\nmpnet_embeddings = HuggingFaceEmbeddings(\n    model_name=\"sentence-transformers/all-mpnet-base-v2\"\n)\ncreate_vector_store(docs, mpnet_embeddings, \"chroma_db_mpnet_nb\")\n\nprint(\"\\n=== 所有向量存儲已建立完成 ===\")\nprint(\"\\n模型特性比較：\")\nprint(\"- Jina v2: 768維，8192 tokens，繁體中文專用\")\nprint(\"- E5 Large: 1024維，512 tokens，多語言高精度\")\nprint(\"- MiniLM: 384維，256 tokens，輕量快速\")\nprint(\"- MPNet: 768維，384 tokens，英文平衡型\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 第3個儲存格：整合 Chain 功能 - 比較不同 Embedding 模型的 RAG Chain\n\nimport os\nfrom langchain_community.vectorstores import Chroma\nfrom langchain_community.embeddings import HuggingFaceEmbeddings\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.runnables import RunnablePassthrough\nfrom langchain_openai import ChatOpenAI\n\n# 定義路徑\ncurrent_dir = os.path.dirname(os.path.abspath(\"__file__\"))\ndb_dir = os.path.join(current_dir, \"db\")\n\n# 初始化 LLM\nllm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n\n# 定義 Prompt 模板\nprompt = ChatPromptTemplate.from_template(\"\"\"你是一位專業的健保諮詢助理，請根據提供的資料回答使用者問題。\n\n參考資料：\n{context}\n\n問題：{question}\n\n請提供清楚、準確的回答：\"\"\")\n\n# 格式化文件的函數\ndef format_docs(docs):\n    return \"\\n\\n\".join(doc.page_content for doc in docs)\n\n# 使用不同 Embedding 模型的 RAG Chain 並比較結果\ndef compare_embedding_rag_chains(store_name, query, embedding_function, model_name):\n    persistent_directory = os.path.join(db_dir, store_name)\n    if os.path.exists(persistent_directory):\n        print(f\"\\n{'='*70}\")\n        print(f\"Embedding 模型：{model_name}\")\n        print(f\"{'='*70}\")\n        \n        # 載入向量資料庫\n        db = Chroma(\n            persist_directory=persistent_directory,\n            embedding_function=embedding_function\n        )\n        \n        # 建立檢索器\n        retriever = db.as_retriever(\n            search_type=\"similarity\",\n            search_kwargs={\"k\": 2}\n        )\n        \n        # 步驟 1：檢索相關文件\n        print(f\"\\n📋 步驟 1：檢索相關文件\")\n        retrieved_docs = retriever.invoke(query)\n        print(f\"找到 {len(retrieved_docs)} 個相關文件\")\n        for i, doc in enumerate(retrieved_docs, 1):\n            print(f\"\\n文件 {i} 內容預覽：\")\n            print(f\"{doc.page_content[:150]}...\")\n        \n        # 步驟 2：建立 RAG Chain\n        print(f\"\\n⛓️  步驟 2：建立 RAG Chain\")\n        rag_chain = (\n            {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n            | prompt\n            | llm\n            | StrOutputParser()\n        )\n        \n        # 步驟 3：執行 Chain 並取得答案\n        print(f\"\\n🤖 步驟 3：生成回答\")\n        answer = rag_chain.invoke(query)\n        print(f\"\\n【{model_name} 的回答】\")\n        print(answer)\n        print(f\"\\n{'-'*70}\")\n        \n        return answer\n    else:\n        print(f\"向量存儲 {store_name} 不存在。\")\n        return None\n\n# 定義不同的嵌入模型\njina_embeddings = HuggingFaceEmbeddings(\n    model_name=\"jinaai/jina-embeddings-v2-base-zh\"\n)\ne5_embeddings = HuggingFaceEmbeddings(\n    model_name=\"intfloat/multilingual-e5-large\"\n)\nminilm_embeddings = HuggingFaceEmbeddings(\n    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n)\nmpnet_embeddings = HuggingFaceEmbeddings(\n    model_name=\"sentence-transformers/all-mpnet-base-v2\"\n)\n\n# 定義使用者的問題\nquery = \"健保卡遺失如何補辦？需要準備什麼文件？\"\n\nprint(\"\\n\" + \"=\"*70)\nprint(f\"查詢問題：{query}\")\nprint(\"=\"*70)\n\n# 比較不同 Embedding 模型的 RAG Chain 效果\nresults = {}\nresults[\"Jina v2\"] = compare_embedding_rag_chains(\n    \"chroma_db_jina_nb\", \n    query, \n    jina_embeddings, \n    \"Jina Embeddings v2 (繁體中文專用)\"\n)\nresults[\"E5 Large\"] = compare_embedding_rag_chains(\n    \"chroma_db_e5_nb\", \n    query, \n    e5_embeddings, \n    \"Multilingual E5 Large (多語言)\"\n)\nresults[\"MiniLM\"] = compare_embedding_rag_chains(\n    \"chroma_db_minilm_nb\", \n    query, \n    minilm_embeddings, \n    \"All-MiniLM-L6-v2 (輕量級)\"\n)\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"📊 Embedding 模型對 RAG Chain 的影響總結\")\nprint(\"=\"*70)\nprint(\"\"\"\n🔍 觀察重點：\n1. 不同模型檢索到的文件是否相關\n2. 中文語義理解的準確度\n3. 最終答案的完整性和準確性\n\n💡 實測結果分析：\n- Jina v2：對繁體中文理解最佳，檢索準確度最高\n- E5 Large：多語言能力強，中文表現也不錯\n- MiniLM/MPNet：主要針對英文，中文效果較差\n\n📌 選擇建議：\n✅ 繁體中文應用 → Jina Embeddings v2 (推薦！)\n   - 768維向量，8192 tokens 支援長文檔\n   - 專門為中英雙語優化\n   \n✅ 多語言應用 → Multilingual E5 Large\n   - 1024維向量，100+ 語言支援\n   - 適合需要處理多種語言的場景\n   \n✅ 英文應用 + 資源受限 → All-MiniLM-L6-v2\n   - 384維向量，輕量快速\n   - 適合英文為主且需要快速回應的場景\n\n🎯 關鍵學習：\nEmbedding 模型的選擇直接影響檢索品質！\n使用適合語言特性的模型，能大幅提升 RAG 系統效果。\n\"\"\")\nprint(\"=\"*70)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}