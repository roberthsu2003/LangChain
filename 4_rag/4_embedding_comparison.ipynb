{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding æ¨¡å‹æ¯”è¼ƒ\n",
    "\n",
    "æœ¬ç¯„ä¾‹å±•ç¤ºï¼š\n",
    "1. **ç¬¬1å€‹å„²å­˜æ ¼**ï¼šä½¿ç”¨ä¸åŒ Embedding æ¨¡å‹å»ºç«‹å‘é‡è³‡æ–™åº«\n",
    "2. **ç¬¬2å€‹å„²å­˜æ ¼**ï¼šæ¯”è¼ƒä¸åŒæ¨¡å‹çš„æª¢ç´¢æ•ˆæœ\n",
    "\n",
    "å­¸ç¿’ç›®æ¨™ï¼šç†è§£ä¸åŒ Embedding æ¨¡å‹å°æª¢ç´¢çµæœçš„å½±éŸ¿ï¼Œé¸æ“‡æœ€é©åˆçš„æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ç¬¬1å€‹å„²å­˜æ ¼ï¼šä½¿ç”¨ä¸åŒ Embedding æ¨¡å‹å»ºç«‹å‘é‡è³‡æ–™åº«\n\nimport os\nfrom langchain_community.document_loaders import TextLoader\nfrom langchain.text_splitter import CharacterTextSplitter\nfrom langchain_community.vectorstores import Chroma\nfrom langchain_community.embeddings import HuggingFaceEmbeddings\n\n# å®šç¾©åŒ…å«æ–‡å­—æª”æ¡ˆçš„ç›®éŒ„å’ŒæŒä¹…åŒ–ç›®éŒ„\ncurrent_dir = os.path.dirname(os.path.abspath(\"__file__\"))\nfile_path = os.path.join(current_dir, \"books\", \"å¥ä¿å°±é†«æŒ‡å—.txt\")\ndb_dir = os.path.join(current_dir, \"db\")\n\n# æª¢æŸ¥æ–‡å­—æª”æ¡ˆæ˜¯å¦å­˜åœ¨\nif not os.path.exists(file_path):\n    raise FileNotFoundError(\n        f\"æª”æ¡ˆ {file_path} ä¸å­˜åœ¨ã€‚è«‹æª¢æŸ¥è·¯å¾‘ã€‚\"\n    )\n\n# å¾æª”æ¡ˆè®€å–æ–‡å­—å…§å®¹\nloader = TextLoader(file_path)\ndocuments = loader.load()\n\n# å°‡æ–‡ä»¶åˆ†å‰²æˆå¡Š\ntext_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\ndocs = text_splitter.split_documents(documents)\n\n# é¡¯ç¤ºåˆ†å‰²æ–‡ä»¶çš„è³‡è¨Š\nprint(\"\\n--- æ–‡ä»¶å¡Šè³‡è¨Š ---\")\nprint(f\"æ–‡ä»¶å¡Šæ•¸é‡: {len(docs)}\")\nprint(f\"ç¯„ä¾‹å¡Š:\\n{docs[0].page_content}\\n\")\n\n\n# å»ºç«‹ä¸¦æŒä¹…åŒ–å‘é‡å­˜å„²çš„å‡½æ•¸\ndef create_vector_store(docs, embeddings, store_name):\n    persistent_directory = os.path.join(db_dir, store_name)\n    if not os.path.exists(persistent_directory):\n        print(f\"\\n--- æ­£åœ¨å»ºç«‹å‘é‡å­˜å„² {store_name} ---\")\n        Chroma.from_documents(\n            docs, embeddings, persist_directory=persistent_directory)\n        print(f\"--- å®Œæˆå»ºç«‹å‘é‡å­˜å„² {store_name} ---\")\n    else:\n        print(\n            f\"å‘é‡å­˜å„² {store_name} å·²å­˜åœ¨ã€‚ç„¡éœ€åˆå§‹åŒ–ã€‚\")\n\n\n# 1. Jina Embeddings v2 (ç¹é«”ä¸­æ–‡å°ˆç”¨)\n# å°ˆé–€ç‚ºä¸­è‹±é›™èªå„ªåŒ–çš„æ¨¡å‹\n# ç¶­åº¦ï¼š768ï¼Œæœ€å¤§åºåˆ—é•·åº¦ï¼š8192 tokens\n# é©ç”¨æ–¼ï¼šç¹é«”ä¸­æ–‡å…§å®¹ã€é•·æ–‡æª”è™•ç†\nprint(\"\\n--- ä½¿ç”¨ Jina Embeddings v2ï¼ˆç¹é«”ä¸­æ–‡å°ˆç”¨ï¼‰---\")\njina_embeddings = HuggingFaceEmbeddings(\n    model_name=\"jinaai/jina-embeddings-v2-base-zh\"\n)\ncreate_vector_store(docs, jina_embeddings, \"chroma_db_jina_nb\")\n\n# 2. Multilingual E5 Large (å¤šèªè¨€æ¨¡å‹)\n# å¾®è»Ÿé–‹ç™¼çš„å¤šèªè¨€åµŒå…¥æ¨¡å‹\n# ç¶­åº¦ï¼š1024ï¼Œæœ€å¤§åºåˆ—é•·åº¦ï¼š512 tokens\n# é©ç”¨æ–¼ï¼šå¤šèªè¨€å…§å®¹ã€é«˜ç²¾åº¦éœ€æ±‚\nprint(\"\\n--- ä½¿ç”¨ Multilingual E5 Largeï¼ˆå¤šèªè¨€æ¨¡å‹ï¼‰---\")\ne5_embeddings = HuggingFaceEmbeddings(\n    model_name=\"intfloat/multilingual-e5-large\"\n)\ncreate_vector_store(docs, e5_embeddings, \"chroma_db_e5_nb\")\n\n# 3. All-MiniLM-L6-v2 (è¼•é‡ç´šè‹±æ–‡æ¨¡å‹)\n# Sentence Transformers çš„è¼•é‡ç´šæ¨¡å‹\n# ç¶­åº¦ï¼š384ï¼Œæœ€å¤§åºåˆ—é•·åº¦ï¼š256 tokens\n# é©ç”¨æ–¼ï¼šé€Ÿåº¦å„ªå…ˆã€è³‡æºå—é™ç’°å¢ƒ\nprint(\"\\n--- ä½¿ç”¨ All-MiniLM-L6-v2ï¼ˆè¼•é‡ç´šæ¨¡å‹ï¼‰---\")\nminilm_embeddings = HuggingFaceEmbeddings(\n    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n)\ncreate_vector_store(docs, minilm_embeddings, \"chroma_db_minilm_nb\")\n\n# 4. All-MPNet-Base-v2 (å¹³è¡¡å‹è‹±æ–‡æ¨¡å‹)\n# Sentence Transformers çš„å¹³è¡¡å‹æ¨¡å‹\n# ç¶­åº¦ï¼š768ï¼Œæœ€å¤§åºåˆ—é•·åº¦ï¼š384 tokens\n# é©ç”¨æ–¼ï¼šè‹±æ–‡å…§å®¹ã€å¹³è¡¡æ•ˆèƒ½èˆ‡é€Ÿåº¦\nprint(\"\\n--- ä½¿ç”¨ All-MPNet-Base-v2ï¼ˆå¹³è¡¡å‹æ¨¡å‹ï¼‰---\")\nmpnet_embeddings = HuggingFaceEmbeddings(\n    model_name=\"sentence-transformers/all-mpnet-base-v2\"\n)\ncreate_vector_store(docs, mpnet_embeddings, \"chroma_db_mpnet_nb\")\n\nprint(\"\\n=== æ‰€æœ‰å‘é‡å­˜å„²å·²å»ºç«‹å®Œæˆ ===\")\nprint(\"\\næ¨¡å‹ç‰¹æ€§æ¯”è¼ƒï¼š\")\nprint(\"- Jina v2: 768ç¶­ï¼Œ8192 tokensï¼Œç¹é«”ä¸­æ–‡å°ˆç”¨\")\nprint(\"- E5 Large: 1024ç¶­ï¼Œ512 tokensï¼Œå¤šèªè¨€é«˜ç²¾åº¦\")\nprint(\"- MiniLM: 384ç¶­ï¼Œ256 tokensï¼Œè¼•é‡å¿«é€Ÿ\")\nprint(\"- MPNet: 768ç¶­ï¼Œ384 tokensï¼Œè‹±æ–‡å¹³è¡¡å‹\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ç¬¬3å€‹å„²å­˜æ ¼ï¼šæ•´åˆ Chain åŠŸèƒ½ - æ¯”è¼ƒä¸åŒ Embedding æ¨¡å‹çš„ RAG Chain\n\nimport os\nfrom langchain_community.vectorstores import Chroma\nfrom langchain_community.embeddings import HuggingFaceEmbeddings\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.runnables import RunnablePassthrough\nfrom langchain_openai import ChatOpenAI\n\n# å®šç¾©è·¯å¾‘\ncurrent_dir = os.path.dirname(os.path.abspath(\"__file__\"))\ndb_dir = os.path.join(current_dir, \"db\")\n\n# åˆå§‹åŒ– LLM\nllm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n\n# å®šç¾© Prompt æ¨¡æ¿\nprompt = ChatPromptTemplate.from_template(\"\"\"ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„å¥ä¿è«®è©¢åŠ©ç†ï¼Œè«‹æ ¹æ“šæä¾›çš„è³‡æ–™å›ç­”ä½¿ç”¨è€…å•é¡Œã€‚\n\nåƒè€ƒè³‡æ–™ï¼š\n{context}\n\nå•é¡Œï¼š{question}\n\nè«‹æä¾›æ¸…æ¥šã€æº–ç¢ºçš„å›ç­”ï¼š\"\"\")\n\n# æ ¼å¼åŒ–æ–‡ä»¶çš„å‡½æ•¸\ndef format_docs(docs):\n    return \"\\n\\n\".join(doc.page_content for doc in docs)\n\n# ä½¿ç”¨ä¸åŒ Embedding æ¨¡å‹çš„ RAG Chain ä¸¦æ¯”è¼ƒçµæœ\ndef compare_embedding_rag_chains(store_name, query, embedding_function, model_name):\n    persistent_directory = os.path.join(db_dir, store_name)\n    if os.path.exists(persistent_directory):\n        print(f\"\\n{'='*70}\")\n        print(f\"Embedding æ¨¡å‹ï¼š{model_name}\")\n        print(f\"{'='*70}\")\n        \n        # è¼‰å…¥å‘é‡è³‡æ–™åº«\n        db = Chroma(\n            persist_directory=persistent_directory,\n            embedding_function=embedding_function\n        )\n        \n        # å»ºç«‹æª¢ç´¢å™¨\n        retriever = db.as_retriever(\n            search_type=\"similarity\",\n            search_kwargs={\"k\": 2}\n        )\n        \n        # æ­¥é©Ÿ 1ï¼šæª¢ç´¢ç›¸é—œæ–‡ä»¶\n        print(f\"\\nğŸ“‹ æ­¥é©Ÿ 1ï¼šæª¢ç´¢ç›¸é—œæ–‡ä»¶\")\n        retrieved_docs = retriever.invoke(query)\n        print(f\"æ‰¾åˆ° {len(retrieved_docs)} å€‹ç›¸é—œæ–‡ä»¶\")\n        for i, doc in enumerate(retrieved_docs, 1):\n            print(f\"\\næ–‡ä»¶ {i} å…§å®¹é è¦½ï¼š\")\n            print(f\"{doc.page_content[:150]}...\")\n        \n        # æ­¥é©Ÿ 2ï¼šå»ºç«‹ RAG Chain\n        print(f\"\\nâ›“ï¸  æ­¥é©Ÿ 2ï¼šå»ºç«‹ RAG Chain\")\n        rag_chain = (\n            {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n            | prompt\n            | llm\n            | StrOutputParser()\n        )\n        \n        # æ­¥é©Ÿ 3ï¼šåŸ·è¡Œ Chain ä¸¦å–å¾—ç­”æ¡ˆ\n        print(f\"\\nğŸ¤– æ­¥é©Ÿ 3ï¼šç”Ÿæˆå›ç­”\")\n        answer = rag_chain.invoke(query)\n        print(f\"\\nã€{model_name} çš„å›ç­”ã€‘\")\n        print(answer)\n        print(f\"\\n{'-'*70}\")\n        \n        return answer\n    else:\n        print(f\"å‘é‡å­˜å„² {store_name} ä¸å­˜åœ¨ã€‚\")\n        return None\n\n# å®šç¾©ä¸åŒçš„åµŒå…¥æ¨¡å‹\njina_embeddings = HuggingFaceEmbeddings(\n    model_name=\"jinaai/jina-embeddings-v2-base-zh\"\n)\ne5_embeddings = HuggingFaceEmbeddings(\n    model_name=\"intfloat/multilingual-e5-large\"\n)\nminilm_embeddings = HuggingFaceEmbeddings(\n    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n)\nmpnet_embeddings = HuggingFaceEmbeddings(\n    model_name=\"sentence-transformers/all-mpnet-base-v2\"\n)\n\n# å®šç¾©ä½¿ç”¨è€…çš„å•é¡Œ\nquery = \"å¥ä¿å¡éºå¤±å¦‚ä½•è£œè¾¦ï¼Ÿéœ€è¦æº–å‚™ä»€éº¼æ–‡ä»¶ï¼Ÿ\"\n\nprint(\"\\n\" + \"=\"*70)\nprint(f\"æŸ¥è©¢å•é¡Œï¼š{query}\")\nprint(\"=\"*70)\n\n# æ¯”è¼ƒä¸åŒ Embedding æ¨¡å‹çš„ RAG Chain æ•ˆæœ\nresults = {}\nresults[\"Jina v2\"] = compare_embedding_rag_chains(\n    \"chroma_db_jina_nb\", \n    query, \n    jina_embeddings, \n    \"Jina Embeddings v2 (ç¹é«”ä¸­æ–‡å°ˆç”¨)\"\n)\nresults[\"E5 Large\"] = compare_embedding_rag_chains(\n    \"chroma_db_e5_nb\", \n    query, \n    e5_embeddings, \n    \"Multilingual E5 Large (å¤šèªè¨€)\"\n)\nresults[\"MiniLM\"] = compare_embedding_rag_chains(\n    \"chroma_db_minilm_nb\", \n    query, \n    minilm_embeddings, \n    \"All-MiniLM-L6-v2 (è¼•é‡ç´š)\"\n)\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"ğŸ“Š Embedding æ¨¡å‹å° RAG Chain çš„å½±éŸ¿ç¸½çµ\")\nprint(\"=\"*70)\nprint(\"\"\"\nğŸ” è§€å¯Ÿé‡é»ï¼š\n1. ä¸åŒæ¨¡å‹æª¢ç´¢åˆ°çš„æ–‡ä»¶æ˜¯å¦ç›¸é—œ\n2. ä¸­æ–‡èªç¾©ç†è§£çš„æº–ç¢ºåº¦\n3. æœ€çµ‚ç­”æ¡ˆçš„å®Œæ•´æ€§å’Œæº–ç¢ºæ€§\n\nğŸ’¡ å¯¦æ¸¬çµæœåˆ†æï¼š\n- Jina v2ï¼šå°ç¹é«”ä¸­æ–‡ç†è§£æœ€ä½³ï¼Œæª¢ç´¢æº–ç¢ºåº¦æœ€é«˜\n- E5 Largeï¼šå¤šèªè¨€èƒ½åŠ›å¼·ï¼Œä¸­æ–‡è¡¨ç¾ä¹Ÿä¸éŒ¯\n- MiniLM/MPNetï¼šä¸»è¦é‡å°è‹±æ–‡ï¼Œä¸­æ–‡æ•ˆæœè¼ƒå·®\n\nğŸ“Œ é¸æ“‡å»ºè­°ï¼š\nâœ… ç¹é«”ä¸­æ–‡æ‡‰ç”¨ â†’ Jina Embeddings v2 (æ¨è–¦ï¼)\n   - 768ç¶­å‘é‡ï¼Œ8192 tokens æ”¯æ´é•·æ–‡æª”\n   - å°ˆé–€ç‚ºä¸­è‹±é›™èªå„ªåŒ–\n   \nâœ… å¤šèªè¨€æ‡‰ç”¨ â†’ Multilingual E5 Large\n   - 1024ç¶­å‘é‡ï¼Œ100+ èªè¨€æ”¯æ´\n   - é©åˆéœ€è¦è™•ç†å¤šç¨®èªè¨€çš„å ´æ™¯\n   \nâœ… è‹±æ–‡æ‡‰ç”¨ + è³‡æºå—é™ â†’ All-MiniLM-L6-v2\n   - 384ç¶­å‘é‡ï¼Œè¼•é‡å¿«é€Ÿ\n   - é©åˆè‹±æ–‡ç‚ºä¸»ä¸”éœ€è¦å¿«é€Ÿå›æ‡‰çš„å ´æ™¯\n\nğŸ¯ é—œéµå­¸ç¿’ï¼š\nEmbedding æ¨¡å‹çš„é¸æ“‡ç›´æ¥å½±éŸ¿æª¢ç´¢å“è³ªï¼\nä½¿ç”¨é©åˆèªè¨€ç‰¹æ€§çš„æ¨¡å‹ï¼Œèƒ½å¤§å¹…æå‡ RAG ç³»çµ±æ•ˆæœã€‚\n\"\"\")\nprint(\"=\"*70)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}