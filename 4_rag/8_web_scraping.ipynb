{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ç¶²é çˆ¬å–èˆ‡ RAG æ•´åˆ\n",
        "\n",
        "æœ¬ç¯„ä¾‹å±•ç¤ºï¼š\n",
        "1. **ç¬¬1å€‹å„²å­˜æ ¼**ï¼šä½¿ç”¨ WebBaseLoader çˆ¬å–ç¶²é ä¸¦å»ºç«‹å‘é‡è³‡æ–™åº«\n",
        "2. **ç¬¬2å€‹å„²å­˜æ ¼**ï¼šæŸ¥è©¢ç¶²é å…§å®¹ä¸¦å±•ç¤º RAG æ‡‰ç”¨\n",
        "\n",
        "å­¸ç¿’ç›®æ¨™ï¼šç†è§£å¦‚ä½•å°‡ç¶²é å…§å®¹æ•´åˆåˆ° RAG ç³»çµ±ä¸­ï¼Œå¯¦ç¾å‹•æ…‹çŸ¥è­˜æª¢ç´¢"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ç¬¬1å€‹å„²å­˜æ ¼ï¼šä½¿ç”¨ WebBaseLoader çˆ¬å–ç¶²é ä¸¦å»ºç«‹å‘é‡è³‡æ–™åº«\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "# å¾ .env è¼‰å…¥ç’°å¢ƒè®Šæ•¸ï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰\n",
        "load_dotenv()\n",
        "\n",
        "# å®šç¾©æŒä¹…åŒ–ç›®éŒ„\n",
        "current_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
        "db_dir = os.path.join(current_dir, \"db\")\n",
        "persistent_directory = os.path.join(db_dir, \"chroma_db_web_nb\")\n",
        "\n",
        "print(f\"æŒä¹…åŒ–ç›®éŒ„: {persistent_directory}\")\n",
        "\n",
        "# æª¢æŸ¥ Chroma å‘é‡å­˜å„²æ˜¯å¦å·²å­˜åœ¨\n",
        "if not os.path.exists(persistent_directory):\n",
        "    print(\"æŒä¹…åŒ–ç›®éŒ„ä¸å­˜åœ¨ã€‚æ­£åœ¨åˆå§‹åŒ–å‘é‡å­˜å„²...\")\n",
        "\n",
        "    # æ­¥é©Ÿ 1ï¼šä½¿ç”¨ WebBaseLoader çˆ¬å–ç¶²é å…§å®¹\n",
        "    # WebBaseLoader è¼‰å…¥ç¶²é ä¸¦æå–å…¶å…§å®¹\n",
        "    # ç¯„ä¾‹ä½¿ç”¨ Python å®˜æ–¹æ–‡æª”é é¢\n",
        "    urls = [\n",
        "        \"https://docs.python.org/3/tutorial/index.html\",\n",
        "        \"https://docs.python.org/3/tutorial/introduction.html\"\n",
        "    ]\n",
        "\n",
        "    print(\"\\n--- æ­£åœ¨çˆ¬å–ç¶²é å…§å®¹ ---\")\n",
        "    print(f\"ç›®æ¨™ç¶²å€: {urls}\")\n",
        "    \n",
        "    # å»ºç«‹ç¶²é å…§å®¹è¼‰å…¥å™¨\n",
        "    loader = WebBaseLoader(urls)\n",
        "    documents = loader.load()\n",
        "    \n",
        "    print(f\"\\næˆåŠŸè¼‰å…¥ {len(documents)} å€‹ç¶²é \")\n",
        "    for i, doc in enumerate(documents, 1):\n",
        "        print(f\"  ç¶²é  {i}: {doc.metadata.get('source', 'Unknown')}\")\n",
        "        print(f\"  å…§å®¹é•·åº¦: {len(doc.page_content)} å­—å…ƒ\")\n",
        "\n",
        "    # æ­¥é©Ÿ 2ï¼šå°‡çˆ¬å–çš„å…§å®¹åˆ†å‰²æˆå¡Š\n",
        "    # CharacterTextSplitter å°‡æ–‡æœ¬åˆ†å‰²æˆè¼ƒå°çš„å¡Š\n",
        "    # chunk_size=1000: æ¯å€‹æ–‡æœ¬å€å¡Šæœ€å¤š 1000 å€‹å­—å…ƒ\n",
        "    # chunk_overlap=200: å€å¡Šä¹‹é–“é‡ç–Š 200 å€‹å­—å…ƒ\n",
        "    print(\"\\n--- æ­£åœ¨åˆ†å‰²æ–‡æœ¬ ---\")\n",
        "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "    docs = text_splitter.split_documents(documents)\n",
        "\n",
        "    # é¡¯ç¤ºåˆ†å‰²æ–‡ä»¶çš„è³‡è¨Š\n",
        "    print(f\"æ–‡ä»¶å¡Šæ•¸é‡: {len(docs)}\")\n",
        "    print(f\"\\nç¯„ä¾‹å¡Š (å‰ 200 å­—å…ƒ):\")\n",
        "    print(f\"{docs[0].page_content[:200]}...\\n\")\n",
        "\n",
        "    # æ­¥é©Ÿ 3ï¼šç‚ºæ–‡ä»¶å¡Šå»ºç«‹åµŒå…¥\n",
        "    # HuggingFaceEmbeddings å°‡æ–‡æœ¬è½‰æ›ç‚ºæ•æ‰èªç¾©æ„ç¾©çš„æ•¸å€¼å‘é‡\n",
        "    print(\"--- æ­£åœ¨å»ºç«‹åµŒå…¥ ---\")\n",
        "    embeddings = HuggingFaceEmbeddings(\n",
        "        model_name=\"jinaai/jina-embeddings-v2-base-zh\"\n",
        "    )\n",
        "    print(\"å®Œæˆå»ºç«‹åµŒå…¥\")\n",
        "\n",
        "    # æ­¥é©Ÿ 4ï¼šä½¿ç”¨åµŒå…¥å»ºç«‹ä¸¦æŒä¹…åŒ–å‘é‡å­˜å„²\n",
        "    # Chroma å„²å­˜åµŒå…¥ä»¥é€²è¡Œé«˜æ•ˆæœå°‹\n",
        "    print(\"\\n--- æ­£åœ¨å»ºç«‹å‘é‡å­˜å„² ---\")\n",
        "    db = Chroma.from_documents(\n",
        "        docs, embeddings, persist_directory=persistent_directory\n",
        "    )\n",
        "    print(f\"å®Œæˆå»ºç«‹å‘é‡å­˜å„²æ–¼ {persistent_directory}\")\n",
        "\n",
        "else:\n",
        "    print(\"å‘é‡å­˜å„²å·²å­˜åœ¨ã€‚ç„¡éœ€åˆå§‹åŒ–ã€‚\")\n",
        "    print(\"å¦‚éœ€é‡æ–°çˆ¬å–ç¶²é ï¼Œè«‹åˆªé™¤è³‡æ–™åº«ç›®éŒ„å¾Œé‡æ–°åŸ·è¡Œã€‚\")\n",
        "\n",
        "print(\"\\nâœ… ç¬¬1å€‹å„²å­˜æ ¼åŸ·è¡Œå®Œæˆ\")\n",
        "print(\"\\nğŸ’¡ æç¤ºï¼š\")\n",
        "print(\"- WebBaseLoader å¯ä»¥çˆ¬å–ä»»ä½•å…¬é–‹çš„ç¶²é \")\n",
        "print(\"- å»ºè­°é¸æ“‡å…§å®¹è±å¯Œã€çµæ§‹æ¸…æ™°çš„ç¶²é \")\n",
        "print(\"- æ³¨æ„éµå®ˆç¶²ç«™çš„ robots.txt å’Œä½¿ç”¨æ¢æ¬¾\")\n",
        "print(\"- å°æ–¼éœ€è¦ç™»å…¥æˆ–å‹•æ…‹è¼‰å…¥çš„ç¶²é ï¼Œå¯è€ƒæ…®ä½¿ç”¨ Firecrawl æˆ– Playwright\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ç¬¬2å€‹å„²å­˜æ ¼ï¼šæŸ¥è©¢ç¶²é å…§å®¹ä¸¦å±•ç¤º RAG æ‡‰ç”¨\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain_ollama import ChatOllama\n",
        "\n",
        "# å¾ .env è¼‰å…¥ç’°å¢ƒè®Šæ•¸\n",
        "load_dotenv()\n",
        "\n",
        "# å®šç¾©æŒä¹…åŒ–ç›®éŒ„\n",
        "current_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
        "db_dir = os.path.join(current_dir, \"db\")\n",
        "persistent_directory = os.path.join(db_dir, \"chroma_db_web_nb\")\n",
        "\n",
        "# å®šç¾©åµŒå…¥æ¨¡å‹\n",
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=\"jinaai/jina-embeddings-v2-base-zh\"\n",
        ")\n",
        "\n",
        "# ä½¿ç”¨åµŒå…¥å‡½æ•¸è¼‰å…¥ç¾æœ‰çš„å‘é‡å­˜å„²\n",
        "db = Chroma(\n",
        "    persist_directory=persistent_directory,\n",
        "    embedding_function=embeddings\n",
        ")\n",
        "\n",
        "# æ­¥é©Ÿ 1ï¼šå®šç¾©ä½¿ç”¨è€…çš„å•é¡Œ\n",
        "query = \"What is Python used for?\"\n",
        "\n",
        "print(f\\n{'='*70})")\n",
        "print(f"ä½¿ç”¨è€…å•é¡Œ: {query}")\n",
        "print(f"{'='*70}")\n",
        "\n",
        "# æ­¥é©Ÿ 2ï¼šæ ¹æ“šæŸ¥è©¢æª¢ç´¢ç›¸é—œæ–‡ä»¶\n",
        "# å»ºç«‹ç”¨æ–¼æŸ¥è©¢å‘é‡å­˜å„²çš„æª¢ç´¢å™¨\n",
        "# search_type=\"similarity\": ä½¿ç”¨ç›¸ä¼¼åº¦æœå°‹\n",
        "# k=3: è¿”å›æœ€ç›¸é—œçš„ 3 å€‹æ–‡ä»¶\n",
        "print(\"\\n--- æ­£åœ¨æª¢ç´¢ç›¸é—œæ–‡ä»¶ ---\")\n",
        "retriever = db.as_retriever(\n",
        "    search_type=\"similarity\",\n",
        "    search_kwargs={"k": 3},\n",
        ")\n",
        "relevant_docs = retriever.invoke(query)\n",
        "\n",
        "# é¡¯ç¤ºæª¢ç´¢åˆ°çš„æ–‡ä»¶\n",
        "print(f"\\næ‰¾åˆ° {len(relevant_docs)} å€‹ç›¸é—œæ–‡ä»¶:\\n")\n",
        "for i, doc in enumerate(relevant_docs, 1):\n",
        "    print(f"--- æ–‡ä»¶ {i} ---")\n",
        "    print(f"ä¾†æº: {doc.metadata.get('source', 'Unknown')}")\n",
        "    print(f"å…§å®¹é è¦½: {doc.page_content[:200]}...\\n")\n",
        "\n",
        "# æ­¥é©Ÿ 3ï¼šæ•´åˆæª¢ç´¢åˆ°çš„æ–‡ä»¶èˆ‡ LLM\n",
        "# é€™æ˜¯ RAG çš„æ ¸å¿ƒï¼šå°‡æª¢ç´¢åˆ°çš„æ–‡ä»¶ä½œç‚ºä¸Šä¸‹æ–‡æä¾›çµ¦ LLM\n",
        "print(\"--- æ­£åœ¨æº–å‚™ RAG æç¤º ---\")\n",
        "combined_input = (\n",
        "    \"ä»¥ä¸‹æ˜¯ä¸€äº›å¯èƒ½æœ‰åŠ©æ–¼å›ç­”å•é¡Œçš„ç¶²é å…§å®¹ï¼š\"\n",
        "    + query\n",
        "    + \"\\n\\nç›¸é—œå…§å®¹ï¼š\\n\"\n",
        "    + \"\\n\\n\".join([doc.page_content for doc in relevant_docs])\n",
        "    + \"\\n\\nè«‹åƒ…æ ¹æ“šæä¾›çš„ç¶²é å…§å®¹æä¾›ç­”æ¡ˆã€‚å¦‚æœåœ¨å…§å®¹ä¸­æ‰¾ä¸åˆ°ç­”æ¡ˆï¼Œè«‹å›è¦†ã€æˆ‘ä¸ç¢ºå®šã€ã€‚\"\n",
        ")\n",
        "\n",
        "print(f\"\\nåˆä½µå¾Œçš„æç¤ºé•·åº¦: {len(combined_input)} å­—å…ƒ\")\n",
        "\n",
        "# æ­¥é©Ÿ 4ï¼šä½¿ç”¨ LLM ç”Ÿæˆç­”æ¡ˆ\n",
        "# å»ºç«‹ ChatOllama æ¨¡å‹ï¼ˆä½¿ç”¨æœ¬åœ° LLMï¼‰\n",
        "print(\"\\n--- æ­£åœ¨ç”Ÿæˆç­”æ¡ˆ ---\")\n",
        "model = ChatOllama(model=\"llama3.2\")\n",
        "\n",
        "# å®šç¾©æ¨¡å‹çš„è¨Šæ¯\n",
        "# SystemMessage: è¨­å®š AI çš„è§’è‰²å’Œè¡Œç‚º\n",
        "# HumanMessage: ä½¿ç”¨è€…çš„å•é¡ŒåŠ ä¸Šæª¢ç´¢åˆ°çš„ä¸Šä¸‹æ–‡\n",
        "messages = [\n",
        "    SystemMessage(content=\"ä½ æ˜¯ä¸€å€‹æœ‰å¹«åŠ©çš„åŠ©æ‰‹ï¼Œå°ˆé–€å›ç­”é—œæ–¼ç¨‹å¼èªè¨€çš„å•é¡Œã€‚\"),\n",
        "    HumanMessage(content=combined_input),\n",
        "]
        ",
        "\n",
        "# ä½¿ç”¨åˆä½µçš„è¼¸å…¥èª¿ç”¨æ¨¡å‹\n",
        "result = model.invoke(messages)\n",
        "\n",
        "# é¡¯ç¤ºç”Ÿæˆçš„å›æ‡‰\n",
        "print(f"\\n{'='*70})")\n",
        "print(\"AI ç”Ÿæˆçš„å›æ‡‰:\")\n",
        "print(f"{'='*70}")\n",
        "print(result.content)\n",
        "print(f"{'='*70}")\n",
        "\n",
        "print(\"\\n--- RAG æµç¨‹ç¸½çµ ---\")\n",
        "print(\"1ï¸âƒ£  ä½¿ç”¨ WebBaseLoader çˆ¬å–ç¶²é å…§å®¹\")\n",
        "print(\"2ï¸âƒ£  å°‡å…§å®¹åˆ†å‰²ä¸¦å»ºç«‹å‘é‡è³‡æ–™åº«\")\n",
        "print(\"3ï¸âƒ£  ä½¿ç”¨è€…æå•\")\n",
        "print(\"4ï¸âƒ£  å‘é‡æª¢ç´¢ç›¸é—œå…§å®¹\")\n",
        "print(\"5ï¸âƒ£  å°‡æª¢ç´¢çµæœä½œç‚ºä¸Šä¸‹æ–‡æä¾›çµ¦ LLM\")\n",
        "print(\"6ï¸âƒ£  LLM åŸºæ–¼ç¶²é å…§å®¹ç”Ÿæˆç­”æ¡ˆ\")\n",
        "\n",
        "print(\"\\nğŸ’¡ æ‡‰ç”¨å ´æ™¯ï¼š\")\n",
        "print(\"- æŠ€è¡“æ–‡æª”å•ç­”ç³»çµ±\")\n",
        "print(\"- æ–°è/éƒ¨è½æ ¼å…§å®¹æœå°‹\")\n",
        "print(\"- ç”¢å“èªªæ˜æŸ¥è©¢\")\n",
        "print(\"- çŸ¥è­˜åº«å»ºç«‹\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ç¬¬3å€‹å„²å­˜æ ¼ï¼šä½¿ç”¨ LCEL å»ºç«‹ RAG Chain\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_ollama import ChatOllama\n",
        "\n",
        "# å»ºç«‹ ChatOllama æ¨¡å‹\n",
        "# æ³¨æ„ï¼šæ¨¡å‹å·²åœ¨ç¬¬2å€‹å„²å­˜æ ¼ä¸­å»ºç«‹ï¼Œæ­¤è™•ç‚ºä¿æŒå„²å­˜æ ¼ç¨ç«‹æ€§è€Œé‡æ–°å»ºç«‹\n",
        "model = ChatOllama(model=\"llama3.2\")\n",
        "\n",
        "# å»ºç«‹æç¤ºæ¨¡æ¿\n",
        "# é€™å€‹æ¨¡æ¿æŒ‡å° LLM å¦‚ä½•ä½¿ç”¨å¾ç¶²é çˆ¬å–çš„ä¸Šä¸‹æ–‡ä¾†å›ç­”å•é¡Œ\n",
        "template = '''\n",
        "åƒ…æ ¹æ“šä»¥ä¸‹å¾ç¶²é çˆ¬å–çš„ä¸Šä¸‹æ–‡ä¾†å›ç­”å•é¡Œï¼š\n",
        "{context}\n",
        "\n",
        "å•é¡Œï¼š{question}\n",
        "'''\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "# æ ¼å¼åŒ–æ–‡ä»¶å‡½æ•¸\n",
        "# å°‡æª¢ç´¢åˆ°çš„æ–‡ä»¶åˆ—è¡¨è½‰æ›ç‚ºå–®ä¸€å­—ä¸²\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "# å»ºç«‹ RAG Chain\n",
        "# é€™æ˜¯ä¸€å€‹ä½¿ç”¨ LCEL (LangChain Expression Language) çš„æ¨™æº– RAG å¯¦ä½œ\n",
        "# retriever å·²åœ¨ç¬¬ 2 å€‹å„²å­˜æ ¼ä¸­å®šç¾©\n",
        "rag_chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | model\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "# åŸ·è¡Œ RAG Chain\n",
        "print(\"\\n--- ä½¿ç”¨ LCEL RAG Chain åŸ·è¡Œ ---\")\n",
        "# æˆ‘å€‘å‚³éåŸå§‹å•é¡Œï¼ŒChain æœƒè‡ªå‹•è™•ç†æª¢ç´¢ã€æ ¼å¼åŒ–å’Œæ¨¡å‹èª¿ç”¨\n",
        "# query å·²åœ¨ç¬¬ 2 å€‹å„²å­˜æ ¼ä¸­å®šç¾©\n",
        "response = rag_chain.invoke(query)\n",
        "\n",
        "print(f"\\nå•é¡Œ: {query}")\n",
        "print(f"\\nAI å›æ‡‰:\\n{response}")\n",
        "\n",
        "print(\"\\n--- LCEL RAG Chain æµç¨‹èªªæ˜ ---\")\n",
        "print(\"1. RunnablePassthrough() å°‡ä½¿ç”¨è€…å•é¡Œå‚³éä¸‹å»\")\n",
        "print(\"2. `retriever | format_docs` æª¢ç´¢æ–‡ä»¶ä¸¦æ ¼å¼åŒ–ç‚ºå­—ä¸²\")\n",
        "print(\"3. `prompt` å°‡ä¸Šä¸‹æ–‡å’Œå•é¡Œå¡«å…¥æ¨¡æ¿\")\n",
        "print(\"4. `model` ä½¿ç”¨æç¤ºç”Ÿæˆå›æ‡‰\")\n",
        "print(\"5. `StrOutputParser()` æå–å›æ‡‰å…§å®¹\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}