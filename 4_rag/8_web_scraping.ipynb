{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 網頁爬取與 RAG 整合\n",
        "\n",
        "本範例展示：\n",
        "1. **第1個儲存格**：使用 WebBaseLoader 爬取網頁並建立向量資料庫\n",
        "2. **第2個儲存格**：查詢網頁內容並展示 RAG 應用\n",
        "\n",
        "學習目標：理解如何將網頁內容整合到 RAG 系統中，實現動態知識檢索"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 第1個儲存格：使用 WebBaseLoader 爬取網頁並建立向量資料庫\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "# 從 .env 載入環境變數（如果有的話）\n",
        "load_dotenv()\n",
        "\n",
        "# 定義持久化目錄\n",
        "current_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
        "db_dir = os.path.join(current_dir, \"db\")\n",
        "persistent_directory = os.path.join(db_dir, \"chroma_db_web_nb\")\n",
        "\n",
        "print(f\"持久化目錄: {persistent_directory}\")\n",
        "\n",
        "# 檢查 Chroma 向量存儲是否已存在\n",
        "if not os.path.exists(persistent_directory):\n",
        "    print(\"持久化目錄不存在。正在初始化向量存儲...\")\n",
        "\n",
        "    # 步驟 1：使用 WebBaseLoader 爬取網頁內容\n",
        "    # WebBaseLoader 載入網頁並提取其內容\n",
        "    # 範例使用 Python 官方文檔頁面\n",
        "    urls = [\n",
        "        \"https://docs.python.org/3/tutorial/index.html\",\n",
        "        \"https://docs.python.org/3/tutorial/introduction.html\"\n",
        "    ]\n",
        "\n",
        "    print(\"\\n--- 正在爬取網頁內容 ---\")\n",
        "    print(f\"目標網址: {urls}\")\n",
        "    \n",
        "    # 建立網頁內容載入器\n",
        "    loader = WebBaseLoader(urls)\n",
        "    documents = loader.load()\n",
        "    \n",
        "    print(f\"\\n成功載入 {len(documents)} 個網頁\")\n",
        "    for i, doc in enumerate(documents, 1):\n",
        "        print(f\"  網頁 {i}: {doc.metadata.get('source', 'Unknown')}\")\n",
        "        print(f\"  內容長度: {len(doc.page_content)} 字元\")\n",
        "\n",
        "    # 步驟 2：將爬取的內容分割成塊\n",
        "    # CharacterTextSplitter 將文本分割成較小的塊\n",
        "    # chunk_size=1000: 每個文本區塊最多 1000 個字元\n",
        "    # chunk_overlap=200: 區塊之間重疊 200 個字元\n",
        "    print(\"\\n--- 正在分割文本 ---\")\n",
        "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "    docs = text_splitter.split_documents(documents)\n",
        "\n",
        "    # 顯示分割文件的資訊\n",
        "    print(f\"文件塊數量: {len(docs)}\")\n",
        "    print(f\"\\n範例塊 (前 200 字元):\")\n",
        "    print(f\"{docs[0].page_content[:200]}...\\n\")\n",
        "\n",
        "    # 步驟 3：為文件塊建立嵌入\n",
        "    # HuggingFaceEmbeddings 將文本轉換為捕捉語義意義的數值向量\n",
        "    print(\"--- 正在建立嵌入 ---\")\n",
        "    embeddings = HuggingFaceEmbeddings(\n",
        "        model_name=\"jinaai/jina-embeddings-v2-base-zh\"\n",
        "    )\n",
        "    print(\"完成建立嵌入\")\n",
        "\n",
        "    # 步驟 4：使用嵌入建立並持久化向量存儲\n",
        "    # Chroma 儲存嵌入以進行高效搜尋\n",
        "    print(\"\\n--- 正在建立向量存儲 ---\")\n",
        "    db = Chroma.from_documents(\n",
        "        docs, embeddings, persist_directory=persistent_directory\n",
        "    )\n",
        "    print(f\"完成建立向量存儲於 {persistent_directory}\")\n",
        "\n",
        "else:\n",
        "    print(\"向量存儲已存在。無需初始化。\")\n",
        "    print(\"如需重新爬取網頁，請刪除資料庫目錄後重新執行。\")\n",
        "\n",
        "print(\"\\n✅ 第1個儲存格執行完成\")\n",
        "print(\"\\n💡 提示：\")\n",
        "print(\"- WebBaseLoader 可以爬取任何公開的網頁\")\n",
        "print(\"- 建議選擇內容豐富、結構清晰的網頁\")\n",
        "print(\"- 注意遵守網站的 robots.txt 和使用條款\")\n",
        "print(\"- 對於需要登入或動態載入的網頁，可考慮使用 Firecrawl 或 Playwright\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 第2個儲存格：查詢網頁內容並展示 RAG 應用\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain_ollama import ChatOllama\n",
        "\n",
        "# 從 .env 載入環境變數\n",
        "load_dotenv()\n",
        "\n",
        "# 定義持久化目錄\n",
        "current_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
        "db_dir = os.path.join(current_dir, \"db\")\n",
        "persistent_directory = os.path.join(db_dir, \"chroma_db_web_nb\")\n",
        "\n",
        "# 定義嵌入模型\n",
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=\"jinaai/jina-embeddings-v2-base-zh\"\n",
        ")\n",
        "\n",
        "# 使用嵌入函數載入現有的向量存儲\n",
        "db = Chroma(\n",
        "    persist_directory=persistent_directory,\n",
        "    embedding_function=embeddings\n",
        ")\n",
        "\n",
        "# 步驟 1：定義使用者的問題\n",
        "query = \"What is Python used for?\"\n",
        "\n",
        "print(f\\n{'='*70})")\n",
        "print(f"使用者問題: {query}")\n",
        "print(f"{'='*70}")\n",
        "\n",
        "# 步驟 2：根據查詢檢索相關文件\n",
        "# 建立用於查詢向量存儲的檢索器\n",
        "# search_type=\"similarity\": 使用相似度搜尋\n",
        "# k=3: 返回最相關的 3 個文件\n",
        "print(\"\\n--- 正在檢索相關文件 ---\")\n",
        "retriever = db.as_retriever(\n",
        "    search_type=\"similarity\",\n",
        "    search_kwargs={"k": 3},\n",
        ")\n",
        "relevant_docs = retriever.invoke(query)\n",
        "\n",
        "# 顯示檢索到的文件\n",
        "print(f"\\n找到 {len(relevant_docs)} 個相關文件:\\n")\n",
        "for i, doc in enumerate(relevant_docs, 1):\n",
        "    print(f"--- 文件 {i} ---")\n",
        "    print(f"來源: {doc.metadata.get('source', 'Unknown')}")\n",
        "    print(f"內容預覽: {doc.page_content[:200]}...\\n")\n",
        "\n",
        "# 步驟 3：整合檢索到的文件與 LLM\n",
        "# 這是 RAG 的核心：將檢索到的文件作為上下文提供給 LLM\n",
        "print(\"--- 正在準備 RAG 提示 ---\")\n",
        "combined_input = (\n",
        "    \"以下是一些可能有助於回答問題的網頁內容：\"\n",
        "    + query\n",
        "    + \"\\n\\n相關內容：\\n\"\n",
        "    + \"\\n\\n\".join([doc.page_content for doc in relevant_docs])\n",
        "    + \"\\n\\n請僅根據提供的網頁內容提供答案。如果在內容中找不到答案，請回覆『我不確定』。\"\n",
        ")\n",
        "\n",
        "print(f\"\\n合併後的提示長度: {len(combined_input)} 字元\")\n",
        "\n",
        "# 步驟 4：使用 LLM 生成答案\n",
        "# 建立 ChatOllama 模型（使用本地 LLM）\n",
        "print(\"\\n--- 正在生成答案 ---\")\n",
        "model = ChatOllama(model=\"llama3.2\")\n",
        "\n",
        "# 定義模型的訊息\n",
        "# SystemMessage: 設定 AI 的角色和行為\n",
        "# HumanMessage: 使用者的問題加上檢索到的上下文\n",
        "messages = [\n",
        "    SystemMessage(content=\"你是一個有幫助的助手，專門回答關於程式語言的問題。\"),\n",
        "    HumanMessage(content=combined_input),\n",
        "]
        ",
        "\n",
        "# 使用合併的輸入調用模型\n",
        "result = model.invoke(messages)\n",
        "\n",
        "# 顯示生成的回應\n",
        "print(f"\\n{'='*70})")\n",
        "print(\"AI 生成的回應:\")\n",
        "print(f"{'='*70}")\n",
        "print(result.content)\n",
        "print(f"{'='*70}")\n",
        "\n",
        "print(\"\\n--- RAG 流程總結 ---\")\n",
        "print(\"1️⃣  使用 WebBaseLoader 爬取網頁內容\")\n",
        "print(\"2️⃣  將內容分割並建立向量資料庫\")\n",
        "print(\"3️⃣  使用者提問\")\n",
        "print(\"4️⃣  向量檢索相關內容\")\n",
        "print(\"5️⃣  將檢索結果作為上下文提供給 LLM\")\n",
        "print(\"6️⃣  LLM 基於網頁內容生成答案\")\n",
        "\n",
        "print(\"\\n💡 應用場景：\")\n",
        "print(\"- 技術文檔問答系統\")\n",
        "print(\"- 新聞/部落格內容搜尋\")\n",
        "print(\"- 產品說明查詢\")\n",
        "print(\"- 知識庫建立\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 第3個儲存格：使用 LCEL 建立 RAG Chain\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_ollama import ChatOllama\n",
        "\n",
        "# 建立 ChatOllama 模型\n",
        "# 注意：模型已在第2個儲存格中建立，此處為保持儲存格獨立性而重新建立\n",
        "model = ChatOllama(model=\"llama3.2\")\n",
        "\n",
        "# 建立提示模板\n",
        "# 這個模板指導 LLM 如何使用從網頁爬取的上下文來回答問題\n",
        "template = '''\n",
        "僅根據以下從網頁爬取的上下文來回答問題：\n",
        "{context}\n",
        "\n",
        "問題：{question}\n",
        "'''\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "# 格式化文件函數\n",
        "# 將檢索到的文件列表轉換為單一字串\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "# 建立 RAG Chain\n",
        "# 這是一個使用 LCEL (LangChain Expression Language) 的標準 RAG 實作\n",
        "# retriever 已在第 2 個儲存格中定義\n",
        "rag_chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | model\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "# 執行 RAG Chain\n",
        "print(\"\\n--- 使用 LCEL RAG Chain 執行 ---\")\n",
        "# 我們傳遞原始問題，Chain 會自動處理檢索、格式化和模型調用\n",
        "# query 已在第 2 個儲存格中定義\n",
        "response = rag_chain.invoke(query)\n",
        "\n",
        "print(f"\\n問題: {query}")\n",
        "print(f"\\nAI 回應:\\n{response}")\n",
        "\n",
        "print(\"\\n--- LCEL RAG Chain 流程說明 ---\")\n",
        "print(\"1. RunnablePassthrough() 將使用者問題傳遞下去\")\n",
        "print(\"2. `retriever | format_docs` 檢索文件並格式化為字串\")\n",
        "print(\"3. `prompt` 將上下文和問題填入模板\")\n",
        "print(\"4. `model` 使用提示生成回應\")\n",
        "print(\"5. `StrOutputParser()` 提取回應內容\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}